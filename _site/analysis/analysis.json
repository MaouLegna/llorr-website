[
  {
    "path": "analysis/defining-archetypes-03/",
    "title": "Defining Archetypes #3: Approaching a Clustering Analysis with a Season worth of Data\n",
    "description": "Describing the basic issues when using Clustering Analysis with a bigger dataset and a possible solution in the context of Legends of Runeterra decks.",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-12-25",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nAn Engineering Problem\r\n\r\nDiscussion\r\nNeedles in the Shuriman (vast) Desert\r\nThe Lazy Approach\r\nCross-Region Comparisons\r\n\r\nConclusion\r\n\r\n\r\n\r\n\r\nIntroduction\r\nIn the previous article/analysis on defining archetypes we introduced the basic theory of Cluster Analysis (CA) and applied to a simple toy-example of Legends of Runeterra (LoR) decks.\r\nWe introduced the general theory along side a few widely-used algorithms and some of the “newer” ones like Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Affinity Propagation Clustering (APcluster).\r\nThe example was tailored to give a general idea about the methods, some of their strong point and also potential weaknesses with this specific context of analysing LoR decks.\r\nAs the previous analysis was mostly based around the basic approach to the methods and a well defined example it can’t translate directly to a generalized use with the commonly analysed data like the weekly reports.\r\nFor now, we want to continue to use the Cluster Analysis but this times applied to a set of data on a scale more similar to a real-case-study. To do this we first need to solve a couple of issues related to the scale of the algorithms at hand.\r\n\r\n\r\n\r\nAn Engineering Problem\r\nWhat are the main issue when switching to data from a real-case study? Mostly the impact of the amount of decks to use with the resulting computational load. Also the dirtiness of the data resulting from not having a clean dataset, but that is to be expected.\r\nDistance matrices and consequently all algorithm derived by them have a quadratic growth \\(O(n^2)\\) so scalability is a problem, even more so as this project to “define archetypes” is not meant to be purely theoretical. The aim of this project is to also apply it to the collected data and provide the results, be it in the reports or any other content so time has to be considered.\r\nYet, creating distance matrices at high dimension is not feasible even assuming the analysis is self contained and we have an infinite amount of time to compute the distances. Time is not the only factor, Space is too and probably it is even more important to find a way to solve it. One may not be used to these context so let us give some numbers of the problem at hand.\r\nAt the moment of the writing of this article our Deck’s dataset is made of about 1M decks 1. The dataset contains only 40-cards decks which has been played in Constructed or PvP modes.\r\nRealistically, we would never try to works with all of them at the same time, at least not when using a cluster analysis (CA). A more appropriate time-frame can be a single competitive Season and restrict ourselves only to the decks played around that time.\r\nTo give a reference of a ‘real-case’ number, the Between Worlds (S10) Season which lasted from patch 2.18 to 2.20 featured at Master rank ~42000 unique decks.\r\nAs we are not ready yet to just simply apply any methods to any kind of decks data we are going to create a dataset so that is has a similar scale of the S10-MasterRank (42000) decks.\r\nFor this article we planned to create an example made of 44000 decks. The creation criteria will be explained in another moment. Its size is clearly to have an order of magnitude similar to the S10-MasterRank numbers. Se say planned as the actual analysis of the dataset is being delayed because of issues we just introduced.\r\n\r\n\r\n\r\n\r\n\r\n\r\nLet us now give some more numbers of the problem at hand, let’s talk about the memory allocation of the distance matrix:\r\nIf we used only a fraction of the chosen decks, just 1100, then we would have a \\(1100 \\times 1100\\) distance matrix that requires: 4.7 Mb\r\nIf we increased the choice to 5500 decks, the resulting 5500x5500 distance matrix would occupy: 115.7 Mb.\r\nQuite the increase but consistent to the fact that the second matrix is 25 times the smaller one and we can see the issue with the quadratic growth that comes with the matrix.\r\nBy using all the 44k decks we can’t even try to recreate the distance matrix, it would require a very good machine and we can infer that just the distance matrix size with its \\(44000^2\\) elements would be of around 7424 Mb. We wouldn’t be able to allocate enough memory to save it, let alone work with it.\r\nOverall, while it would be nice to work with any available data (assuming it’s meaningful) one can’t ignore the time/cost that comes from each choice and so we need to search for a way to circumnavigate the issue. While we don’t have the perfect solution, we are going to propose a way to approach the problem making it a bit more feasible.\r\nDiscussion\r\nNeedles in the Shuriman (vast) Desert\r\nLet us assume that we are able to solve the computation and allocation of the distance matrix; this would solve the engineering-side of the problem it would most likely be an incredible ‘a waste’ of resources.\r\nTo explain this we are going to show the resulting heatmaps of a couple of subsets of the example dataset. One with a subset of 1100 decks and another one with 5500 decks. In both cases the subset decks are chosen not completely at random.\r\nThe resulting heatamap with 1100 decks is:\r\n\r\n\r\n\r\nFigure 1: heatmap of a 1100 x 1100 distance matrix of LoR decks chosen not completely at random\r\n\r\n\r\n\r\nThe resulting heatamap with 5500 decks is:\r\n\r\n\r\n\r\nFigure 2: heatmap of a 5500 x 5500 distance matrix of LoR decks chosen not completely at random\r\n\r\n\r\n\r\nAs we can see in Fig:1 and Fig:2 there are clear indication of the presence of several small clusters (the yellow areas) but in the majority, the vast majority of the matrix, the distance is at its max (1) and the similarity is at its min (0) 2.\r\nWhile we need to account for the decks that compose the example, in a typical real-case the results would be similar in most cases.\r\nThere is a structural reason behind this and that’s a result of the limitation imposed by the deck building process which doesn’t allow the use of cards from more than two different regions (not counting Dual Region cards). This makes almost all pair of decks decks with no common region having a similarity that has to be zero (again, dual region cards aside).\r\nOur proposed solution is to use this information and start simplify the problem to a series of smaller one cases.\r\nBecause of the limitation in deck building we know that the similarity of decks with no common faction has to be zero. A Noxus-PnZ deck has to have a similarity equal to zero with a ShadowIsles-Shurima deck and if we order the deck by faction it means that the distance matrix is made of several \\(0_{n \\times n}\\) sub null-matrix.\r\nTo be more precise, there are sadly exception to this property: when we deal with dual region cards we can have non overlapping factions but still common cards 3.\r\n\r\nExample: a BandleCity/Noxus (BC/NX) deck and a Demacia/Ionia (DE/IO) deck both sharing “Poppy” as a card. Both their regions are different but the similarity if not null is we are going to use the original card code of a card.\r\n\r\nFor now everything we will do will ignore the dual-region issue and leave it for for future works.\r\nThe Lazy Approach\r\nLet’s assume we don’t have the problem of the Dual-Region cards and all the 10 regions, what do we know about the structure of the similarity matrix?\r\nWe know that there are 55 unique combination of region and so when comparing two decks it can fall into one of \\(55^2\\) possible confrontation. Of course as we know that the Matrix is symmetrical it’s reduced to just 1540 cases.\r\nOf these 1540 cases, as we already explained, most of them are made of null-matrix. But how many exactly?\r\nAs we mentioned only when there is at least a common region the similarity can be different from zero. This makes it so the number of sub-matrix to consider follows the following formula:\r\n\\[\r\n\\sum_i^n((i-1)^2+\\frac{i(i+1)}{2})\r\n\\]\r\n\r\n\r\n\r\nThe following table shows the percentage of sub-matrix that can be not-null depending on the number of existing regions:\r\n\r\n\r\nSparsity of Similarity Matrix\r\n    Percent of sub-matrix that share a common region  by number of existing regions.\r\n    region\r\n      coverage\r\n    1\r\n100.00&percnt;2\r\n83.33&percnt;3\r\n71.43&percnt;4\r\n61.82&percnt;5\r\n54.17&percnt;6\r\n48.05&percnt;7\r\n43.10&percnt;8\r\n39.04&percnt;9\r\n35.65&percnt;10\r\n32.79&percnt;\r\n\r\nTab. 1: Percent of sub-matrix that share a common region by amount of by number of existing regions.\r\nFrom Tab. 1 we can see that in the current setting with n=10 existing regions, of the 1540 cases only the 32.8% of pairing of combination of regions is actually meaningful with a similarity that can different from zero.\r\nBut this is not over as again only a small subset of this 32.8% is actually relevant.\r\nOf the region comparisons all sub-matrix in the diagonal (55) are of course necessary/relevant (so all NX/PZ vs all NX/PZ), what remains are the cases with only one shared region.\r\nWhen we compare decks with a single shared region not all comparison are meaningful and what follows is a simplification which works for most cases.\r\nIf pairs of decks shares only one regions, for the similarity not to be zero that very same region needs to contains all the common cards. Usually it means that the shared cards are key component to a strategy and unless they are mainly staples they would probably identify an archetype. In the most extreme case the shared region presence may be overwhelming compared to the second one which is used only for the second region unique strength offered by some cards. Like the Rally effects from Demacia.\r\nIn other words, when comparing pair of decks with a single shared region, since we aim to look for clusters, the decks that matters are the “bridge” among the regions with a main region that mostly identify the deck.\r\nAs easy example is the Mistwraith decks that we also used in the previous article 4.\r\nNormally Mistwraith decks are made mostly of Shadow Isles cards while the remaining cards are often from a region of choice that synergies with the rest of the deck but are not essential / key-cards. This cards act are the bridge between regions.\r\nIs the deck using as the only not-SI cards 3 copies of Pale Cascade? Then it’s a SI/MT deck\r\nIs the deck using as the only not-SI cards any copies of Raz Bloodmane? Then it’s a SI/SH deck and SI/MT and SI/SH are connected\r\nIs the deck using as the only not-SI cards 3 copies of Iterative Improvement? Then it’s a SI/PZ deck and we connected SH,MT and PZ by SI.\r\nAnd so on with all the non-SI regions.\r\nOf course as mentioned this is more an approximation as one could that a Mistwraith deck with just 20 SI cards and a lot of duplication cards, the deck could still be defined as Mistwraith decks; here we are going to assume that such identification is an over-simplification and it’s more likely it would be better to define that ‘20 SI cards Mistwraith deck’ as a sub-archetype of Mistwraith Allegiance. While the main archetype and the sub-archetype would have a similar strategy, we believe it would have a play-pattern that differs enough from the ‘main Mistwraith Allegiance’ as the amount of cards from the second region would have a greater impact.\r\nWhat we propose is to use only the ~mono-region decks, add them to the the true-mono region sub-matrix and ignore most of the remaining cases of comparisons of decks with only one shared region.\r\nThe result would for example having all mono-region Noxus decks with all ~mono-region NX/BW, NX/DE, NX/FR,… and reduce all the off-diagonal sub-matrix to n=10 cases, one for each region.\r\nIn a TL:DR we end up reducing our initial problem with 1540 sub-matrix to one with 45 sub-matrix containing all dual region combinations and 10 sub-matrix which contains all the MonoRegion decks AND all the ~mono region decks. The almost mono-region decks will end up being used twice overall but it’s a small increase compared to the smaller coputational load overall.\r\nCross-Region Comparisons\r\nWhen confronting decks with only a shared region we explained how we consider more appropriate to only use bridge decks and considering all the other cases as with null similarity. This open for question: how do we define these bridge decks? Intuitively we described how they mainly relates to cases where a region has an overwhelming playrate compared to the second one, or to put it on another term they are almost mono-region decks.\r\nIf so, at which point a deck can be considered almost mono-region? What benchmark and rules should we use?\r\nThis is tricky but our idea is to use both an hard defined benchmark and the presence of Allegiance cards.\r\nThe choice to include the use of Allegiance cards is meant to be a clear and easy to understand rule that at the same times allows for a more “fuzzy separation” of ~Mono decks with the not-mono decks. The allegiance rule should be able to include some decks that may still point toward a certain strategy that is connected to the region identity while not investing as much cards from that region.\r\nAs such, one question may arise: doesn’t the presence of Allegiance cards requires already a massive amount of cards in a deck from the same region of the allegiance card? It does. But it’s not an hard requirement. Also one shouldn’t underestimate the wild deckbuilding that can be found even at high level ranks, even if few, it’s possible to find all kind of wild decks. We are going to now provide a couple of characteristics of the presence of Allegiance cards in the “Between Worlds Master rank” decks.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTab. 2: Frequency table of all combination of card and copies of Allegiance cards played in the S10 at Master rank.\r\nFirst and foremost with Tab. 2 we can see that simply assuming Allegiance cards identify the main region of a deck is not completely fail-proof as they may exist decks that use Allegiance cards from both regions of a deck. Of course they are extreme cases, they are exception to the rule but as they exist they needs to be accounted for. For now we will simply remove these cases if encountered.\r\nFor the amount of cards from the same region we propose to use all decks with no less than 32 cards from the same region (80%+ cards from the same region). This choice is mostly a guided personal choice than a data-driven one even if we will be able to see that data sort of confirm the validity of choice.\r\nThe reason behind the choice is a such when creating an Allegiance deck that wants to use an Allegiance card deck one can push a second risk with the risk at the main region not being as consistent as it could:\r\nUsing 3 cards from the second region minimize the risk of failing Allegiance while maximizing the use a very strong card from the second region.\r\nMost players would agree that without card draw control, more than 10 cards from the second region (25%+) is pushing luck.\r\nOf all the other cases in the middle having 8 cards from the second region (20% of the total) is probably the most one may push with the risk-benefit.\r\nThe following table shows the relationship of Decks with Allegiance cards with the amount of cards from the same region of the Allegiance card.\r\n\r\n\r\n\r\n\r\n\r\nCumulative Frequencies of Allegiance Decks\r\n    Percentages by decreasing amount of cards from the same region of the Allegiance card.\r\n    same region cards\r\n      n\r\n      cumulative frequency\r\n    40\r\n490\r\n14.57&percnt;39\r\n35\r\n15.61&percnt;38\r\n157\r\n20.28&percnt;37\r\n840\r\n45.26&percnt;36\r\n790\r\n68.75&percnt;35\r\n438\r\n81.77&percnt;34\r\n303\r\n90.78&percnt;33\r\n109\r\n94.02&percnt;32\r\n62\r\n95.87&percnt;31\r\n31\r\n96.79&percnt;30\r\n16\r\n97.26&percnt;29\r\n10\r\n97.56&percnt;28\r\n14\r\n97.98&percnt;27\r\n11\r\n98.31&percnt;26\r\n17\r\n98.81&percnt;25\r\n8\r\n99.05&percnt;24\r\n2\r\n99.11&percnt;23\r\n6\r\n99.29&percnt;22\r\n5\r\n99.44&percnt;21\r\n5\r\n99.58&percnt;20\r\n4\r\n99.70&percnt;19\r\n1\r\n99.73&percnt;18\r\n2\r\n99.79&percnt;17\r\n1\r\n99.82&percnt;16\r\n1\r\n99.85&percnt;15\r\n2\r\n99.91&percnt;12\r\n2\r\n99.97&percnt;9\r\n1\r\n100.00&percnt;Values from the example dataset created for this article. The dataset is made of 800 random decks for each of the 55 combinations of regions among the decks collected over time.\r\n    \r\n\r\nTab. 3: Cumulative Frequencies of Allegiance decks by decreasing amount of cards from the same region of the Allegiance card.\r\nFrom Tab. 3 we can see that in this example 32 cards is the benchmark which allows to include 95% of the Allegiance decks and we are satisfied by this.\r\nThe most surprising result is the presence of decks that have a very few amount of cards from the same region of the Allegiance card like the following example\r\n\r\nThe above deck is an example of those decks. While strange we can still see that it’s supposed to be a different take from the Teemo-Ionia decks that are usually played. Would this case be more appropriate to be considered noise for that archetype? Maybe but at the same time we can also assume it’s an archetype of its own. Overall this is problem related to what defines an archetype. This topic will be explored in the next article as we are trying to apply this approach to the example dataset, or to be more correct, to two of the 55 possible subsets of the example dataset, one for a MonoRegion case and one for a generic dual-region case.\r\nConclusion\r\nOverall this was a very simple article of the subject but that is key to the archetype problem. Again and again I usually start with an idea I have in mind for what should follow an article I just released and each time while in the process of doing it I find myself having to deal with many different issue that needs to be solved before going forward. In this case I wanted to simply apply the cluster algorithms from the second article to the example dataset created here and had to deal with the resources problem (well that one was expected actually) and having to define the rules which allows for the overall data to be divided.\r\nThe proposed method still has a \\(O(n^2)\\) computational complexity but it also has at least one order of magnitude less than the starting problem by switching the focus to each possible region combination. This should solve the computational-load for the time being but now the true challenge begins, the dirtiness of the data still remains.\r\nThe next article should try to deal with this dirtiness and the problem of defining what defines an archetype which is related to the Theseus Ship dilemma. When does an archetype stops being the same archetype after changing one card at a time? Here I won’t promise I will find a personal answer to the problem but again at least something that will allows me to provide some results for the two sub-examples I’m planning to tackle. Will it actually be what the next article will accomplish? Hard to say, but at least that’s the new visible goal.\r\n\r\nConstructed, SeasonalTournamentLobby, Bo3ChallengeLobby, StandardGauntletLobby, LastCallQualifierGauntletLobby↩︎\r\n [0,1] being the domain of the cosine-similarity.↩︎\r\nBandleCity Ruined more than the Ruination↩︎\r\nAt the moment of the writing the Ionia-Allegiance decks provides an even more easier example as similar to Mistwraith decks they are often made of only Ionia cards and differ mostly by the choice of the second region↩︎\r\n",
    "preview": "analysis/defining-archetypes-03/defining-archetypes-03_files/figure-html5/Heat1100-1.png",
    "last_modified": "2021-12-27T06:03:12+01:00",
    "input_file": {},
    "preview_width": 768,
    "preview_height": 768
  },
  {
    "path": "analysis/defining-archetypes-02/",
    "title": "Defining Archetypes #2: Discerning Archetypes by the Application of Clustering Analysis\n",
    "description": "Exploring Clustering Algorithms applied to Archetypes of Legends of Runeterra",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-10-30",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nClustering\r\nK-Means\r\nElbow method\r\nSilhouette method\r\n\r\nHierarchical Clustering\r\n\r\nDefining the problem\r\nUpping the game\r\nShould there exist outliers that’s best not to assign to a cluster?\r\nShould the data be weighted?\r\nIs there any other way to use the metagame data?\r\n\r\n\r\nDBSCAN\r\nDoes DBSCAN scale well?\r\n\r\nK-Medoids (results)\r\nAffinity Propagation Clustering\r\nData\r\nResuls\r\nK-Means\r\nHierachical Clustering\r\nK-Medoid\r\nDBSCAN\r\nAPcluster\r\n\r\n\r\nConclusion\r\nLegal bla bla\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nDefining archetypes on Legends of Runeterra is both a simple yet complex problem. It’s simple as we can define decks for the most part by the combination of champions and regions of choice but it’s also complex by the fact that such definition is quite limited.\r\nOn our previous article/analysis we gave a possible method about how to compare archetypes and see if they can be considered from a shared common archetype or not. The method applied in that article makes use of inferential statistical analysis to reach a conclusion. Sadly, it’s also a methodology that’s more fitting a posterior analysis, when hypothetical archetypes are already defined, a tool more fitted to refine the results and not to define archetypes.\r\nTo identify archetypes, a more fitting methodology is a form of exploratory data analysis (EDA) known as Clustering Analysis (CA). Its aim is to find subgroups (or clusters) in our data without relying on a response variable, also why it’s called unsupervised learning.\r\nAs useful as it is CA suffer from a fundamental problem of not being able to check out the quality of the results. With a vast array of different algorithms and hyper-parameters this also means that finding the the “correct” way to use a CA to define archetypes (which was supposed to be the aim of this article) is not only impossible, it’s also seeing the CA in the wrong way. Surely some choices are better than others but there is no perfect answer and to be fair, this was making us, was making me, procrastinating the writing of this article. The result, or maybe compromise was to reduce the scale on this article which will be a small dive into the cluster analysis. While I want to provide some food for thought to others in the end the main recipient of the article is myself, to provide me a more solid foundation on the topic and how to approach it, knowing the basic limitations of what I’m planning to use.\r\nClustering\r\nClustering is an heterogeneous domain. Applied in a wide range of disciplines with the aim of finding subgroups or clusters, in a data set.\r\nClustering is considered a basic tools of data mining along side the supervised learning domain (clustering is defined as unsupervised learning) but differently from it clustering suffers from a lack of theoretical understanding of its application.\r\nEach example, even the most basic face the problem of selecting which algorithm to apply (known as “the user dilemma”); there is no principled method to guide the selection. While the theory is starting to identify differences between clustering methods, this field is still in it’s early phase and the applications are left to ad hoc decisions. If decisions are being made usually they are defined by engineering properties as run times or memory used.\r\nThis is also a consequence of clustering being a problem not well defined. As statistics is all about the question, it’s not possible to define the ‘correct’ clustering if we have no definition of what it is correct.\r\nOf course, to make this concrete, we must define what it means for two or more observations to be similar or different. As a general rule of rule of thumb we try to aggregate similar observations in the same group while making it so that the differences between groups is overall high.\r\nK-Means\r\nK-Means clustering is a commonly used approach; it’s simple yet performing method for partitioning a data set into K distinct, non-overlapping clusters. The K-Means algorithm has as hyper-parameter the numbers of desired number of clusters K, from that the algorithm will try to create the best k-clusters based by an optimization function. To start, there is an initialization step that randomly assign one of the k cluster to each data point, then, the algorithm iterates until cluster assignments stop changing:\r\nFor each of the K clusters, compute the cluster centroid or barycentre.\r\nAssign each observation to the cluster whose centroid is closest (where closest is defined using Euclidean distance)\r\nAs mentioned, the number of clusters that will be returned is a pre-condition to perform K-Means. The problem of selecting K is far from simple.\r\nThis issue, along with other practical considerations that arise performing K-Means clustering like: should variables should be first be standardized in some way?1\r\nThere are some general guides about how to choose the optimal number of clusters.\r\nThe most commonly used rules are:\r\nElbow method\r\nAs the K-Means clustering tries to define clusters such that the total intra-cluster variation (known as total within-cluster variation or total within-cluster sum of square) is minimized\r\n\\(minimize(\\sum_{k=1}^KW(C_k))\\)\r\nThe total within-cluster sum of squares (wss) measures the compactness of the clustering; we want it to be as small as possible so we can use its value in function of k (number of clusters) and plot them.\r\nThe location of a knee/elbow in the plot is generally considered as an indicator of the appropriate number of clusters.\r\nThis is because normally the wss is related to the number of cluster by a monotone decreasing function, meaning that if the aim is simply to minimise wss then having k = n clusters each of them corresponding to a single element which would give the minimum wss.2\r\nOne must search the optimal value we are searching for is in \\(1 < k < |X|\\) finding a compromise between the reduction of the objective function wss and the dimension of the hyper-parameter k.\r\nCommon practise is to use the Elbow method as it tells us when increasing k is less “worth” compared to the reduction in wss.\r\n\r\n\r\n\r\nFigure 1: within sum of squares as a fnction of number of clusters obtained with K-Means applyed to the example data set\r\n\r\n\r\n\r\nSilhouette method\r\nPrior to this article I’m not sure I even heard about this value: From Wikipedia, the silhouette is defined as:\r\n\r\nThe silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters.\r\n\r\n\r\n\r\n\r\nFigure 2: Silhouette as a fnction of number of clusters obtained with K-Means applyed to the example data set\r\n\r\n\r\n\r\nFig:1 and Fig:2 show the results from the described methods. Using K-Means the algorithm is suggesting a number of k clusters with k around 6 or 7. We will discuss later the quality of these choices, for now we will focus on the algorithm per se.\r\nK-Means while a powerful tool in many fields doesn’t seems to be the best choice for the archetype problem. Its main con is it requires the user to define a priori the number of clusters it needs to find.\r\nThis is almost the opposite of what we would like from the algorithm that should aid us in defining archetypes. Ideally we would prefer if the clustering methods gives us some indications regarding which decks to aggregate into a single archetype, or even division of sub-archetypes if the region+champion combination is not enough to distinguish archetypes. In addition, K-Means presents other problems like having to start with a randomized assignment of clusters, of course this can be controlled by having fixed seeds; it’s also common practises to repeat K-Means multiple times in order to find the ‘mean’-cluster assignment. Yet, the methods is overall quite sensitive to noise/outliers. Even the methods that should help us can be quite subjective, if n is very large defining the location of the knee can be not as clear as in this example.\r\nLastly but not less important, differently from other class of cluster algorithm, there is less flexibility regarding the measure/distance to compare decks.\r\nHierarchical Clustering\r\nOne potential disadvantage of K-Means clustering is that it requires us to pre-specify the number of clusters K. Hierarchical clustering is an alternative approach which does not require that we commit to a particular choice of K. Hierarchical clustering has an added advantage over K-Means clustering in that it results in an attractive tree-based representation of the observations, called a dendogram.\r\nThe hierarchical clustering dendogram is obtained via an extremely simple algorithm. We begin by defining some sort of dissimilarity measure between each pair of observations. Most often, Euclidean distance is used and the algorithm proceeds iteratively. Starting out at the bottom of the dendogram, each of the n observations is treated as its own cluster. The two clusters that are most similar to each other are then fused so that there are now n-1 clusters. The algorithm proceeds in this fashion until all of the observations belong to one single cluster, and the dendogram is complete.\r\nThis algorithm seems simple enough, but one issue has not been addressed. Consider the aggregation step, how do we determine which cluster should be fused with another cluster? We have a concept of the dissimilarity between pairs of observations, but how do we define the dissimilarity between two clusters if one or both of the clusters contains multiple observations? The concept of dissimilarity between a pair of observations needs to be extended to a pair of groups of groups of observations. This extensions is archived by developing the notion of linkage, which defines the dissimilarity between two groups of observations.\r\nThe five most common types of linkage are:\r\nSingle Linkage: The distance between two clusters is the minimum distance between any single data point from the first cluster with any single data point from the second cluster.\r\nWith d as a distance function\r\n\\[\\begin{equation}\r\n\r\n\\textit{l}_{SL}=min_{a\\in A,b\\in B}d(a,b) \\tag{1}\r\n\r\n\\end{equation}\\]\r\nBy applying Single linkage to the example data set the resulting dendogram is:\r\n\r\n\r\n\r\nFigure 3: Dendogram obtained by applying Single linkage to the example data set\r\n\r\n\r\n\r\nFrom Fig:3 it’s possible to notice how Single linkage can result in extended, trailing clusters in which single observations are fused one-at-a-time.\r\nComplete Linkage: The distance between two clusters is the maximum distance between any single data point from the first cluster with any single data point from the second cluster.\r\n\\[\\begin{equation}\r\n\r\n\\textit{l}_{CL}(A,B,d)=max_{a\\in A,b\\in B}d(a,b) \\tag{2}\r\n\r\n\\end{equation}\\]\r\nBy applying Complete linkage to the example data set the resulting dendogram is:\r\n\r\n\r\n\r\nFigure 4: Dendogram obtained by applying Complete linkage to the example data set\r\n\r\n\r\n\r\nClusters resulting from Complete linkage tend to have a spherical structure and are usually more compact.\r\nAverage Linkage: The distance between two clusters is the average distance between any single data point from the first cluster with any single data point from the second cluster.\r\n\\[\\begin{equation}\r\n\r\n\\textit{l}_{CL}(A,B,d)=\\frac{\\sum_{a\\in A,b\\in B}d(a,b)}{|A| \\cdot |B| } \\tag{3}\r\n\r\n\\end{equation}\\]\r\nBy applying Average linkage to the example data set the resulting dendogram is:\r\n\r\n\r\n\r\nFigure 5: Dendogram obtained by applying Average linkage to the example data set\r\n\r\n\r\n\r\nAs intuitively as it is, clusters resulting from Average linkage is a less “extreme” version of both Single and Complete linkage\r\nCentroid Linkage: The distance between two clusters is the distance between the two centroids/barycentre that are defined from the data points within respectively the first and second cluster.\r\nCentroid linkage can result in undesirable inversions, whereby two clusters are fused at a height below either of the individual clusters in the dendogram.\r\n\r\n\\[\\begin{equation}\r\n\r\n\\textit{l}_{Centroid}(A,B,d)= d(\\overline{x},\\overline{y}) \\tag{4}\r\n\r\n\\end{equation}\\]\r\nBy applying Average linkage to the example data set the resulting dendogram is:\r\n\r\n\r\n\r\nFigure 6: Dendogram obtained by applying Centroid linkage to the example data set\r\n\r\n\r\n\r\nFrom Fig:6 it’s possible to notice the inversion phenomenon that can occurs with Centroid linkage with as the clusters are fused at a height below either of the individuals clusters in the dendogram.\r\nWard’s Method: This method does not directly define a measure of distance between two points or clusters. It is an ANOVA based approach. One-way univariate ANOVAs are done for each variable with groups defined by the clusters at the stage of the process. At each stage, two clusters merge that provide the smallest increase in the combined error sum of squares. (We won’t try this method)\r\nThe choice of number of clusters with hierarchical clusters can be done the same way we did with K-Means (like wss or silhouette). A strength of hierarchical clustering is making the choice of k by being guided by the dendogram.\r\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are.\r\nSimilarly it’s possible to cut the dendogram and define k clusters. The height of the cut to the dendogram controls the number of clusters obtained. It plays the same role as the k in K-Means clustering. In order to identify sub-groups (i.e. clusters).\r\nFrom all the dendograms there is evidence that suggest choosing around 5 or 6 clusters is the optimal choice. Again, we will discuss later the ‘quality’ of this choice.\r\nDefining the problem\r\nUpping the game\r\nUp until now what has being described is the basic of the basic on clustering which could be found in any article/guide/course on the subject. What will follows is more akin as a self-explanation of points that could be worth to evaluate in order to approach the algorithm problem. Additional algorithms will be introduced with both their pros and cons. After describing all the applied algorithms we will at last explain the example used in this article to highlight what seems to be more interesting to explore for future analysis in the search of a way to define archetypes.\r\nLet us introduce a couple of point from a discussion with Drisoth and their effects:\r\n\r\n\r\nThe point of clustering is to increase sample size by being able to talk about a large section of decks in aggregate rather than each one individually. (Auhor Note: so using the existing data from played games) With that goal in mind, clustering off-meta decks with low sample size as noise is not a large loss of information, since even if we clustered similar decks together the cluster would still have too little data for any meaningful analysis to be done on it.\r\n\r\nFrom this approach three questions comes to mind:\r\nShould there exist outliers that’s best not to assign to a cluster?\r\nIf the question is formulated simply like that, with no other conditions, then yes, there is no deny that outliers and/or noise exists in the archetype problem and the best way to deal with them would be not assigning them to clusters.\r\nThe reason is obvious: it’s possible for a random pile of 40 cards to resemble an archetype, but, for the most cases it would likely turn into just that, a random pile of cards.\r\nTheir existence is certain, even worse many cluster algorithm are sensitive to noise and outliers and at various degree so are the methods described up until know. If K-Means starts on an outlier it won’t be easily dealt with, also a reason why it’s best practise to repeat K-Means several times to avoid being too depending on the original random choice at the initialization step. In (Agglomerative) Hierarchical Clustering (AHC), if an outlier is wrongly assigned to a cluster this error will be propagated on all the following steps with no way to intervene.3\r\nAmong the class of clustering algorithms that are able to deal with outliers and noise DBSCAN is probably the most popular and cited. The algorithm will be explained in the following paragraph.\r\nShould the data be weighted?\r\nWhile being developed only recently, the concept of a weighted clustering framework can be traced back into the ’70.  A more formal definition has has been developed while also introducing a series of mathematical properties related to the weights (Ackerman et al. 2016). The use of weights can be seen as a more generalized definition of centroid if not even just its description as barycentre also called centre of mass.\r\nIt is easy to see that using unweighed data can be seen as having the same weight 1 on all data. Applying weight would be the same as having duplicates as multiple points with mass would correspond to a single point with weight equal to the sum of masses. Similarly a point of zero mass can be seen as non-existent. From this, for many algorithms the consequence would be such as: instead of starting the iterative steps from the leafs, they would start from point-clusters of different masses.\r\nFollowing the definition of weighted clustering, one may ask what effect does this have on the clustering algorithms? (Ackerman et al. 2016) introduced the properties related to the response to weighted data\r\nBe it \\((X,d)\\) a dissimilarity function and \\(|range(A(X,d,k))|\\) the range of a partitional algorithm on a data set defined as the number of clusterings it outputs on that data over all weights functions:\r\nWeight Robust Algorithm A partitional algorithm \\(A\\) is weight-robust if for (X,d) and \\(1 < k < |X|\\) \\(|range(A(X,d,k))|=1\\). This means that the output of a weight robust algorithm is unaffected by the choice of weights\r\nWeight Sensitive Algorithm A partitional algorithm \\(A\\) is weight-sensitive if for (X,d) and \\(1 < k < |X|\\) \\(|range(A(X,d,k))|>1\\). This case imply that no matter the original data, the result can be changed in response of the use of weights. Even if we would like to use weights to guide our output this properties doesn’t seems desirables as we may want to not be too subjected to the weights. Of course it’s not like we can’t have the same results when applying different weights if the geometry of out data helps us. Yet, no matter the case we can’t be sure that the algorithm won’t be affected by the weights.\r\nWeight Considering Algorithm A partitional algorithm \\(A\\) is weight-considering if\r\n\\(\\exists\\) (X,d) and \\(1 < k < |X|\\) so that \\(|range(A(X,d,k))| = 1\\) and\r\n\\(\\exists\\) (X,d) and \\(1 < k < |X|\\) so that \\(|range(A(X,d,k))| > 1\\)\r\n\r\nWe took this detour of explaining how an algorithm can react to the addition of weights as we needed to point out that in some cases their inclusion doesn’t bring any difference to the results.\r\nAlso, while what we described was defined around duplicated (or weighted) data, this also apply to near-duplicated data.\r\nIn addition these properties can tell us a bit more of the algorithm in question.\r\nThe next figure gives an idea of what to expect for robust and sensitive cases.\r\nDifferent cluster structures based from the same data. All weight-sensitive methods select the clustering on the right while weight-robust methods select the one on the leftWe must remind how there is not correct partitioning, it all depends by the characteristics of each case study.\r\nWhat this example wants to convey is that if we know something of the underlying geometry of our data, and, what we would like our algorithm to favour, while there is no correct clustering we can still reduce a little “the user’s dilemma” of which algorithm to choose from.\r\nAmong the algorithms showed up until know Single linkage and Complete linkage are weight robust (and not many others more generally possess this property). Fig:7 shows an example with Single linkage\r\nWard and K-Means (as many other variant of the ‘k-family’) are weight sensitive and Average linkage is weight considering. Fig:8 shows an example with Average linkage. While only marginal, we can see the effect of applying weights on the second ‘main’ cluster.\r\n\r\n\r\n\r\nFigure 7: Dendogram obtained with unweighted and weighted using Single linkage with the example data set\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 8: Dendogram obtained with unweighted and weighted using Average linkage with the example data set\r\n\r\n\r\n\r\n\r\nSo remember kids, don’t try weighted data when applying Single-linkage at home (it’s useless)\r\n\r\n\r\n\r\n \r\n      Partional\r\n      Hiercarchical\r\n    Weight\r\nSensitive\r\nK-Means, k-medoids,k-median, Min-sum\r\nWard's Method, Bisecting K-MeansWeight\r\nConsidering\r\nRatio-cut\r\nAverage LinkageWeight\r\nRobust\r\nMin-diameter, k-center\r\nSingle/Complete LinkageA classification of clustering algorithms based on their response to weighted data.\r\n                  Source: Ackerman2016\r\n    \r\n\r\nIs there any other way to use the metagame data?\r\nThis question is more a result of seeing the Drisoth philosophy in a different way. Just because we want to be guided by the metagame in order to define archetypes doesn’t mean the weighting of data is the only option.\r\nFrom out perspective if we want to use the games data the reason is because we have a clear idea about what to expect from certain decks. From games we have an idea of what can identify a specific archetype, sometimes we may even have what is an ideal deck-list, a deck-list that is exemplar.\r\nThe easiest way to introduce this concept is by describing how it’s possible to use it starting from the K-Means algorithm.\r\nIn K-Means a cluster’s centre is defined by the centroid obtained from its points, aside for this they have no constraints about their position in the data space.\r\nIf we add the constraint that the centre must an actual data point the ‘centre’ is called examplars. The algorithm that can be defined by this change in K-Means is called K-medoids.\r\nK-Medoids only slightly differ from K-Means as:\r\nInstead of just computing the cluster’s centroid we find the existing data point whose average dissimilarity between it and all other members of the cluster is minimal.\r\nWe can use any distance to find the examplar.\r\nAn even more interesting approach is applied by a message-based cluster algorithm called Affinity Propagation.\r\nWhat is interesting about these methods is that they associate a real data point to each cluster. This open for a variety of decisions and quality-check options like being able to evaluate the quality of the identified clusters, checking the similarity within-cluster or differences between-clusters with a reduced number of points/references.\r\nAs it is more complex compared to K-Medoids, Affinity Propagation will be described in the next paragraph after DBSCAN.\r\nDBSCAN\r\nDBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a fairly recent algorithm as it was introduced in 1996 and it’s currently the most popular density-based method.\r\nDBSCAN uses two hyper-parameters to define the clusters:\r\nminPts: for a region to be considered dense, the minimum number of points required are minPts\r\neps: to locate data points in the neighbourhood of any points, eps \\(\\epsilon\\) is used a distance measure.\r\nFrom these parameters two concept are also introduced: Density Reachability and Density Connectivity\r\nReachability: in terms of density, establishes a point to be reachable from another if it lies within a particular distance \\(\\epsilon\\) from it. This property is not symmetrical\r\nConnectivity: on the other hand involves a transitivity based chaining-approach to determine whether points are located in a particular cluster.\r\nThis algorithms and concepts are based on the idea that clusters are defined by dense data space, dense with points and with other clusters being separated by region of low density.\r\nThis type of clustering algorithm connects data points that satisfy particular density criteria (minimum number of objects within a radius). After DBSCAN clustering is complete, there are three types of points: core,border,and noise.\r\nCore: is a point that has some (minPts) points within a particular \\(\\epsilon\\) distance from itself.\r\nBorder: is a point that has at least one core point at distance \\(\\epsilon\\).\r\nNoise: is a point that is nether border nor core. Data points in sparse area required to separate clusters are considered noise and broader points.\r\nThe algorithm proceeds as it follows:\r\nDBSCAN starts with a random data point (not-visited). Note: even if this step is randomized the algorithm is almost heuristic and robust to the initial choice.\r\nThe neighbourhood of this point is extracted using a distance \\(\\epsilon\\)\r\nIf there are sufficient data points within this area the current data point becomes the first point in the newest cluster, else, the point is marked as noise and visited.\r\nThe point within its \\(\\epsilon\\) distance neighbourhood also became a part of the same cluster for the first point in the new cluster. For all the new data points added to the cluster above, the procedure for making all the data points belong to the same cluster is repeated.\r\nThe above two steps are repeated until all points in the cluster are determined. All points within the \\(\\epsilon\\) neighbourhood of the cluster have been visited and labelled. Once we’re done with the current cluster, a new unvisited point is retrieved and processed, leading to further discovery of the cluster or noise. The procedure is repeated until all the data points are marked as visited.\r\nUsually to find the the value for \\(\\epsilon\\) we use the a plot of the k-nearest neighbour (kNN) distances for the dataset with all the distances being plotted from the smallest to largest.\r\nIn R, for the package ‘dbscan’ the heuristic method to find \\(\\epsilon\\) is a follows:\r\n\r\nA suitable neighborhood size parameter eps given a fixed value for minPts can be found visually by inspecting the kNNdistplot of the data using k = minPts -1 (minPts includes the point itself, while the k-nearest neighbors distance does not). The k-nearest neighbor distance plot sorts all data points by their k-nearest neighbor distance. A sudden increase of the kNN distance (a knee) indicates that the points to the right are most likely outliers. Choose eps for DBSCAN where the knee is.\r\n\r\nSince the example data set data is quite small we will assign minPts=2 and so using k=1\r\n\r\n\r\n\r\nWe will do the clustering with \\(\\epsilon\\)=0.2775 and using both the cosine similarity.\r\nIn addition we will replicate a previously used methodology by Drisoth by choosing the Manhattan distance and \\(\\epsilon\\)=37 (40-3 ‘cards’ similarity)4\r\n\r\n\r\n\r\n\r\n\r\n\r\nWhen applied to the example data set we get:\r\n\r\nDBSCAN clustering for 50 objects.\r\nParameters: eps = 0.2775, minPts = 2\r\nThe clustering contains 5 cluster(s) and 2 noise points.\r\n\r\n 0  1  2  3  4  5 \r\n 2 10 10 10 10  8 \r\n\r\nAvailable fields: cluster, eps, minPts\r\n\r\nDBSCAN with the cosine similarity, \\(\\epsilon\\)=0.2775 and minPts=2 return 5 cluster with 2 noise points\r\n\r\nDBSCAN clustering for 50 objects.\r\nParameters: eps = 37, minPts = 2\r\nThe clustering contains 5 cluster(s) and 1 noise points.\r\n\r\n 0  1  2  3  4  5 \r\n 1 10 10 10 10  9 \r\n\r\nAvailable fields: cluster, eps, minPts\r\n\r\nDBSCAN with the Manhattan distance, \\(\\epsilon\\)=0.2775 and minPts=2 returns again 5 clusters but only 1 noise point\r\nDoes DBSCAN scale well?\r\nIn this article we introduced the problem of a lack of consideration of a clustering properties in order to decide which clustering algorithm to apply to our data set.\r\nA series of weight-related properties were introduced to make us aware how some algorithms can be influenced or not by weighted data.\r\nMore generally it’s possible to define a wide series of clustering methods properties Ackerman and Ben-David (2011). Among them there is property that we believe should be present for any clustering methods we are planning to use for the archetype problem: Locality\r\n\r\n\\(\\forall\\) domain (X,d) and number clusters, k, if X’ is the union of k’ clusters in F(X,d,k) for some k’ \\(\\leq\\) k then, applying F to (X’,d) and asking for a k’-clustering, will yield the same clusters that started with\r\n\r\nIt is pretty clear why we wants this property. It we cluster a subset of an archetype, we should still get the a result consistent with the same archetype.\r\nWe wondered if this property is satisfied by DBSCAN because of the minPts hyper-parameter and if its value would be able to determine different results with the same setting.\r\nWe can say that DBSCAN satisfy this property. This is easily proved by the existence of the DBSCAN extension HDBSCAN which convert DBSCAN into an hierarchical algorithm. Because of HDBSCAN we can then use the following lemma introduced by Ackerman (Ackerman and Ben-David 2011):\r\nWhat is the linkage method applied by DBSCAN? Simple-linkage. In fact, DBSCAN search the the minPts at a \\(\\epsilon\\) distance which is a more constrained use of single-linkage.\r\nWe can also point that locality specify that the sub-set in made of k’ clusters so it exclude the choice of picking a subset of a mixture of noise points and a partial subset of a cluster. Because of this we know that the cluster will satisfy again the definition of cluster by DBSCAN allowing locality to be satisfied.\r\n\r\nTLDR: DBSCAN is a fine good as an algorithm to define archetypes. It may have other reasons to make us not completely sure about using this algorithm but this key property is satisfied.\r\n\r\nK-Medoids (results)\r\nWe report the results in seeking the optimal number of clusters using K-Medoid using two different metric, the Manhattan distance (or L1 distance) and the Cosine similarity to the example data set.\r\nAs with the other methods the results will be discussed at the end of the article.\r\n\r\n\r\n\r\nFigure 9: within sum of squares as a fnction of number of clusters obtained with K-medoids and manhattan & cosine metric applyed to the example data set\r\n\r\n\r\n\r\nAffinity Propagation Clustering\r\nAffinity Propagation Clustering (APcluster) is a fairly recently introduced clustering methods Frey and Dueck (2007).\r\nIt is based on the passage of messages between data points to detect patterns in data.\r\nAs K-Medoids it uses examplars data point.\r\nTwo messages are exchanged between data points:\r\nResponsibility r(i,k) is sent from i to k and correspond to the accumulated evidence for how well-suited k is to server as the examplar for i, taking into account other potential exemplars for point i\r\nAvailability a(i,k) is sent from k to i and correspond to the accumulated evidence for how appropriate it is for i to choose k as its examplar, taking into account the support from other points that point k should be examplar\r\nThe iteration steps updates the following values:\r\n\\(R(i,k) \\leftarrow S(i,k) - max_{k' \\neq k}(A(i,k')+S(i,k'))\\)\r\n\\(A(i,k) \\leftarrow min{(0,R(k,k')+\\sum_{j \\notin {i,k}}max(0,R(j,k) ) )}\\)\r\n\\(A(k,k) \\leftarrow max_{j \\neq k}(0,R(j,k))\\)\r\nThe examplar are chosen as the point from whom responsibility+availability for themselves is positive \\(r(i,i)+a(i,i)>0\\)\r\nS(i,k) is the similarity matrix we provide which doesn’t even need to satisfy the usual metric property, not only it doesn’t have to satisfy the triangular inequality but it doesn’t even need to be symmetric.\r\nIn this example we will use the similarity matrix provided by the application of the cosine similarity. What follows in the heatmap obtained by applying APcluster to the example data set.\r\n\r\n\r\n\r\n\r\nFigure 10: Heatmap obtained by applying APcluster to the example data set\r\n\r\n\r\n\r\nSimilarly to most of the other methods, the algorithm is suggesting us the presence of 5 archetypes with one of them being a little less homogeneous compared to the other 4.\r\nAs we finally showed all the algorithm we planned to introduce and explain, we can finally describe the data set used an show more in the detail the results we had.\r\nData\r\nThe example used in this article is made out of 50 decks.\r\nFive archetypes with different regions & different play style have been selected as ‘core’\r\nAshe/LeBlanc\r\nAzir/Irelia\r\nDragons (DE/MT)\r\nDraven/Sion (NX/PZ)\r\nMistwraith Alligiance\r\n\r\nDoes this mean that the correct answer of k-cluster we should have expected was 5? Well… not necessarily, there is in fact a catch that I didn’t mention. Among the ‘archetypes’ I also selected some of their sub-archetypes.\r\nTo help explain what I actually choose I’ll also report the code I used to sample the deck-lists.\r\n\r\n\r\n# how I selected the decks, it is reproducible as more decks will be inserted in the DB\r\n\r\n#' archetypes names\r\narchetypes <- c( \r\n  \"Ashe/LeBlanc\",           # 75/25 noMarauder/Marauder\r\n  \"Azir/Irelia\",            # 100\r\n  \"Dragons (DE/MT)\",        # 30/70 J4/PureDrake \"Aurelion Sol/Jarvan IV/Shyvana\",  \"Aurelion Sol/Shyvana\",\r\n  \"Draven/Sion (NX/PZ)\",    # 80/20 DravenSion/RubinBait\r\n  \"Mistwraith Allegiance\"   # 50/50 Targon/Piltover\r\n)\r\n\r\n#' sampling a bigger number of decks for a bigger example I ended up not using\r\nset.seed(123)\r\nRep1 <- LoR.Deck.RMD |>\r\n  filter( archetype == \"Ashe/LeBlanc\" & is.na(archetype_pretty) ) |>\r\n  slice_sample(n = 75) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nRep2 <- LoR.Deck.RMD |>\r\n  filter( archetype_pretty == \"Marauder\" ) |>\r\n  slice_sample(n = 25) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nAI <- LoR.Deck.RMD |>\r\n  filter( archetype == \"Azir/Irelia\", ) |>\r\n  slice_sample(n = 100) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nDragon1 <- LoR.Deck.RMD |>\r\n  filter( archetype == \"Aurelion Sol/Jarvan IV/Shyvana\" ) |>\r\n  slice_sample(n = 30) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nDragon2 <- LoR.Deck.RMD |>\r\n  filter( archetype == \"Aurelion Sol/Shyvana\" ) |>\r\n  slice_sample(n = 70) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nSion1 <- LoR.Deck.RMD |>\r\n  filter( archetype == \"Draven/Sion (NX/PZ)\" & is.na(archetype_pretty) ) |>\r\n  slice_sample(n = 80) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nSion2 <- LoR.Deck.RMD |>\r\n  filter( archetype_pretty == \"RubinBait - Draven/Sion\", ) |>\r\n  slice_sample(n = 20) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nMist1 <- LoR.Deck.RMD |>\r\n  filter( archetype_pretty == \"Mistwraith Allegiance\" & str_detect(factions,\"Targon\") ) |>\r\n  slice_sample(n = 50) |>\r\n  pull(deck_code)\r\n\r\nset.seed(123)\r\nMist2 <- LoR.Deck.RMD |>\r\n  filter( archetype_pretty == \"Mistwraith Allegiance\" & str_detect(factions,\"Piltover\") ) |>\r\n  slice_sample(n = 50) |>\r\n  pull(deck_code)\r\n\r\n#' sub-sampling the decks I ended up not using\r\nLoR.Archetype.Ex <- rbind(\r\n  LoR.Deck.RMD[ deck_code %in% Rep1, ],\r\n  LoR.Deck.RMD[ deck_code %in% Rep2, ],\r\n  LoR.Deck.RMD[ deck_code %in% AI, ],\r\n  LoR.Deck.RMD[ deck_code %in% Dragon1, ],\r\n  LoR.Deck.RMD[ deck_code %in% Dragon2, ],\r\n  LoR.Deck.RMD[ deck_code %in% Sion1, ],\r\n  LoR.Deck.RMD[ deck_code %in% Sion2, ],\r\n  LoR.Deck.RMD[ deck_code %in% Mist1, ],\r\n  LoR.Deck.RMD[ deck_code %in% Mist2, ]\r\n)\r\n  \r\nmini.ex <- c(Rep1[1:7], # Ashe/LB\r\n             Rep2[1:3], # Marauder\r\n             AI[1:10],  # AI\r\n             Dragon1[1:3], # with J4\r\n             Dragon2[1:7], # no J4\r\n             Sion1[1:8],   # OG\r\n             Sion2[1:2],   # fake-burn\r\n             Mist1[1:5],   # MT\r\n             Mist2[1:5])   # PnZ\r\n\r\n\r\n\r\n\r\n\r\n\r\nSo if I had to better specify what the sample contains:\r\nFive archetypes with different regions & different play style have been selected as ‘core.’ Almost all archetypes contains some variants of the same decks\r\nAshe/LeBlanc\r\n7 decks of ‘standard’ Ashe/LB\r\n3 decks of the ‘Marauder’ variant which is defined by playing 3 copies of Strength in Numbers in a Freljord/Noxus deck. No Ashe/LB could be sampled from this subgroup\r\nAzir/Irelia\r\n10 decks of Azir/Irelia\r\nDragons (DE/MT)\r\n3 decks with at least Jarvan IV/Shyvana/Aureion Sol\r\n7 decks with at least Shyvana/Aureion Sol (but no Jarvan IV)\r\nDraven/Sion (NX/PZ)\r\n8 decks of ‘standard’ Draven/Sion\r\n2 decks of the Rubin-Bait variant\r\nMistwraith Alligiance - Mistwraith Alligiance decks are defined by having 3 copies Mistwraith and overall 37 SI cards\r\n5 decks of a Mistwraith decks with Mount Targon and 3 copies of Pale Cascade\r\n5 decks of a Mistwraith decks with PnZ and 3 copies of Iterative Improvements\r\n\r\nSomething that I want to highlight of the Mistwraith decks is that the option for the champions of choice was completely free. In this archetype after all the champions plays a marginal role to the deck’s strategy. The following table shows the champions combination’s distribution.\r\n\r\n\r\narchetype\r\n      n\r\n      percent\r\n    Elise/Kalista (MT/SI)\r\n4\r\n0.4Elise/Kalista (PZ/SI)\r\n2\r\n0.2Kalista (PZ/SI)\r\n2\r\n0.2Kalista/Nocturne (MT/SI)\r\n1\r\n0.1Viego (PZ/SI)\r\n1\r\n0.1\r\n\r\nThe Mistwraith example could be said it was key for why and how I want to approach the archetype problem. SI is probably the region who is less tied by its champions per se. Thresh is more an exception but for example Kallista and Elise are included in a wide variety of decks that cannot be identified simply by their use.\r\nIn addition to the ‘champions problem’ the Mistwraith has the additional problem of being the first archetype to this is not bound by the regions it use. As of now Bandle expanded this concept with a variety of BandleTree Decks, but Mistwraith was the OG case.\r\nResuls\r\nK-Means\r\n\r\n\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\nDragons\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons+J4\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion\r\n\r\n\r\n8\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMarauder\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(MT)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(PnZ)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nRubinBait-Sion\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n7\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons+J4\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n8\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMarauder\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(MT)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\nMistwraith(PnZ)\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\nRubinBait-Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nWe can see why the K-Means wasn’t returning 5 as the number of suggested clusters as the other methods, because it was more prone to notice the differences between the Reputation decks and the SI Mistwraith decks. Strangely enough it doesn’t seems to notice the differences between the Sion decks.\r\nHierachical Clustering\r\nWe report only the results with Average-linkage as we don’t have reasons to suggest out data would work well with Single/Complete linkage and we showed that these choice would impact the results in many ways. So we opt for Average-linkage as it is a compromise of most methods.\r\n\r\n\r\n\r\nWith the hierarchical clustering we have can not only how clearly the method grouped the archetypes but the similarities between the groups and how some archetypes may suggest the presence of sub-archetypes similarly by how we choose them, at least for Dragons and Sion. As Mistwraith decks contain an higher range in similarity cutting the dendogram in more than 5 archetypes would first and foremost identify the differences in SI decks.\r\nOverall the methods can provide a useful tool to explore the cluster but suffer from the fact that it doesn’t scale well at the increase of sample size, not just in term of memory/cost but as how to find a proper level to cut the tree.\r\nK-Medoid\r\nThe K-Medoid applied with 5 cluster had the same results of all the other methods but differently from the other it was able to identify a couple of the Marauder decks when he used 7 clusters. As the more interesting result, we will report the one with 7 cluster.\r\n\r\n\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n7\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons+J4\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n8\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMarauder\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(MT)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(PnZ)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n4\r\n\r\n\r\n1\r\n\r\n\r\nRubinBait-Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nWith K-Medoids the algorithm also provide the examplars that identified correctly most (2/3) of the Marauder decks and assigned the Mistwraith-Viego deck to its own cluster.\r\n\r\n\r\narchetype\r\n      archetype.v2\r\n      deck_code\r\n    Ashe/LeBlanc\r\nAshe/LB\r\nCMCACAYBAIBACAY7EEBAIAYCAQCACAILEYUTAAQCAEBQINIDAEAQCFRKAIAQCAZTAIAQCBA6Ashe/LeBlanc/Sejuani\r\nMarauder\r\nCECACAYBAIBAIAYCCEBQCAYECUPQIAIBAMFR4JQEAEAQCAIBAEBTKAIEAEFACBADAQBACAIBFIAQEAICAzir/Irelia\r\nAzir/Irelia\r\nCMCACAYCAUBACAQGFIBQIBYDDIZQIBACAQCQSDYCAECAECYCAQDTSXIEAEBAECQBAMBBIAIEAIDQCBAHDQAurelion Sol/Shyvana\r\nDragons\r\nCICACAIADIBAIAAOCQCAGAAGBAFQ4BADBEBQ4V3EAIAQEAABAECASBACAEAQABYCAMEVIVIDraven/Sion (NX/PZ)\r\nDragon/Sion\r\nCECQCAIDCQAQGBASAECAIEADAUBQCCINAQAQIJRHFU2AIAIBAMXACAIEAEAQGAYPAECQGBQCAEAQGCYBAUBQIElise/Kalista (MT/SI)\r\nMistwraith\r\nCMBQCAYJEMCAGBIDAQDA2CABAUBQ4EA6E4YTKOAAAEAQCBIWViego (PZ/SI)\r\nMistwraith\r\nCECACAYEBUAQGBINAMCAKNJWG4CQCBIOCAUC4NQBAUAQKAITDERC6AA\r\n\r\nDBSCAN\r\nAs DBSCAN also introduce noise points we want to check which points have been assigned as such.\r\nNot surprisingly the noise was found in the Mistwraith decks always including as noise the ‘Viego’ variant. With DBSCAN we have to remember it could be wiser to test for a wider range of hyper-parameters minPts and \\(\\epsilon\\).\r\nYet, the main cons of this method is exactly how to define minPts, especially if we used a bigger/real dataset as we have no idea about the distribution of the archetypes lists.\r\nOverall this method can be a valuable source to check for outliers in the archetypes list but we are not sure its definition of noise of appropriate for the archetype problem.\r\n\r\n\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n0\r\n\r\n\r\n9\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAshe/LeBlanc/Sejuani\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAurelion Sol/Jarvan IV/Shyvana\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAurelion Sol/Shyvana\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion (NX/PZ)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\nElise/Kalista (MT/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n4\r\n\r\n\r\nElise/Kalista (PZ/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\nKalista (PZ/SI)\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nKalista/Nocturne (MT/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nViego (PZ/SI)\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n0\r\n\r\n\r\n9\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAshe/LeBlanc/Sejuani\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAurelion Sol/Jarvan IV/Shyvana\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAurelion Sol/Shyvana\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion (NX/PZ)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\nElise/Kalista (MT/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n4\r\n\r\n\r\nElise/Kalista (PZ/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\nKalista (PZ/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\nKalista/Nocturne (MT/SI)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n1\r\n\r\n\r\nViego (PZ/SI)\r\n\r\n\r\n1\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nLastly, when considering DBSCAN there is a monumental reason why the method may be not yet appropriate to use.\r\nAs described DBSCAN is based on the idea if clusters separated by region with different density of data points. As of now we are not sure if the archetype problem can truly satisfy this requirement as the card pool in Legends of Runeterra is extremely limited compared to counterparts like Magic: the Gathering or Yu-Gi-Oh.\r\nAPcluster\r\nLastly the APcluster algorithm\r\n\r\n\r\n\r\n\r\n7\r\n\r\n\r\n17\r\n\r\n\r\n28\r\n\r\n\r\n36\r\n\r\n\r\n48\r\n\r\n\r\nAshe/LeBlanc\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nAzir/Irelia\r\n\r\n\r\n0\r\n\r\n\r\n10\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n7\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDragons+J4\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nDraven/Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n8\r\n\r\n\r\n0\r\n\r\n\r\nMarauder\r\n\r\n\r\n3\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\nMistwraith(MT)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\nMistwraith(PnZ)\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n5\r\n\r\n\r\nRubinBait-Sion\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n0\r\n\r\n\r\n2\r\n\r\n\r\n0\r\n\r\n\r\nThe column names refers to the id of the examplars chosen to represent the archetype\r\n\r\n\r\n\r\n(#fig:heat-apcluster.v2)Heatmap with labels obtained by applying APcluster to the example data set\r\n\r\n\r\n\r\nAs now it could be expected the ‘less homogeneous’ cluster was the one from Mistwraith decks.\r\nIf we wanted we can apply an agglomerative clustering on top of AP clustering.\r\n\r\n\r\n\r\nFigure 11: Dendogram obtained by applying APcluster to the example data set\r\n\r\n\r\n\r\nAnd lastly as K-Medoid we can see the examplars provided by the algorithm\r\n\r\n\r\narchetype\r\n      archetype.v2\r\n      deck_code\r\n    Ashe/LeBlanc\r\nAshe/LB\r\nCEBQEAIDAQPQEBADAICAMAIBAECAWHRGGABQCAIBFEAQGAICAIAQGIJVAEBAIAYIB4Azir/Irelia\r\nAzir/Irelia\r\nCMBQCAICFICAIBYDDIZTSBIEAICAKCILB4BQCAQCBIAQGAQUAIAQEBRMAEBAIB25PEAurelion Sol/Shyvana\r\nDragons\r\nCICACAIADIBAGCIOK4BAIAAOCQCAGAAGBAFQ4AYBAEAA6AICAAAQIAYJANKVYZABAEAQABYDraven/Sion (NX/PZ)\r\nDragon/Sion\r\nCECQCAIDCQAQGBASAECAIEADAUBQCCINAQAQIJRHFU2AIAIBAMXACAIEAEAQGAYPAECQGBQCAEAQGCYBAUBQIElise/Kalista (PZ/SI)\r\nMistwraith\r\nCEBQCAYEBUBAGBIGBUEACBIDBYIB4JZIGU4AEAIBAUYQEAYFAMCACAIBAUHQ\r\n\r\nAgain, the Burn variant of Draven/Sion looks way confounded in its own archetype, the remaining results are similar to the other methods. The results could overall be more optimized of affinity propagation clustering is an extremely flexible method but we lack for now experience with it.\r\nConclusion\r\nClustering is truly a wide and troublesome (and fascinating) domain. As there is no clear definition about how to define an archetype in Legends of Runeterra finding an appropriate approach to classify them based on clustering analysis is no easy task.\r\nWhile most cluster algorithm used in this articles were able to differentiate for the macro-archetypes selected for this example the example of Draven/Sion decks shows that some variant that is recognized by the community as a different deck.\r\nA better definition of the problem seems to be crucial in order to approach the archetype problem as, as of now it mostly relies on intuition and shared agreements about how to consider certain decks.\r\nEven if the results did agreed for the most part among all the algorithm the degree of freedom left to the user that could hinder the results has to be taken into account for which methods are worth exploring with bigger/real examples. K-Means is the method that overall we would consider the worst as it’s affect by the randomized initialisation step, the choice of k-cluster that is guided ‘not as good’ as the methods that can provide dendograms or exemplars to further explore the choices and results. K-Medoids while a more robust version of K-Means still suffer from the initialisation step. Hierarchical clustering another basic clustering algorithm is a promising option to check for possible sub-archetypes or differences within cluster. The main concern is the scale with bigger data-set as the required dissimilarity matrix has a quadratic increase of the sample size.\r\n\r\n\r\n\r\nLegal bla bla\r\nThis content was created under Riot Games’ “Legal Jibber Jabber” policy using assets owned by Riot Games. Riot Games does not endorse or sponsor this project.\r\n\r\n\r\n\r\nAckerman, Margareta, and Shai Ben-David. 2011. “Discerning Linkage-Based Algorithms Among Hierarchical Clustering Methods.” In Twenty-Second International Joint Conference on Artificial Intelligence.\r\n\r\n\r\nAckerman, Margareta, Shai Ben-David, Simina Brânzei, and David Loker. 2016. “Weighted Clustering.” http://arxiv.org/abs/1109.1844.\r\n\r\n\r\nAckerman, Margareta, Shai Ben-David, and David Loker. 2010. “Towards Property-Based Classification of Clustering Paradigms.” Advances in Neural Information Processing Systems 23: 10–18.\r\n\r\n\r\nFrey, Brendan J, and Delbert Dueck. 2007. “Clustering by Passing Messages Between Data Points.” Science 315 (5814): 972–76.\r\n\r\n\r\nas we use a sparse matrix that contain the number of copies for each card, so with possible value \\([0,3] \\in \\mathbb{N}\\), in this example, no it’s not necessary to standardize↩︎\r\nNot exactly: for k = n the wss is not even defined as it’s not possible to define variance for n=1.↩︎\r\nThis behaviour allows AHC to more easily identify smaller clusters. In contrast, Divisive Hierarchical clustering is more robust to noise and outliers.↩︎\r\nI’m sorry to say I wasn’t clear in the first draft that \\(\\epsilon\\) wasn’t the same after using a different metric. Let me also add that trying to use the elbow method with the manhattan distance proved to be quite ineffective and the ‘logical’ choice of 3 cards differences worked much better.↩︎\r\n",
    "preview": "analysis/defining-archetypes-02/defining-archetypes-02_files/figure-html5/heat-apcluster-1.png",
    "last_modified": "2021-10-31T13:50:44+01:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "analysis/lmi-02-tentative-expansion/",
    "title": "LoR Meta Index (LMI) expansion by using Bo3 data",
    "description": "The LMI is limited in its current setting as it uses only playrates and win-rates. By using Bo3 data we propose a way to expand the LMI with a ban-index",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-09-21",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nData\r\nMethods\r\nComposite Indicators - A Better Introduction\r\nThe LMI Composite Indicator\r\nBase LMI\r\nAdding Banrate Information\r\n\r\nStatistical Analysis\r\nCorrelation\r\nWeigths\r\n\r\n\r\nResults\r\nConclusions\r\nAppendix\r\nLegal bla bla\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nComposite Indicators (CI) are a quantitative measure that aggregate multi-dimensional data into a single index. Differently from other aggregation methods as Principal Components Analysis (PCA) or Factorial Analysis (FA) they are not entirely data driven and they are compiled in order to communicate a concept. Mostly used in social or policy evaluation, they allows for a single and direct comparison between their units. Gamers commonly and intuitively use this tool when talking about tier list. In a card game like Hearthstone (HS) a simple but known example of CI is the Meta Score from viciousSyndicate (vS).\r\nIn Legends of Runeterra (LoR) we created a similar CI defined as LoR-Meta-Index (LMI)1. The index didn’t just try to replicate the vS Meta Score but tried to adjust it to the LoR data and its differences from HS. A limitation of the proposed index is it’s composed by only two variables: play-rates and win-rates. While they are the most important variables of performance of a deck, they don’t fully catch the complexities on the meta-game performances. This can be solved by adding other variables to the index and a natural candidate is the ban-rate of a deck (in a contest of BoX matches).\r\nAn experiment to add the ban-rate was done earlier this year, for ‘Rise of the Underworld - Seasonal Tournament’ report2.\r\nThe inclusion of such variable, was done without checking all the proper steps so that we wouldn’t compromise the quality of the CI. In this article we introduce in more detail the concept and framework of a CI and how to add the the information of the ban rates and their results.\r\nFollowing the necessary steps, the proposed variation of the LMI partially contradicts the expected theoretical-framework requiring an higher level of complexity to reach the aimed .\r\nData\r\nData are taken from the Seasonal tournaments ‘Guardian of the Ancient’ and ‘Rise of the Underworld’ Open Rounds.\r\nThe Open Rounds are the are organized in a series of nine Bo3 Matches with open lists and a ban phase before the start of the games. The smaller amount of games from the Asian shard/server is allegedly because of the fewer players taking part of it3\r\nNot all information about the tournament can be derived from the API. There is no direct data about the chosen ban deck or the entire line-up brought by a player at this have to be extracted by aggregating the metadata of games from a single match and all matches played during that day.\r\nWe only consider the decks that appears in the cases of a full-line-up and whose we can extrapolate the banned deck.\r\nTo evaluate win-rates on the ladder, as additional source, we includes Ranked games from Master players (at least one of the two players being Master) from up to two weeks before the start of the first game of the Seasonal (because of the time zone, two weeks, before the start of the Asian Seasonal).\r\n\r\n\r\nBo3 Data\r\n    Matches by Server\r\n    Characteristic\r\n      Seasonal - Guardian of the Ancient, N = 20,6371\r\n      Seasonal - Rise of the Underworld, N = 20,5111\r\n    server\r\n\r\namericas\r\n9,126 (44%)\r\n9,018 (44%)asia\r\n2,457 (12%)\r\n2,421 (12%)europe\r\n9,054 (44%)\r\n9,072 (44%)Bo3 Data from Seasonal Open Rounds - Rise of the Underworld Open Rounds Matches - games extracted with Riot API\r\n    \r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n      \r\n    \r\n\r\nExample and part of the raw-data used can be found in Appendix ??)\r\nMethods\r\nComposite Indicators - A Better Introduction\r\nThe LMI is a composite indicator (CI) and in a previous article we introduced the tool we gave a brief explanation about how to create them. Here, we want to give a better and more complete overview of the tool.\r\nFor a manual on CI, a commonly referred guide is from the Joint Research Centre (JRC) of the European Commission: Handbook on Constructing Composite Indicators - METHODOLOGY AND USER GUIDE. In that guide building a composite indicator requires the following 10 steps:\r\nTheoretical Framework\r\n\r\nProvide the basis for the selection and combination of variables into a meaningful composite indicator under a fitness-for-porpuse principle (involment of experts and stakeholders is envisaged at this step)\r\n\r\nWhat is the concept that the CI wants to convey? Of what characteristics is it made and what variable can express them? This steps is all about setting the definition of what needs to be created.\r\nData selection\r\n\r\nShould be based on the analytical soundness, measurability, coverage and relevance of the indicators to the phenomenon being measured and relationship to each other. The use of proxy variables should be considered when data are scarce (involvement of experts and stakeholders is envisaged at this step)\r\n\r\nWhen defining the CI structure there is also the need to maintain a coherent structure. This means, among other, that values in the same sub-dimension should all follows the same direction. In an increase of a variable imply an increase in the final value of the sub-dimension index then all the other variables should be same.\r\nExample: if we have a sub-dimension index related to “quality of life” containing life expectancy and child mortality, the higher the value of life expectancy the better and higher the final index should be. But, for the values of child mortality it is the opposite, the smaller the value, the better it is. In this case it’s not a problem as a common practise is to just use the opposite values by changing the sign as it is a linear transformation and the smaller the value of child mortality (with opposite sign) the better it is in evalutating “quality of life”.\r\nThe ‘polarity’ of an individual indicator is the sign of the relation between the indicator and the concept to be measured. For example, in the case of well-being, “Life expectancy” has positive polarity, whereas “Unemployment rate” has negative polarity. I\r\nImputation of missing data\r\n\r\nIs needed in order to provide a complete dataset (e.g by means or multiple imputation).\r\n\r\nIn the real world rarely the available data are complete (and this article is no exception). If the missing value are MCAR (Missing Completely At Random) then there would be no problem to just remove the rows with missing values but this is not always the case and sometimes we can’t just remove units as they too important and so we must try to impute the missing values without compromising the end results or estimate these values to be as near as possible as what we would have obtain as the “true” value (not compromising the quality and trying to estimate the best imputation are not the same problem).\r\nDealing with outliers is also part of this step. In our case it’s related to the minimum amount of games to require to a deck.\r\nMultivariate analysis\r\n\r\nShould be used to study the overall structure of the dataset, assess its suitability, and guide subsequent methodological choices (e.g. weighting aggregation).\r\n\r\nSometimes the framework is not enough to guide our decision and variables may actually behave differently from our exceptions. This step is about checking the underlying structure of the data, helps identify groups and evaluate statistically evaluated structure of the data set to the theoretical framework and discuss potential differences.\r\nIn this article this will be done when looking at the correlations among our variables.\r\nNormalization\r\n\r\nShould be carried out to render the variables comparable\r\n\r\nAs this steps was invested with care in the previous article, we will maintain the choice for using a quantile normalization for our data.\r\nWhile it’s possible to use different normalization for the same CI at different groups of variables, it’s not a recommended practise.\r\nWeighting and aggregation\r\n\r\nShould be done along the lines of the underying theoretical framework\r\n\r\nThis steps mostly intertwined with the the Multivariate analysis as it can highlight\r\nLike the normalization step, this step too was was invested with care in the previous article and we will maintain the choice for using an harmonic mean when aggregating our data. It is possible to use different aggregation method for the same CI if it’s justified (like for compensability)\r\nUncertainty and sensitivity analysis\r\n\r\nShould be undertaken to assess the robustness of the composite indicator in terms of e.g. the mechanism for indulging or excluding an indicator, the normalization scheme, the imputation of missing data, the choice, the choice of weights, the aggregation method\r\n\r\nThis is an highly complex step that will be left for future articles.\r\nBack to the data\r\n\r\nIs needed to reveal the main drivers for an overall good or bad performance. Trasparency is promordial to good analysis\r\n\r\nAs it can be done better with the results of a uncertainty and sensitivity analysis, this steps too will be left for the future.\r\nLinks to other indicators\r\n\r\nShould be made to correlate the composite indicator (or its dimension) with existing (simple or composite) indicators as well as to identify linkages through regressions.\r\n\r\nThis can be done when comparing the result of Balco’s Meta-Score which applies the same algorithm by vS but is not part of this article as we would also include the opinion of third-party experts (some high level players) to evaluate the different CI performances.\r\nVisualization of the results\r\n\r\nShould receive proper attention, given that the visualization can influence (or help to enhance interpretability)\r\n\r\nWhile not the only choice we will maintain for now the same plot strcture used up until now in the meta-reports and the previous LMI article.\r\nWhen creating for the first time a CI these 10 steps aren’t done in a strict sequential order, so in this article we will sometimes return to what is are previous steps compared to the one we are mainly referring in a section of the article.\r\nThe LMI Composite Indicator\r\nBase LMI\r\nThe basic LMI is made by aggregating play-rates and win-rates and its creation was was inspired by seeing the meta score on vS.\r\nWhile the base raw data are from the same concept, they are combined in a different way.\r\nFrom their F.A.Q.\r\n\r\nQ: What is the meaning of the Meta Score and how do you compute it?\r\nThe Meta Score is a supplementary metric that measures each archetype’s relative standing in the meta, based on both win rate and prevalence, and in comparison to the theoretical “best deck”.\r\nHow is it computed?\r\n…\r\nWe take the highest win rate recorded by a current archetype in a specific rank group, and set it to a fixed value of 100. We then determine the fixed value of 0 by deducting the highest win rate from 100%. For example, if the highest win rate recorded is 53%, a win rate of 47% will be set as the fixed value of 0. This is a deck’s Power Score. The range of 47% – 53%, whose power score ranges from 0 to 100, will contain “viable” decks. The length of this range will vary depending on the current state of the meta. Needless to say, it is possible for a deck to have a negative power score, but it can never have a power score that exceeds 100.\r\nWe take the highest frequency recorded by a current archetype in a specific rank group, and set it to a fixed value of 100. The fixed value of 0 will then always be 0% popularity. This is a deck’s Frequency Score. A deck’s frequency score cannot be a negative number.\r\nWe calculate the simple average of a deck’s Power Score and Frequency Score to find its vS Meta Score. The vS Meta Score is a deck’s relative distance to the hypothetical strongest deck in the game. Think of Power Score and Frequency Score as the coordinates (x, y) of a deck within a Scatter Plot. The Meta Score represents its relative placement in the plane between the fixed values of (0, 0) and (100,100).\r\nIf a deck records both the highest popularity and the highest win rate, its Meta Score will be 100. It will be, undoubtedly, the best deck in the game.\r\n\r\nWhile for the LMI:\r\nOnly decks with at least 200 games are considered. A similar filter is most likely being applied by vS too, we just don’t know the values for the cut-off\r\nPlay-rates and win-rates are normalized with a quantile normalization into a Freq-Index and a Win-Index\r\nFreq-Index and a Win-Index are aggregated by an harmonic mean of equal weights into the LMI\r\nThe reasoning behind these choices compared to other options can be found in the LMI - early concept article.\r\nAdding Banrate Information\r\nAs the number of variables increase from the two of the base-LMI to three we now have more options as to combine them. Normally, this doesn’t mean that each possible choice should be evaluated, the definition we want to communicate should guide our choices and so the characteristics of our variables, e.g. we don’t add a variable of Life expectancy in a sub-dimension of ‘Infrastructure quality’\r\nWhen creating the LMI we described it as a measure of performance of a deck and as definition of performance of a deck as:\r\n\r\nThe performance of a deck is defined by its own strength and popularity inside the metagame.\r\n\r\nThe definition of performance is probably not be as functional as it should as it seems a bit limiting in what it means. Yet, the term performance still remains appropriate.\r\nWhat information can be added to the index? An easy inspiration can be taken from Riot’s main games: League of Legends (LoL)\r\nIn LoL a common value to describe the performance of a champion, in in addition to play-rates and win-rates is the ban-rate of a champion.\r\nThe most infamous value of the ban-rate was 95% ban-rate of Kassadin in S3. If we consider the definition of performance given earlier we can see that the ban-rate doesn’t fir perfectly strength or popularity in the metagame but it is more a case in the middle. It can seen as an aspect of strength as people don’t want to deal with it, so banning it, but it can be as an aspect of popularity or better yet a more general presence as while it may have not been played it sort of lingers in the match. The banned champion was not present directly in the match but with its spirit (the ban).\r\nIn the context of LoR such information can be added once we consider BoX data, currently only Bo3 with the easiest example being the Seasonal Tournaments and a possible way to define it is:\r\nBan Rate - ratio between the number of bans and the number of matches of a deck.\r\n\\[\\begin{equation}\r\n\r\nBanRate = \\frac{\\#ban}{\\#match}\r\n\r\n\\end{equation}\\]\r\nExample: 2 Line-Ups contained a Teemo/Ezreal deck, both played all 9 matches and Teemo/Ezreal was banned respectively 3 and 6 times; the ban rate would be \\(\\frac{(3+6)}{(9+9)} = 50\\%\\)\r\nAs the variable is deemed appropriate for the LMI purpose the following step is to define the structure of the LMI to account for the new variable.\r\nWith just three variables the possible ways to combine them are exactly three as shown in Fig:1, Fig:2 and Fig:3\r\n\r\n\r\n\r\n\r\nFigure 1: (1/3) Possible theoretical framework for the LMI - All the variables are part of their own subdimension\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 2: (2/3) Possible theoretical framework for the LMI - retaining two main subdimension of the base LMI, ban-rate and win-rate are both used to measure the ‘strenght’ of a deck\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 3: (3/3) Possible theoretical framework for the LMI - retaining two main subdimension of the base LMI, ban-rate and playrate are both used to measure the ‘presence’ of a deck\r\n\r\n\r\n\r\nEach different structure correspond to a different way to see the ban-rate relationship with the other variables.\r\nIn the first structure it is considered a different characteristic altogether in comparison to play-rates and win-rates.\r\nIn the second structure the ban-rate of a deck is considered a part of its ‘strength’, the higher it is the more it means that players don’t want to deal with it be it for play-patterns, expected win-rates, or other reasons one may have.\r\nIn the third structure the ban-rate of a deck is considered a part of its ‘presence’, it may have not been played, but like in the Kassadin example before, it’s lingering in the matches as an unseen factor that is still influential to the results. After all the ban or not of a deck, so if it takes an active or passive role in a match can heavily influence the remaining Match Ups.\r\nWhile the second structure may seems the more intuitive choice, none of these strctures are the one proposed at the end. This is because of the results we found during the statistical analysis.\r\nStatistical Analysis\r\nIn this section we describes how the analysis was done in its entirely and not just the final version of the steps to do in order to create the LMI. This is so to highlight some of the results we found and how we add the account for them.\r\nCorrelation\r\nTo assess which structure should be used we need to check the relationship between variables. This can be done by looking at their correlations.\r\nUsing all the data and calculating the correlation would be wrong, as, as showed in the previous LMI article it is better to limit the analysis to a smaller pool of decks with a sufficient amount of games.\r\nAt the Seasonal Tournament the number of games in total is overall small compared to the number of decks played so we tried a series of possible cut-off as min number of games played and find a compromise between not eliminating too many decks and having enough data to have quality results.\r\n\r\n\r\n\r\nWe tried to decide the min number of games required by looking at the amount of remaining decks we would have. The effect of different choices can be seen in Tab:1.\r\nNote: it’s the number of decks with also no missing values, as in the 296 decks there is 1 with no mean ban-rate even at cut-off of zero, the overall number is reduced by one.\r\n\r\nTable 1: Cut-off Table\r\n\r\n\r\n\r\nminGames\r\n      #Deck\r\n    0\r\n29510\r\n14530\r\n7950\r\n52100\r\n37200\r\n29Amount of remaining Decks\r\ndepending on the required min amount of Games\r\n    \r\n\r\nAt the first glance, the 200 games used during the meta-reports seems excessive as it reduce the decks to 1/10th, 10 games is probably not enough as the win-rates would be too unstable making us gravitating mostly on 30,50,100 but we will truly decide being guided by the correlation results as shown in Tab:2.\r\n\r\nTable 2: Correlation Table at different cut-off\r\n\r\n\r\n\r\nCorrelation\r\n      0\r\n      10\r\n      30\r\n      50\r\n      100\r\n      200\r\n    WR/playrate\r\n0.07\r\n0.12\r\n0.18\r\n0.16\r\n0.13\r\n0.08meanBan/playrate\r\n0.09\r\n0.24\r\n0.29\r\n0.33\r\n0.28\r\n0.24meanBan/WR\r\n-0.02\r\n0.09\r\n-0.07\r\n-0.03\r\n-0.08\r\n-0.02Correlation between the three raw variables on different amount of required min amount of Games\r\n    \r\n\r\nThe resulting correlations took us by surprise in a first moment. Not only the variable with the higher correlation to the ban-rate is the play-rate and not the win-rate (the expected initial result) but the correlation with win-rate seems to be negative. This is not strange, in Bo3 setting after the bans each player tries to enforce the best match-ups among the remaining decks so it easier to have bad match-ups even for highly-performing decks on the ladder. This made us question whatever to aggregate the ban-rate with play-rate, so the structure in Fig:3. What we actually did was to consider:\r\nIf the ban-rate of a deck during the Seasonal is negative correlated its win-rate it’s probably because many brought counter line-ups to popular and strong decks. So it would also means that the ban-rate is also correlated to the performance of a decks in the ladder before the tournament.\r\nWe tried to see if this is the case by looking at the correlation of the ban-rates with not just the win-rates at the Seasonal but also the win-rates from the ladder up to two weeks before the tournament starts. Since the aggregation is not done with the raw values but the normalized transformation the correlation is calculated after the normalization step using the quantile normalization as done in the previous iteration of the LMI. In addition, not to be affected by the particular tournament chosen this is why we also used the data from the ‘Seasonal Tournament - Guardian of the Ancient’ when the case-study was aimed to compute the LMI for the ‘Rise of the Underworld’ edition. As seens in Fig:4 this was a crucial choice as the relationship of the ban-rates with the Seasonal win-rates can change radically. In the June tournament the metagame was more polarized and this probably affected the correlations.\r\n\r\n\r\n\r\nFigure 4: correlation of Seasonal Win-Rates and Ladder Win-Rates with the Ban-Rates at different benchmarks of minimum amount of games for each deck\r\n\r\n\r\n\r\nHow to continue was the hardest part of the analysis. The correlation of ladder win-rates have a strong positive orientation with the ban-rates while the correlation with the Sesonal win-rates is more unstable and tends to be negative for certain value. If we wanted to use the structure of Fig:1 or Fig:2 than our problem would have to aggregate variables with different orientations. While this is not a rule one must always follows in the cases mentioned this would negatively impact the quality of the LMI. We would have for sure that an high value of a deck would decrease the win-rate index and to have an high LMI we may not want an high ban-rates as it’s increase may decreae the win-rate. It would be harder to have decks with high LMI and high values of both win-rates and ban-rates. At the same time, can we really say the strength of the deck is the one we measured if the win-rates we observe seems to be a consequence of the metagame from the ladder and the high performances in Bo1 that is reflected by high ban-rates as to suggest people don’t want to deal with decks they in the ladder they found are difficult to deal with unless the line-up can handle them?\r\nThe solution proposed is to use a win-index that is not created from just the Seasonal win-rates but also the ladder win-rates to include both informations and having the ladder value reduce if not remove the negative correlation of the Seasonal value. Both for this to work we have to check a couple of conditions:\r\nWin-rates from Seasonal and ladder needs to be correlated and the orientation shouldn’t change depending on the tournament, which is a legit worry after seeing the previous figure. A positive correlation can be found and seen in Fig:5.\r\nThe aggregated win-rates have works better as a component to aggregate with ban-rates. The results can be seen in Fig:6.\r\n\r\n\r\n\r\nFigure 5: correlation of Seasonal Win-Rates with Ladder Win-Rates at different benchmarks of minimum amount of games for each deck\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 6: correlation of Ban-rates with a Win-Index computed as harmonic mean of Seasonal and ladder win-Rates with Ladder at different benchmarks of minimum amount of games for each deck\r\n\r\n\r\n\r\nConsidering the overall results the final choices to the LMI frameworks are the following:\r\nHaving the LMI as seen in Fig:7. This is an aggregation of three subdimensions: popularity(playrate), ban and a win-subdimension which is made of the ladder and seasonal win rates. This can be justified by the correlation of the ban-index with both the play-index and the win-index. This option can\r\n\r\n\r\n\r\n\r\nFigure 7: Possible theoretical framework for the LMI - adding both ban-rate and ladder win-rate, using three main subdimension: ban, playrate and strength\r\n\r\n\r\n\r\nHaving the LMI as seen in Fig:8. The ban-rates shows a stronger causal relationship with the win-rates compared to the playrates (Fig:4) so considering it part of the strenght of a deck can be considered more appropriate. This the option which tries to follows the definition which was given before: ‘The performance of a deck is defined by its own strength and popularity inside the metagame.’ and is in fact the framework which is proposed.\r\n\r\n\r\n\r\n\r\nFigure 8: Proposed LMI theoretical framework - mainteining two main subdimension and having the ban-rate as a component of the ‘strength’ subdimension\r\n\r\n\r\n\r\n\r\n\r\n\r\nWeigths\r\nAggregating variable into a single index this is always done by applying weights to each component, be them equal weights or another vector. The decision can be made by following different method not all being entirely data-driven. A common way to compute the weights is by using the normalized loading factors of the first eigenvalue from the principal components. With the proposed structure both the weights for the win-index and strength index resulted in a equal weights (0.50 and 0.50). As it is both the simplest case and being confirmed by a data-driven approach equal weights are the applied weights.\r\nNote: if we used the 3-subdimension structure the resulting weights would have been\r\n\r\nPlayRate Index Strength Index  BanRate Index \r\n         0.533         -0.070          0.537 \r\n\r\nResults\r\nIf we tried to apply the proposed structure for the LMI and create again the graph from the Seasonal - Rise of the Underworld report there is a clear difference from the past version. With the new framework Akshan/Sivir (DE/SH) is not in a league of its own while still being the best decks. We want to remember it is not like the previous or the current iteration is wrong and the other correct, they just measure the same/similar data in a different way. While the previous iteration created a more sensational graph we consider the current one more ‘realistic’ as the difference between Akshan/Sivir (DE/SH) and the other top performing decks was way too high. One may object that the difference is now too small but even it was the case we still consider it an improvement from the previous framework.\r\n\r\n\r\n\r\nConclusions\r\nWe started this article with the aim of adding the ban-rate to the LMI, contrary from out expectations this required to consider more the relationship with the selected variables and the possible causal relationship among than (in particular the ban-rates with the seasonal win-rates). To solve this problem we proposed to add a forth variable in the ladder win-rates from ranked games prior to the tournament.\r\nA question that emerged during the analysis is about how to evaluate decks with a really small numbers of games because of an high ban-rate so if the selection filter should be adjusted to account for them. This could be done in future analysis that includes the uncertainty and sensitivity analysis.\r\nAs the new LMI doesn’t create what seems to be an outlier in Akshan/Sivir (DE/SH) a possible research question is how to determine is an even simpler way the strength of a deck. Meaning is we can translate the LMI into a tier-value, for example from ‘tier-D’ to ‘tier-S’, the commonly system used by gamers.\r\nIf we tried used the cut-off values used by Balco we would have the following results.\r\n\r\n\r\n\r\nAs the cut-off values were chosen without any particular reason behind them, a future article will try to investigate different options for the cut-off values.\r\nTo expand the application of this version of the LMI an analysis that will follow will try to apply this framework to Bo3 taken from the gauntlet and friendly Bo3.\r\nLastly, as the variable we are using are a result of the state of the metagame of that time future article will try to check if we can add informations regarding the quota of counter-decks for a specific deck are played in a particular time of the meta/during the tournament.\r\nAppendix\r\n\r\nTable 3: Quantile table\r\n\r\n\r\n\r\n\r\nLegal bla bla\r\nThis Meta Report was created under Riot Games’ “Legal Jibber Jabber” policy using assets owned by Riot Games. Riot Games does not endorse or sponsor this project.\r\n\r\nLMI - early concept↩︎\r\nLMI with Ban Rate - from Seasonal Rerport↩︎\r\nNo official data are known at the moment of the writing. Supposition made from a series of points like the fewer amount of Master rank players when the cut-off takes place.↩︎\r\n",
    "preview": "analysis/lmi-02-tentative-expansion/lmi-02-tentative-expansion_files/figure-html5/print-seqCor-1.png",
    "last_modified": "2021-10-10T08:03:55+02:00",
    "input_file": {},
    "preview_width": 1728,
    "preview_height": 1152
  },
  {
    "path": "analysis/defining-archetypes-01/",
    "title": "Defining Archetypes #1: Looking at the similarity of Akshan/Sivir/Zed with similar archetypes",
    "description": "First entry on a series of article that will gather my explorations over different way to define archetypes in Legends of Runeterra",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-09-06",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nData\r\nMethods\r\nHierarchy of steps\r\nDistance among decks\r\nDecklist Distance Matrix\r\n\r\nAnalysis\r\nConclusion\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nThis series of article/analysis are meant to rappresent my journey in how to define archetypes.\r\nArchetypes in Legends of Runeterra are currently defined by me by the combinations of champions and regions. While it’s a lazy method, it’s (was?) a first approximation that worked decently aside for some exception. A limitation I always knew is that the number of possible archetypes increase too rapidaly with the release of new cards and will probably get too high compared to the number of available games (at least at Master) sooner or later. On the other side of the spectrum the most restricting classification would with a categorical (maybe even just dichotomical) variable, something like using the Super Archetypes from viciousSyndicate (vS): Initiative and Resource decks 1. Every other archetype classification is in immediatiate and it’s a vast ocean of possibilities with no ‘correct’ solution.\r\nAs everything needs to be done step by step, I’ll start with what was pointed to me a few weeks ago:\r\n\r\nHow do you feel about combining Akshan/Zed/Sivir with Akshan/Sivir since it's generally just 1 card difference? And maybe even with Zed/Sivir (a bit more different on average, but still conceptually the same deck).— Dr. LoR (@drlor4) July 28, 2021\r\n\r\n\r\nAround the times Dragons and Overwhelm (SH/FR) decks turned into legit meta options, decks with 3 champions have become more widely used and they are their acceptance as legit option has increased, no more being just a bad choice by default.\r\nDuring the times of that tweet, in the patch 2.12/2.13 there was an higly performing deck with three champions: Akshan/Sivir/Zed (ASZ).\r\nWhat I aim to answer is related so the suggestion in the tweet : is my current aggregation too strict? Is Sivir/Zed or Akshan/Sivir the same deck as ASZ, only lacking a champion? While by intuition they may looks similar, it’s not a proper answer which I tried to respond with this article. 2\r\nData\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe sample is made of 845370 Ranked games from 2021-07-14 21:00:00 to 2021-08-25 21:00:00, so covering the patch 2.12/2.13 after the start of the Ruination Event so that there aren’t any changes in the card pool in the timeframe analyzed by amount of cards or balance changes.\r\nBecause there was the raise of the Demacian deck with Akshan/Sivir, these decks are removed as they could create a few problem in the following steps. In addition I only consider decks with 6 copies of champions (the max value). This is done to remove the outliers in deck creation and making the sample more homogeneous for a step that will follow.3\r\n\r\n\r\n\r\nThe sample is reduced to 704464 games\r\n\r\n\r\nCharacteristic\r\n      \r\n        Zed\r\n      \r\n      \r\n        Akshan\r\n      \r\n    Overall, N = 704,4641\r\n      no Sivir/Zed, N = 662,9821\r\n      Sivir/Zed, N = 41,4821\r\n      no Sivir/Akshan, N = 644,7411\r\n      Sivir/Akshan, N = 59,7231\r\n    #Champion\r\n\r\n\r\n\r\n\r\n2\r\n649,177 (92%)\r\n634,195 (96%)\r\n14,982 (36%)\r\n617,513 (96%)\r\n31,664 (53%)3\r\n54,373 (7.7%)\r\n27,878 (4.2%)\r\n26,495 (64%)\r\n26,414 (4.1%)\r\n27,959 (47%)4\r\n718 (0.1%)\r\n713 (0.1%)\r\n5 (<0.1%)\r\n663 (0.1%)\r\n55 (<0.1%)5\r\n38 (<0.1%)\r\n38 (<0.1%)\r\n0 (0%)\r\n37 (<0.1%)\r\n1 (<0.1%)6\r\n158 (<0.1%)\r\n158 (<0.1%)\r\n0 (0%)\r\n114 (<0.1%)\r\n44 (<0.1%)\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n      \r\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote : The percetages are column-wise\r\nThe overall prevalence of ‘3 champions deck’ is around 7.72%. This value is mostly carried by the ASZ decks with 26418 games which amoutn to almost half the cases of 3 champs decks 48.6%\r\nMore specificaly, those 26418 ASZ decks are the main subset of both SZ decks when using 3-champions (99.7% of the cases) and for AZ decks too (94.5% of the cases). In other words, when a third champion is added to SZ or AZ decks the result is almost always an ASZ, meaning ASZ seems a common ground to both these two archetypes. But are ASZ just a common ground or the general cases are already almost equal (AZ and SZ).\r\nMethods\r\nHierarchy of steps\r\nThis section illustrate the mathematical/statistical theory and application I’ll use to tackle the question the article’s question.\r\nBut before that, what are the steps I want to follows?\r\n\r\n\r\n\r\nFigure 1: ASZ as special case of AS\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 2: ASZ as special case of SZ\r\n\r\n\r\n\r\nAs mentioned I first need to see if the hyphothesis rappresented in the venn diagrams (Fig:1 and Fig:2) is correct: ASZ is just a special case of one/or both of AS or SZ.\r\n\r\n\r\n\r\nFigure 3: ASZ as special case of both AS and SZ\r\n\r\n\r\n\r\nIf it’s true for both, then I will check AS and SZ can be considered similar, so, by looking at Fig:3 how the intersection is, if Sivir/Zed and Akshan/Zed do seems to overlap and how.\r\nDistance among decks\r\nWhen looking at a deck it’s possible to visualize them a network-graph where each node is a card and the edges the connection between cards.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 4: Deck as a Network graph\r\n\r\n\r\n\r\nIt’s possible than to expand the concept to archetypes where they would be a collection of decks, expanding the graph to more cards and for example adding the information related to the playrates of cards and which are commonly played toghether by using weighted edges.\r\nThe advantage of this approach for the question of this article would be having to compare a single item for each archetype, the archetype-network, but with the disadvantage of working with a more complex structure which is the reason it’s not applied in this paper.\r\nTo compare archetypes we start by comparing decks, but what does it means to “compare” decks? To compare somethings we must to able to measure the similarity or dissimilarity which requires the use of a metric. What follows in an example to illustrate an example of metric and how to evalute the similarity of decks.\r\nSuppose we have the following decks of 10 cards:\r\n\r\n\r\n\r\n\r\n  cardcode count faction set card_number             name\r\n1  01IO009     2      IO   1         009              Zed\r\n2  04SH020     2      SH   4         020            Sivir\r\n3  04SH093     2      SH   4         093     Shaped Stone\r\n4  04SH103     2      SH   4         103 Merciless Hunter\r\n5  04SH130     2      SH   4         130           Akshan\r\n  cardcode count faction set card_number             name\r\n1  04SH020     3      SH   4         020            Sivir\r\n2  04SH130     3      SH   4         130           Akshan\r\n3  04SH093     2      SH   4         093     Shaped Stone\r\n4  04SH103     2      SH   4         103 Merciless Hunter\r\n\r\nThe only differences are the champions and their amount.\r\nOverall there’s a similarity of 8 (out of 10) or a distance of 2 (out of 10).\r\nIt can proven that this is indeed what it’s called a distance or metric as it has all the necessary properties:\r\nNot-negative codomain, so \\([0,Inf)\\)4. This is true as it’s definite in \\([0,40]_\\mathbb{N}\\)\r\n\\(d(x,y) = d(y,x)\\) (Simmetry)\r\n\\(d(x,x)=0\\)\r\n\\(d(x,y)\\leq d(x,z)+d(z,y)\\) (The Triangle inequality)\r\nDrisoth already showed that it can be used with success in hierarchical clustering (DBSCAN in his case)5 to good success.\r\nWhile a proper metric, there is a problem with this measure that makes us prefer another one. The following example explain the problem with the “counting of cards difference”, it could be said that the metric lack subtlety as it doesn’t reward decks having a similar distribution of cards’ copies as can be seen in the following example:\r\n\r\n  cardcode count faction set card_number             name\r\n1  04SH020     3      SH   4         020            Sivir\r\n2  04SH130     3      SH   4         130           Akshan\r\n3  04SH093     2      SH   4         093     Shaped Stone\r\n4  04SH103     2      SH   4         103 Merciless Hunter\r\n  cardcode count faction set card_number             name\r\n1  04SH020     3      SH   4         020            Sivir\r\n2  04SH130     3      SH   4         130           Akshan\r\n3  04SH055     2      SH   4         055      Ruin Runner\r\n4  04SH103     2      SH   4         103 Merciless Hunter\r\n  cardcode count faction set card_number             name\r\n1  04SH020     3      SH   4         020            Sivir\r\n2  04SH130     3      SH   4         130           Akshan\r\n3  04SH103     2      SH   4         103 Merciless Hunter\r\n4  04SH055     1      SH   4         055      Ruin Runner\r\n5  04SH093     1      SH   4         093     Shaped Stone\r\n\r\nThe difference among these deck is the same at 2 cards, what changes are either 2 copies or Merciless Hunter, 2 copies of Ruin Runner or a single copy for both of the cards Marciless Hunter and Ruin Runner.\r\nAgain, we want to remark, this is not “wrong”, just we would prefer an alternative with more discriminatory power. A possible solution, is the commonly used metric that add this nuance, the cosine distance.\r\nThe cosine similarity is defined as:\r\n\r\n\\[\\begin{equation}\r\n\r\n\\cos(A,B) = \\frac{A \\cdot B}{||A||_2||B||_2} \\tag{1}\r\n\r\n\\end{equation}\\]\r\nwhich can be written as\r\n\r\n\\[\\begin{equation}\r\n\r\n\\cos(A,B) = \\frac{\\sum{A_iB_i}}{ \\sqrt{\\sum{A^2_i}} \\sqrt{\\sum{B^2_i}}} \\tag{2}\r\n\r\n\\end{equation}\\]\r\nThe measure runs from 0 (orthogonal vectors or maximum dissimilarity) to 1 (parallel vectors or maximum similarity) so with max and min at the opposite cases of what we want as it is indeed a measure of similarity and not dissimilarity. The cosine distance is simply defined as 1 - cosine similarity.\r\nThe previous example that would always have same distance 0.2\r\n\\[\r\n\\begin{bmatrix}\r\n0 & 0.2 & 0.2 \\\\\r\n0.2 & 0 & 0.2 \\\\\r\n0.2 & 0.2 & 0\r\n\\end{bmatrix}\r\n\\]\r\nhave now distance matrix:\r\n\r\n\r\n\r\n\\[\\begin{bmatrix}0&0.15&0.04 \\\\0.15&0&0.04 \\\\0.04&0.04&0 \\\\\\end{bmatrix}\\]\r\n\r\n\r\n\r\nIt’s now possible to better explain the reason why the data was restricted to cases with 6 copies of Champions cards.\r\nWe have to measure the similarity in three different archetypes (AS,SZ,ASZ) and no matter our choices, from the raw data we would always find at least a difference related to one card among these archetypes.\r\nFor example between an AS and SZ deck the min card-difference would be a single copy of Akshan with a single copy of Zed because of the definition of archetypes applied.\r\nIn order not to have to account the difference in champions and the number of their copies we will evalutate the difference among all non-champion cards. If the distance is zero or near it, it would mean that aside for the champions of choice the decks are similar giving support to the hypthesis of being part of the same “archetype”. Or, to put it differently, we modify out data so that when comparing different deck from different archetypes the possible values for the cosine distance remain in \\([0,1]\\) helping the comparison in the following steps, without for example having to rescale the values. Because of the choice of removing the champions there’s the suggestion of also filtering all cases with less than 6 champions cards. While it’s possible to compute the cosine distance with deck of a different number of cards computable for this problem we consider more appropriate working with decks with the same number of cards.\r\nDecklist Distance Matrix\r\nWe described how to compare single decks but we want to answer a question related to archetypes. To do as such, let’s say we want to start with the comparison with AS and ASZ, from the decklist/deckcode of these decks we create the distance matrix among decks.\r\n\\(A={\\begin{pmatrix}A_{{11}}&A_{{12}}\\\\A_{{21}}&A_{{22}}\\end{pmatrix}}\\)\r\nWhere A is a \\((n+m)×(n+m)\\) simmetric block matrix where\r\nn is the number of deckcodes/decklist from \\(Archetype_1\\)\r\nm is the number of deckcodes/decklist from \\(Archetype_2\\)\r\n\\(A_{{11}}\\) is the \\(n×n\\) distance matrix relative to deck of \\(Archetype_1\\)\r\n\\(A_{{22}}\\) is the \\(n×n\\) distance matrix relative to deck of \\(Archetype_2\\)\r\n\\(A_{{12}}=A_{{21}}^T\\) is the \\(n×m\\) matrix containing the distances between \\(Archetype_1\\) vs \\(Archetype_2\\)\r\nWhat we propose is to compare the values between \\(A_{{11}}\\), \\(A_{{22}}\\) 6 and \\(A_{{12}}\\) with the hyphotesis that if the archetypes are indeed similar/equal the distances should have the same mean (and variance) which is equivalent to apply and ANOVA test.\r\nAnalysis\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nNot all deckcodes have been used to create the submatrices of the block matrix. The number of unique deckcodes for each archetypes was considered too big, relative to the number of games 7, and as each deck have the same weight there could be risk of not properly rapresenting the distances distribution by using all deckcodes. Only the most frequent deck codes that account for at least 50% of the games have been used 60 decks for AS, 49 decks for SZ, 10 decks for ASZ.\r\nTwo distance matrix have been created for AZ decks vs ASZ decks and SZ decks vs ASZ decks.\r\nResults are provided in Tab:1 and Fig:5 for the ASZ vs AS decks while for ASZ vs SZ decks in Tab:2 and Fig:6\r\n\r\n\r\n\r\n\r\n\r\nTable 1: Summary statistic ASZvsAS decks\r\n\r\nGroupMeanSdSkewAS0.0690.0350.333ASZ0.0560.0290.715ASZvsAS0.0580.0360.329\r\n\r\n\r\n\r\n\r\nFigure 5: distribution of cosine distances for ASZ vs AS decks\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 2: Summary statistic ASZvsSZ decks\r\n\r\nGroupMeanSdSkewASZ0.0560.0290.715ASZvsSZ0.0610.0430.930SZ0.0780.0490.881\r\n\r\n\r\n\r\n\r\nFigure 6: distribution of cosine distances for ASZ vs SZ decks\r\n\r\n\r\n\r\nAnd lastly we show the result of the ANOVA applied first for AZ decks\r\n\r\n             Df  Sum Sq  Mean Sq F value Pr(>F)\r\ngroup         2 0.00444 0.002217   1.895  0.154\r\nResiduals   168 0.19659 0.001170               \r\n\r\nHere we don’t reject \\(H_0\\) as the p-values (the values the \\(Pr(>F)\\) columns ) is above 0.05 giving support to the hyphotesis that ASZ is just a special case of AS and they can be aggregated.\r\nIn th case with SZ decks the ANOVA test gives:\r\n\r\n             Df  Sum Sq  Mean Sq F value Pr(>F)  \r\ngroup         2 0.01075 0.005375   3.106 0.0474 *\r\nResiduals   168 0.29076 0.001731                 \r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nMeaning we reject the null hyphotesis \\(H_0\\) that the distances are from the same population and their distribution is the same. But while this is true, we can also see that the value is near 0.5 meaning it would be wiser to check Tukey post-hoc tests.\r\n\r\n  Tukey multiple comparisons of means\r\n    95% family-wise confidence level\r\n\r\nFit: aov(formula = value ~ group, data = DSim.tbl_2)\r\n\r\n$group\r\n                   diff           lwr        upr     p adj\r\nASZvsSZ-ASZ 0.005239898 -0.0127209395 0.02320074 0.7697297\r\nSZ-ASZ      0.022181593  0.0001841494 0.04417904 0.0476100\r\nSZ-ASZvsSZ  0.016941695 -0.0024582271 0.03634162 0.1003015\r\n\r\n\r\n\r\n\r\nFigure 7: Tukey Post-Hoc test\r\n\r\n\r\n\r\nWe can see that the rejection for the ANOVA test can be explained by the resulting differences for SZ and ASZ decks. But simply looking at the threshold of 0.05 would ignore how this is a very borderline result. So, while rules are not meant to be broken (when doing analysis) this is a rare case where we don’t blindy follows the raw numbers, meaning we accept the hyphotesis that SZ and ASZ too are from the same population / or the same Archetype.\r\nConclusion\r\nThe analysis gives support to the hyphotesis of aggregating the archetypes defined as ASZ, SZ and AS as Dr.LoR suggested. 8\r\nFurther testing should check is the sample and condition we choose are too strict or too lenient.\r\nThe next article in this series will introduce the application of hierarchical clustering methods to the archetypes problem both replicating Drisoth methodology and possible alternatives.\r\n\r\ntheir definition, example and so on will be a topic for the future.↩︎\r\nI’m aware that the aggregation problem is not limited to cases with three champions, some cases may even be related to a single card like “Feel the Rush” or “ARAM (Howling Abyss)” but as mentioned, one must proceed with baby steps and this is probably a good starting point.↩︎\r\nall deck with no Champion or mono Champion are excluded by default because of this.↩︎\r\nNot actually a properties but a requirement in its definition↩︎\r\nArchetypes - Cluster↩︎\r\nAs \\(A_{{11}}\\) and \\(A_{{22}}\\) are simmetric matrix relative to the same Archetype’s decks we’ll only use the values from the upper triangular matrix without diagonal.↩︎\r\n2113 decks for AS, 1350 decks for SZ, 1336 decks for ASZ↩︎\r\nany change will probably occour on the first report after the release of this article.↩︎\r\n",
    "preview": "analysis/defining-archetypes-01/defining-archetypes-01_files/figure-html5/plot-ASZ-SZ-1.png",
    "last_modified": "2021-10-06T09:21:12+02:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "analysis/esplore-lor-mastery-curve/",
    "title": "An exploratory analysis to Mastery Curve in LoR",
    "description": "Applying the concept of Learning Curve to Legends of Runeterras' decks.",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-07-19",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nINTRODUCTION\r\nMATERIALS AND METHOD\r\nData\r\nCreating the curve\r\nLurk\r\nChrono Squad\r\nJinx/Lulu\r\n\r\n\r\nConlusions\r\n\r\nINTRODUCTION\r\nWin rate is the most common and most useful metric when evaluating a deck in a Collectible Card Games (CCG) but that value alone may not tell the full story. In Legends of Runeterra (LoR), a common example for saying that the win rate alone isn’t enough is citing “Lee Sin (MT/IO)” decks.\r\nIn the ladder, acroos all Masters’ players, even when LeeSin win rate was only ranging around 50% it was considered an undisputed Tier-1 choice (similar now with Akshan/Lee?), so why was as such when it wasn’t an highly performing deck? Because:\r\nIt was a strong option in a more controlled format like during tournaments\r\nBecause that win rate included both “noobs” and more experienced player with the deck. It is a common opinion in the community that only after playing an huge amount of games with Lee that a player would learn how to pilot the deck and bring it to its fullest potential, changing radically the match ups more in its favor.\r\nFrom my knowledge there’s no hard data to support the claim but just the overall feeling from the community, but this doesn’t mean that the hyphotesis is not solid. Learning curve are a thing and in the context of “Runeterra” it was perfectly showed by an ex-Rioter when talking about certain champion learning-curve in League of Legends (LoL)\r\n\r\n\r\n\r\nThe reason I’m showing this tweet as an example should be easy to understand: here, I’ll try to replicate those graphs for LoR.\r\nMATERIALS AND METHOD\r\n\r\n\r\n\r\n\r\n\r\n\r\nData\r\nThe dataset consist of at most 137270 games played after the application of patch 2.11 so after 2021-06-30 19:00:00 CEST.\r\nThese are games collected following two criteria:\r\nGames from Master players\r\nGames from the previous top32 players from the latest Seasonal (EU and NA).\r\nFrom these I filtered the games only on Constructed pvp modes (Normal,Ranked,StandardGauntlet,Bo3ChallengeLobby). 1\r\nWith 2.12 there has been an addition of several cards that heavily affected the metagame so there’s a case to restrict the analysis only to games on the same patch (2_11 or 2_12). In addition, since we are talking about learning curve it may be intuitive to leave all games between two human players (all pvp constructed modes) but some may think that it’s only appropriate to limit the data to Ranked games. By considering both factors the data we start with are distributed like this:\r\n\r\n\r\nCharacteristic\r\n      N\r\n      2_11, N = 56,1611\r\n      2_12, N = 81,1091\r\n    pvp\r\n137,270\r\n\r\nnotRanked\r\n\r\n5,608 (10.0%)\r\n21,437 (26%)Ranked\r\n\r\n50,553 (90%)\r\n59,672 (74%)\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n      \r\n    \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nWhile this is the available dataset one should ask: which decks should I check? They need of course be decks that doesn’t exist before patch 2.11 or that they were soo rare that I can assume my reference population didn’t play them at all. Luckily the choice of patch 2.11 is not at random as it introduced a small expansion “Rise of the Underworld” that introduced a couple of new meta decks. In addition it would be wiser to choose decks whose structure is mostly defined by a limited range of choices because of the limited card-pool. In addition\r\nWhat follows are decks that I considred potential candidate for this analysis and the respective sample size available:\r\nLurk (Pyke/Rek’Sai) - n°games: 29959\r\n“Chrono Squad” 2 (Ekko/Zilean) - n°games: 3894\r\nYeti - n°games: 1241 with PnZ and n°games: 959 with Noxus - being more popular thanks to the introduction or Abominable Guardian\r\nElnuk - n°games: 412 - being more popular thanks to the introduction or Volunteer Elnuk\r\nLulu/Jinx - n°games: 3724 - not new but very rarely played and not only risen in popularity in 2.12 but also made stronger thanks to Boom Baboon\r\nThose are max numbers of games available, their number could be reduced depending on the subset we would prefer to use like the patch and pvp-mode chosen. This numbers can be seen in Tab:1\r\n\r\nTable 1: Summary table\r\n\r\n\r\n\r\nCharacteristic\r\n      \r\n        2_11\r\n      \r\n      \r\n        2_12\r\n      \r\n    N\r\n      notRanked, N = 1,8331\r\n      Ranked, N = 24,1361\r\n      N\r\n      notRanked, N = 3,1171\r\n      Ranked, N = 11,1031\r\n    player\r\n25,969\r\n\r\n\r\n14,220\r\n\r\nEkko / Zilean\r\n\r\n351 (12%)\r\n2,661 (88%)\r\n\r\n442 (50%)\r\n440 (50%)Elnuk (FR/PZ)\r\n\r\n69 (19%)\r\n285 (81%)\r\n\r\n21 (36%)\r\n37 (64%)Jinx / Lulu\r\n\r\n141 (9.3%)\r\n1,372 (91%)\r\n\r\n390 (18%)\r\n1,821 (82%)Pyke / Rek'Sai\r\n\r\n1,075 (5.6%)\r\n18,225 (94%)\r\n\r\n2,068 (19%)\r\n8,591 (81%)Yeti (FR/NX)\r\n\r\n92 (11%)\r\n717 (89%)\r\n\r\n111 (74%)\r\n39 (26%)Yeti (FR/PZ)\r\n\r\n105 (11%)\r\n876 (89%)\r\n\r\n85 (33%)\r\n175 (67%)\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n      \r\n    \r\n\r\nAs shown in the above table there’s an high number of games of Lurk games but way lower for everything else. Still, using only one example would result on a terrible external validation so it would be better to at least add a couple more cases (not that with just three is much better).\r\nLooking at the number in Tab:1 the best candidate are “Chrono Squad” (Ekko/Zilean) and Jinx/Lulu. “Chrono Squad” dataset also may potentially be better since while the numbers for Jinx/Lulu aren’t that bad, “Chrono Squad” games are mostly on patch 2.11 so mostly in a stable metagame and expected average win rate.\r\nCreating the curve\r\nBefore trying to recreate the mastery curve we must be sure how it’s created.\r\nThe main question is: taking in account two players: one with 100 games and one with 50 games. Do I have 150 points using the win rates from 1 to 100 games and 1 to 50 games or do I have only 2 points? One corresponding to 100 games and one for 50 games? Luckily it seems another tweet is helping:\r\n\r\n\r\n\r\nHe’s saying there’s a lack of players with “exactly” 389 games on Ivern which means/suggest he can’t use the data of Ivern players with 390+ games.\r\n\r\n\r\n\r\nLurk\r\nThe tweet means/suggest that on the x-axis of the mastery curve plot we have the average of win rates of players with exactly n games. This limitation will be shown with some initial resultsing graphs (Fig:1)\r\n\r\n\r\n\r\nFigure 1: Lurk master curve on different settings\r\n\r\n\r\n\r\nThe aboves graphs shows the fitted mastery curve on three different settings:\r\nUsing all pvp-modes with games from the top32 EU/NA Seasonal players, fitted with a linear model which use the number of games as covariate up to the quadratic term. While it shows a positive “mastery-coefficient” there’s too much noise with error bands way too wide and a too limited sample pool.\r\nThe second plot add all the players collected up to the moment of the analysis and it’s possible too see a clearer trend. Compared to the LoL-example from Blastoise we are clearly in a similar case to the Invern graph where we lack data points. While compared to the mean results there seems to be a positive “mastery-coefficient” the fitted curve doesn’t seems appropriate most likely overestimating the effect of skills.\r\nTo solve the fit-problem the third plot use a loess method again up to the quadratic term of the number of games on the same sample used for the second graph. Here the graph again seems to suggest there is a positive “mastery-coefficient” but compared to the mean results it’s more an additive (capped) and not moltiplicative factor which can be considered after about 50/100 games.\r\nSomething that nedds to be considered is that: while for the top32 I’m sure I have collected all their games, this isn’t sure for everyone else so it’s safe to assume that for every other player the effective number of games with Lurk is m >= n where n is the number of games I collected. This may impact on the curve as I may have higher WR for a corresponding number of games that’s effectively lower than the real number. Also a question is: is the sample appropriate? As mentioned at the start this sample contains both patch 2.11 and 2.12. On those patches Lurk wasn’t effected as a deck structure but the metagame around itself surely changed and it also effected the expected win rate (Tab:2)\r\n\r\nTable 2: Win Rate between patches\r\n\r\n\r\n\r\nCharacteristic\r\n      2_11, N = 18,8701\r\n      2_12, N = 9,9161\r\n      p-value2\r\n    winRate\r\n9,670 (51%)\r\n5,333 (54%)\r\n<0.001\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n        \r\n          2\r\n          \r\n           \r\n          Two sample test for equality of proportions\r\n          \r\n      \r\n    \r\n\r\nWhat follows in (Fig:2) is the mastery curve using only patch 2.11 side by side with the one previsouly obtained with both patches (loess fit, all pvp modes).\r\n\r\n\r\n\r\nFigure 2: Comparison of Lurk master curve with loess fit using only patch 2.11 or both 2.11 and 2.12 with all pvp modes\r\n\r\n\r\n\r\nUsing only patch 2.11 the skill-coefficient is not as clear as in the other setting. The trend is not as clear and there’s a lack of point for an higher number of games still while using both patches there’s the risk that the higher WR is a result of also playing in a patch where the deck is a little favorable.\r\nStill, if the sample is almost too little for the case with the highest amount of games, what abou the other two cases mentioned?\r\nChrono Squad\r\n\r\n\r\n\r\nBefore showing the plot for this case, is the Win Rate a possible confounding effect like in Lurk? It seems that’s not the case here as seen in (Tab:3)\r\n\r\nTable 3: Win Rate between patches\r\n\r\n\r\n\r\nCharacteristic\r\n      2_11, N = 2,8531\r\n      2_12, N = 6661\r\n      p-value2\r\n    winRate\r\n1,225 (43%)\r\n292 (44%)\r\n0.7\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n        \r\n          2\r\n          \r\n           \r\n          Two sample test for equality of proportions\r\n          \r\n      \r\n    \r\n\r\nSince there doesn’t seems to be a difference in performance for “ChronoSquad” the graph (Fig:3) will include games from both patches.\r\n\r\n\r\n\r\nFigure 3: Chrono Squad master curve with loess fit\r\n\r\n\r\n\r\nAs feared the sample size can’t be ignored while evalutating this graph. Again it seems there’s indeed an initial “skill-coefficient” that affects the overall performance which seems to peak after ~20 games and continue to be stabke again as an additive effect, yet the expected win rate is way too close to the error bands (which may be a little conservative) for most of the curve and it’s than inside the band for the values corresponding to the highest amoutn of games. Sure, it doesn’t makes sense from a causal point of view saying that the win rate decrease after a certain amount of games (after accounting for potential confonding effects) but we can’t do more with the little amount of games available. Lastly, let’s see the case of Jinx/Lulu\r\nJinx/Lulu\r\n\r\n\r\n\r\nAgain, before anything, let’s see if there are differences in the win rates between patches:\r\n\r\nTable 4: Win Rate between patches\r\n\r\n\r\n\r\nCharacteristic\r\n      2_11, N = 1,4951\r\n      2_12, N = 2,1721\r\n      p-value2\r\n    winRate\r\n834 (56%)\r\n1,277 (59%)\r\n0.076\r\n        \r\n          1\r\n          \r\n           \r\n          n (%)\r\n          \r\n        \r\n          2\r\n          \r\n           \r\n          Two sample test for equality of proportions\r\n          \r\n      \r\n    \r\n\r\nThe decks seems to have gained a lot with the latest patch (2.12) and so it would be follish to aggregate the data but I’ll also show that case the effect we would have on the other plots.\r\n\r\n\r\n\r\nFigure 4: Comparison of Jinx/Lulu master curve with loess fit using only patch 2.11 or both 2.11 and 2.12 with all pvp modes\r\n\r\n\r\n\r\nOverall this case is quite “the mess”, quite fitting since we are talking of loose scews like Jinx and Lulu.\r\nJokes aside:\r\nThe graph with only games with patch 2.11 is the worst among the ones obtained up until this point and it doesn’t suggest the presence of even a little skill-coefficient, heck not even a negative one. A possible explanation could be that it’s because since I’m using all the players and this deck was already rarely played, this is the result of the problem mentioned before where for some players the actual number of games played is higher than the one in my possession. Sadly, this doesn’t explain why for only patch 2.12 I see again what looks like the steepness of a small learning curve. Sadly in the third plot with the information in our possession it’s pretty much impossible to know whatever the absence on a skill-coefficient is masked by the higher expcted win rate for games played also in patch 2.11 or it’s indeed “the correct” behaviour. If anything this example highlist the importance of an appropriate sample.\r\nConlusions\r\nThe presence or lack of a skill-factor when playing an huge number of games with certain LoR-decks may still be debatable but aside for the Jinx/Lulu example a first explatory analysis suggest that there’s indeed an initial increase in the mean win rate compared to later results. The analysis also highlisted the requiment of a huge amount of games just to have a good curve (Lurk data) that if limited to a single patch correspond to an highly popular deck making this not applicable to most decks, at least with the current API/DB limitation. An idea could be try to repeat this analysis after a new mayor release of cards without a champion expansion that immediately follows. The release of the last region and main release of the next expansion in August doesn’t seems a good choicr as it should have too many cards so with less players focuing on specific decks. On the other hand the second/third expansion may be a better candidate.\r\n\r\n\r\n\r\n\r\nBo3ChallengeLobby are friendly Bo3 introduced from patch 2.12↩︎\r\nLegendary meme↩︎\r\n",
    "preview": "analysis/esplore-lor-mastery-curve/esplore-lor-mastery-curve_files/figure-html5/print-plot-Lurk-2-1.png",
    "last_modified": "2021-07-21T12:01:23+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 936
  },
  {
    "path": "analysis/matching-win-rate/",
    "title": "Matching games by 'Expected Win Rate'",
    "description": "Using a Pseudo-Propensity Score Matching to reduce sample bias when comparing win rates between players in LoR.",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-06-15",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nExample\r\n\r\nData\r\nMethod\r\nAnalysis\r\nResults\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nIn the context of Collectable Card Games (CCG) win rates are probably the most desidered information from the community. If it’s about decks, the meta is shaped around these values (also playrates), if it’s between players it can be a proxy to define who are the strongest players. Yet, one has to be carefull when computing even just single means of win rates, results are based on the individual match ups (MU) between archetypes so that the aggregated WR of a deck is the result of a weighted mean among the different MU. When applyed to a player, again, the playrates are still a factor to consider but this is rarely done.\r\nExample\r\nLet’s create an example from Legends of Runeterra (LoR) to exaplain this player’s WR bias in a simplified context where both of them use the same deck-archetype.\r\nPlayerA plays 10 games of Thralls (Lissandra / Taliyah) against 3 Nasus / Thresh and 7 against Azir / Irelia. The score being 4 wins and 6 loss.\r\nPlayerA plays 10 games of Thralls against 5 Nasus / Thresh and 5 against Lissandra/Trundle (TLC). The score being 6 wins and 4 loss.\r\nIf we just looks at the aggregated win rate then the WR of PlayerB (60%) > WR of PlayerA (40%) but saying that PlayerB is better than PlayerA would be disingenuous, the reason being, they played different MU with completely different excepted WR.\r\nWhile writing this document the expected WR are:\r\nThralls vs Azir/Irelia: 20.2%\r\nThralls vs Nasus/Thresh: 57.8%\r\nThralls vs TLC: 69.3%\r\nSo, the expected number of wins from PlayerA is 3.148\r\nWhile, the expected number of wins from PlayerB is 6.355\r\nThe expected and actual results are pretty much the same for each player, but since we just showed they are obtained in different context the 2 WR can’t be directly compared and we can’t say who’s the better player.\r\nSample bias is a common problem in statistics and pretty much any social/medical study have to deal with it, but while we are not in the context of the golden standard, a Randomized Study, we can elaborate our data so that it’s as similar as possible to it in which the data between each group of interest are as balanced as possible (Ceteris Paribus / other things being equal).\r\nThe objective of this document will be to explain a possible way to apply those techniques to LoR and the comparison of WR among players.\r\nData\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe data are a sample of 326437 matches played at Master rank during patch 2.7 and 2.8 (so same buff/nerfs).\r\n\r\n\r\n\r\nWe are going to present 3 examples of pair of players who played three among the most popular archetypes:\r\nAlanzq and SouL Who Wanders when playing Azir / Irelia\r\nMeliador0 and Bülat when playing Discard (Draven / Jinx)\r\nThe players were chosen among those with the higher amount of games with the archetypes, but still a relevant difference in sample sized among the two on them.\r\nAlso, there is a bit of personal curiosity and bias like for choosing the “Discard-derby” Bülat/Meliador and the pair of Alanzq/SouL Who Wanders for the memes.\r\nMethod\r\nTo have comparable win rates one needs to balance the MU between the players. The easiest way is to match each game from groupA with another from groupB whose opponent’s archatypes is the same. A match against NT with a game of NT, a game of Discard with a game of Discard and so on. While not far from what will be the proposed method, there’s the risk of not being able to match too many games. Let’s say that groupA because of the shard/server and timezone in which he plays, have higher chances of playing against rares decks, it could be be hard if not impossible to have a perfect MU-match in the “control group” groupB.\r\nTo solve this problem I propose the use of a proxy to the MatchUp archtype: the excepeted Win Rate of the match played. If n archetypes have similar MU values, than if I can’t match it by the exact MU I can select a game from one of the alternatives where I’m expected to have similar results. The assumption is that this wouldn’t effect the mean WR if it is the only variable that needs to be considered.\r\nIt’s then necessary to define a caliber that limits the range of archetypes which we considered similar (the value used here is 2%). The fact I’m matching on a “pseudo”-continuous (it’s discrete with possible domain (0,1)) variable and the use of a caliber could remind of the use of Propensity Score Matching (PSM). While the code used is indeed from a package mostly for PSM (MatchIt) the theory is completely different.\r\nWhen using a propensity score we estimate the probability of treatment assignment conditional of observed covariates. The treament here would be being played by PlayerA or PlayerB. The PS would then be used to match sets of treatment and untreated subjects who share a similar value of propensity score. Treatment “effect” is estimated comparing outcomes between treated and untreated subjects in the matches sample. Here the “effect of a player (~skill)” compared to someone else player would be comparing win rates obtained from the matched sample.\r\nAssuming that the archetypes are the only predictor variables, the model for the PS score is:\r\n\\[\r\nlogit(p=PlayerA|X) = \\alpha + \\sum_{i=1}^n \\beta_{1} X_{1i} + \\sum_{i=1}^n \\beta_{2} X_{2i} + \\sum_{i=1}^n \\beta_{3} X_{1i}X_{2i}\r\n\\]\r\nWhere \\(\\beta_1\\) is a m-dimensional vector where m is the amount of archetypes (minus 1) a player played, and \\(\\beta_2\\) is the corresponding for the archetypes used by the opponent.\r\nWe would have to drop the interaction component (\\(\\beta_3\\)) as we don’t have enough data but overall the model by itself is feasible. But again, we are not proposing the use of PS but an algorithm/procedure that works in a similar way also, the proposed change of using the MU-WR as proxy would simplify the model into a simple univariate logistic regression:\r\n\\[\r\nlogit(p=PlayerA|X) = \\alpha + \\beta_1 X_1\r\n\\] Now \\(\\beta_1\\) is a single value as \\(X_1\\) is now a continuous variable of the match ups win rates.\r\nAside for archetypes, are there any other covariate we can use? All time-dependent covariates are excluded. For example the “starting game time” is pretty much a leaker variable of the playerID (players tend to have a similar pattern in the time they can play, even more different among different shards). The patch shouldn’t be of any use. The remaining data which could be used are “order of play” (Fig:1) and “total turn count” (Fig:2), but “turn order” should be already balanced as it’s supposed to be random and equally distributed.\r\n\r\n\r\n\r\nFigure 1: Order of play\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 2: Turn count\r\n\r\n\r\n\r\nIn the first example (Azir/Irelia) there seems indeed to be balance for among the players’ potential predictors while there seems to be a little unbalance in the “Discard example” for order of play. So, aside from visualization, it’s better the check the balance by the numbers with the Odds Ratio (OR).\r\nAzir / Irelia\r\n\r\nTable 1: Tentative covariate balance for Azir/Irelia example\r\n\r\n\r\n\r\nCharacteristic\r\n      N\r\n      OR1\r\n      95% CI1\r\n      p-value\r\n    Total Turn Count\r\n1652\r\n1.00\r\n0.99, 1.01\r\n0.7Order of Play\r\n1652\r\n1.06\r\n0.87, 1.29\r\n0.6\r\n        \r\n          1\r\n          \r\n           \r\n          OR = Odds Ratio, CI = Confidence Interval\r\n          \r\n      \r\n    \r\n\r\nDiscard (Draven/Jinx)\r\n\r\nTable 2: Tentative covariate balance for Discard example\r\n\r\n\r\n\r\nCharacteristic\r\n      N\r\n      OR1\r\n      95% CI1\r\n      p-value\r\n    Total Turn Count\r\n1028\r\n1.04\r\n1.03, 1.06\r\n<0.001Order of Play\r\n1028\r\n1.11\r\n0.85, 1.44\r\n0.4\r\n        \r\n          1\r\n          \r\n           \r\n          OR = Odds Ratio, CI = Confidence Interval\r\n          \r\n      \r\n    \r\n\r\nIn the “Discard-example” the unbalance was actually for the turn count. While now a potential addition to the model we won’t use them as it would make the model easily reproducible for those who have not access to a match total turn count (number of times a players has initiative). Finally, the following tables display the distribution of the expected win rates for each player:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 3: Expected WR distribution - Azir/Irelia example\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 4: Expected WR distribution - Discard example\r\n\r\n\r\n\r\nIn the figures (Fig.3 between Alanz and SWW there doesn’t seems to be a big different in MU played but in Fig.4), the Discard example between Bülat and Meliador there’s a clear difference in the MU distribution and so the expected WR distribution.\r\nAnalysis\r\nA good rule when matching a continuos variable is trimming the starting dataset so that both groups has the same range of possible values, simply put the values are restricted to the maxmin and minmax of each group.\r\nFor Azir/Irelia the inizial range is 0.358, 0.836\r\nFor Discard the inizial range is 0.281, 0.706\r\n\r\n\r\n\r\nOnce trimmed, for Azir/Irelia, the range goes to to 0.374, 0.836, for Discard there are no changes.\r\nThe implementation of the matching is done as applying an optimal 1:1 matching. By applying a matching algorithm, compared to the usual Propensity Score Matching (PSM) procedure there’s a problem by having multiple rows with the same MU WR (so more candidates for the match). Usually the algorithm choose the control unit with a specifc order (like the first by ascending/descending order) but it would be bad here as the match should ideally be chosen at random among all the exact or similar match (within the caliber).\r\nSo, the solution proposed is to choose at random among the many match candidates, match the data, compute the resulting WR for each player and repeat the whole process n times (10^5 in this document) and get the distribution of the mean WR. To make replicate the random component we just need to permute the data before at the start of each iteration of the matching.\r\n\r\n\r\n\r\n\r\n\r\n\r\nFor those who would like to replicate the process this is the code I used The matching results are as shown is Fig.5 and Fig.6.\r\n\r\n\r\n\r\nFigure 5: Relative frequencies of Matched WR\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 6: Absolute frequencies of Matched WR\r\n\r\n\r\n\r\nWith Fig.6 in particular it’s possible to see how the matching perfectly create the balance we wanted to archive but as mentioned, the result is dependent on the order of the rows, so I did 10^4 permutations of both example data.\r\nResults\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nNo Matching\r\n\r\n\r\nMatched\r\n\r\n\r\nBülat\r\n\r\n\r\n59.63%\r\n\r\n\r\n59.70%\r\n\r\n\r\nMeliador0\r\n\r\n\r\n56.52%\r\n\r\n\r\n56.52%\r\n\r\n\r\nAlanzq\r\n\r\n\r\n59.71%\r\n\r\n\r\n59.30%\r\n\r\n\r\nSouL Who Wanders\r\n\r\n\r\n49.21%\r\n\r\n\r\n49.21%\r\n\r\n\r\nSadly for me, I didn’t choose an example that showed significant results by matching or not, still it’s not like the results has too often and the objective of this article is to make people more aware of the sample bias problem.\r\nWhile the mean for the “treat group” doesn’t change as it’s the “control group” the one that’s reduced here to match the other one, it’s not like it doesn’t change even by a little at each iteration/permutation. This can be seens by the distribution of WR obtained of the 10^4 permutations.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "analysis/matching-win-rate/matching-win-rate_files/figure-html5/plot-optmatch-1-1.png",
    "last_modified": "2021-07-21T13:01:21+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 936
  },
  {
    "path": "analysis/an-irelia-s-world/",
    "title": "An Irelia's World",
    "description": "Looking at the metagame response to Azir/Irelia's",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-06-09",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nData\r\nResults\r\n\r\nIrelia’s presence has been a staple of the meta ever since her appearence on patch 2.7\r\nCombining an high playrate with an high win rate a common opinion is that the deck is too powerful as even when people tried to counter it, for example with dragons, it would still remain the best performing deck . This analysis is going to tackle exactly this last point: that we lived in a meta that tried to counter Irelia but couldn’t.\r\nData\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe data use 63032 matches from patch 2.7 up until patch 2.9. There is complete coverage of all games at Master.\r\nThe games are then filtered using the following methodology:\r\nI estimate the win rate (WR) and their confidence interval (CI) for all match ups (MU) using all shards and games played in patch 2.7/2.8 I could include patch 2.9 as it should not have changed the direction of many MU (if not at all) but “better safe than sorry”.\r\n\r\n\r\n\r\nI filter all MU whose CI doesn’t include 50% or have less than 500 games, as aside for the mirror it’s possible to have MU which are too near the 50% benchmark. Actually the only case aside for the mirror that’s included with the “500 games clause” it’s Nightfall whose data suggest to have a negative direction for Azir/Irelia. Still, Nightfall is grouped with the “counter” decks.\r\n\r\n\r\nopponent\r\n\r\n\r\nmuWin\r\n\r\n\r\nmuGames\r\n\r\n\r\nmuWR\r\n\r\n\r\nLCI\r\n\r\n\r\nUCI\r\n\r\n\r\nAzir / Irelia\r\n\r\n\r\n6007\r\n\r\n\r\n12014\r\n\r\n\r\n0.5000000\r\n\r\n\r\n0.4910185\r\n\r\n\r\n0.5089815\r\n\r\n\r\nDiana / Nocturne\r\n\r\n\r\n246\r\n\r\n\r\n505\r\n\r\n\r\n0.4871287\r\n\r\n\r\n0.4427301\r\n\r\n\r\n0.5316788\r\n\r\n\r\nThe reason to filter the data is to be sure enough about the direction of the MU. Of the archetypes (champion+regions) left I group them as “counters” or “weak” depending is the WR is below or higher than 50% for Azir/Irelia meaning is Azir Irelia has a 55% against such MU, it’s a “weak” deck.\r\n\r\n\r\n\r\nBy filtering I reduce all cases to 87.3% at the matches collected. Of these 19.1% are made from mirrors which are also excluded.\r\nAt least for the global results this doesn’t seems to effect the overall “performance” of Azir/Irelia\r\n\r\n\r\ncumulative WR\r\n\r\n\r\n(filtered) cumulated WR\r\n\r\n\r\n54.14%\r\n\r\n\r\n54.29%\r\n\r\n\r\nAll that’s left is computing the cumulative play rates and win rates of Azir/Irelia either at a global scale or shard-specific.\r\nNote: since it can be an interesting info, those are the combinations that counters Irelia:\r\n\r\n\r\n\r\n\r\nFor those who may complain about the small numbers of some of these cases: this is exactly why I filtered to those with a good enough CI. They may be rare occurrences but the direction is safe enough. Not to mention that if you are interested just in the direction of the MU we can use a binomial test with \\(H_0\\) and an unidirectional with alternative hypothesis: true probability of success is less than 0.5\r\nAll values not only are below the 0.05 benchmark, but also below 0.01. We are really confident about those MU directions.\r\nResults\r\n\r\n\r\nAll Shard\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 1: Global trend\r\n\r\n\r\n\r\n\r\n\r\nEU Shard\r\n\r\n\r\n\r\nFigure 2: EU trend\r\n\r\n\r\n\r\n\r\n\r\nNA Shard\r\n\r\n\r\n\r\nFigure 3: NA trend\r\n\r\n\r\n\r\n\r\n\r\nAsia Shard\r\n\r\n\r\n\r\nFigure 4: Asia trend\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "analysis/an-irelia-s-world/an-irelia-s-world_files/figure-html5/plot-global-1.png",
    "last_modified": "2021-07-21T13:04:46+02:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 936
  },
  {
    "path": "analysis/lmi/",
    "title": "Developing a LoR-Meta score",
    "description": "Recreating  the viciousSyndicate (vS) - Meta Score for Legends of Runeterras.",
    "author": [
      {
        "name": "Valentino (Legna) Vazzoler",
        "url": {}
      }
    ],
    "date": "2021-06-04",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nDefining our parameter of interest (Framework)\r\nData selection\r\nTesting Filters\r\n\r\nNormalization\r\nMinMax Normalization\r\nQuantile normalization\r\n\r\nAggregation (and weighting)\r\nRanking methods\r\nAggregating Ranks: Borda\r\n\r\nLMI (final)\r\nAppendix\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIntroduction\r\nIf you are/were interested in Hearthstone, its metagame and its “data” you probable know about vicioussyndicate (vS)\r\nAmong the data they provide probably one of the most interesting is the “Meta Score”\r\nFrom their F.A.Q.\r\n\r\nQ: What is the meaning of the Meta Score and how do you compute it?\r\nThe Meta Score is a supplementary metric that measures each archetype’s relative standing in the meta, based on both win rate and prevalence, and in comparison to the theoretical “best deck”.\r\n\r\nHow is it computed?\r\n\r\n…\r\nWe take the highest win rate recorded by a current archetype in a specific rank group, and set it to a fixed value of 100. We then determine the fixed value of 0 by deducting the highest win rate from 100%. For example, if the highest win rate recorded is 53%, a win rate of 47% will be set as the fixed value of 0. This is a deck’s Power Score. The range of 47% – 53%, whose power score ranges from 0 to 100, will contain “viable” decks. The length of this range will vary depending on the current state of the meta. Needless to say, it is possible for a deck to have a negative power score, but it can never have a power score that exceeds 100.\r\nWe take the highest frequency recorded by a current archetype in a specific rank group, and set it to a fixed value of 100. The fixed value of 0 will then always be 0% popularity. This is a deck’s Frequency Score. A deck’s frequency score cannot be a negative number.\r\nWe calculate the simple average of a deck’s Power Score and Frequency Score to find its vS Meta Score. The vS Meta Score is a deck’s relative distance to the hypothetical strongest deck in the game. Think of Power Score and Frequency Score as the coordinates (x, y) of a deck within a Scatter Plot. The Meta Score represents its relative placement in the plane between the fixed values of (0, 0) and (100,100).\r\nIf a deck records both the highest popularity and the highest win rate, its Meta Score will be 100. It will be, undoubtedly, the best deck in the game.\r\n\r\nThe final result usually looks like this\r\n\r\n\r\n\r\nThe size of the circles represent the meta score, the bigger it is the bigger the value.\r\nNow, before asking ourselves to translate this methodology in LoR, what’s the theory behind the Meta Score?\r\nThe Meta Score, in this case a LoR-Meta Index (LMI) is an extremely simple example of a Composite Indicator (CI).\r\nA composite indicator is the result of combining multiple variables usually into a single value. If you ever heard of a ranking among cities / companies / universities, and so on, chances are that it’s done with a Composite Indicator.\r\nIn my opinion, even among other statistic’s fields, creating a CI is more like an art. There is no perfect indicator (as there’s no perfect model ) at most there good and bad indicators. Even if their creation can be entirely data driven, most of the works stem from a theoretical framework that it’s very subjective. There are 10 main steps and each one of them can highly change the overall result. This doesn’t mean that one can’t trust a CI, there are ways of checking the quality of a CI but that’s almost an entirely problem I won’t tackle for this case-study.\r\nWhile building a CI can be quite the challenge, creating a LMI is not as hard as some of the required steps are (in this case) not necessary or quite simplified.\r\nDefining our parameter of interest (Framework)\r\nThe objective of the CI is to measure the “strength” of the current meta decks. Usually the context and more details are added but overall that stength is a combination of “win rates”, “play rates”, “consistency” and probably other variables I don’t remember here, in the context of LoR I would probably add something like maybe “the ability to interact with the opponent”.\r\nThe definition I’ll use is the following\r\n\r\nThe performance of a deck is defined by its own strength and popularity inside the metagame.\r\n\r\nData selection\r\n\r\n\r\n\r\nSadly, for now, this step it’s way simplified: to measure the strength I’m going to use the win rate and to measure the popularity I’ll use the play rate. 12\r\nThe variables have been selected, but what about their values? Do we keep everything or filter them? To check this point let’s try to simply compute the LMI and take the 10 highest values without filters. (Fig. 1)\r\n\r\n\r\n\r\nFigure 1: LMI no filter\r\n\r\n\r\n\r\nWhile it may seems like there’s an error, sadly the graph is not wrong. If we keep all data (Appendix 1 ) , aside for the first 2 values of the LMI (corresponding to Nasus/Thresh and Azir/Irelia) the remaining 8 points are all at the coordinate (0,1) with Meta Score of 0.5.\r\nWithout filtering we left the outlier cases of 100% WR decks that also have a very small playrate. With this the “WR index” correspond the raw WR3 and just the frequencies are modified.\r\nIn order to find just the third point that’s not an outlier, we have to reach the 72° deck (Draven/Ez with a meta score of 0.45). While some choices about how to measure the index could deal with these extreme cases it’s not a good choice, it’s best to remove them from the start. Let’s try to remove the cases with less than 100/200/300 games.\r\nA quick look at the summary (below) of WR suggest that 200/300 gives similar results. Looking at PlayRate doesn’t really makes sense as the value is directly tied to the number of games played.\r\nSummary with Filter at 100:\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n 0.2077  0.4182  0.4580  0.4512  0.4932  0.6229 \r\n\r\nSummary with Filter at 200:\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n 0.2995  0.4356  0.4695  0.4614  0.4965  0.5827 \r\n\r\nSummary with Filter at 300:\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n 0.2995  0.4358  0.4688  0.4603  0.4956  0.5827 \r\n\r\nTo help me deciding I also created the Meta-score plots with the vS methodoly at the 3 benchmark for the filter.\r\nNote: the following plots only needs to give an idea about the distribution of the decks on WR and Play Rate. The specific values for each deck are not of interest here.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTesting Filters\r\n\r\n\r\nFilter at 100\r\n\r\n\r\n\r\nFigure 2: LMI filter at 100 (vS)\r\n\r\n\r\n\r\n\r\n\r\nFilter at 200\r\n\r\n\r\n\r\nFigure 3: LMI filter at 200 (vS)\r\n\r\n\r\n\r\n\r\n\r\nFilter at 300\r\n\r\n\r\n\r\nFigure 4: LMI filter at 300 (vS)\r\n\r\n\r\n\r\n\r\n\r\nThe first thing that comes to notice is that no matter what there are probably too many values near 0 of the Freq Index. This will be important in the next steps.\r\nOverall, there are some minor changes jumping from 100 to 200 games min and a bit less from 200 to 300.\r\nFiltering at 100 games may be too low as benchmark as the values are still too sensible to the sample size.\r\n300 games seems ok but may be too harsh at removing “sleeper decks”, one need to consider that the sample sizes of LoR - Master rank data are not that high, so now it the filter may be too harsh, for now.\r\n\r\n\r\n\r\nAlso, worth noticing, the point’s radius doesn’t seems to change much for the plotted points and the radius here is proportional the LMI suggesting that the range of the index (for positive values) is a bit limited and it is confirmed when looking at the tabular data. (Appendix 2 )\r\nSo are we done? No, we haven’t even started. Let’s explain the following point to consider when creating a CI.\r\nNormalization\r\nNormalization usually refer to the process of rescaling a variable so that its domain is [0,1]\r\nTo compute the vS Meta score we don’t use the raw values of WR and playrate but the rescaled ones obtained following the rules described at the start. Usually this is done in order to bring the different variables to a more common scale, and, from a certain point of view the raw data are already like that, or at least they have theoretically the same range, but, their effect range is quite different and so is their variability.\r\nIn order to understand the value (and necessity of this process) it’s better to also show what would have been the results without such process.\r\n\r\n\r\n\r\nFigure 5: LMI with no Normalization\r\n\r\n\r\n\r\nFrom 5 it’s possible to see how, without normalization, we are completely at the mercy of the raw data and their “limitations”.\r\nFor WR we have the problem that the values are limited to a small interval.\r\nFor Play rate not only it’s limited to a small interval but the data are quite skewed too with an heavy right tail and everything else concentrated around of the 0.005. This is most likely a sistematic problem in the data compared to HS, at least looking at vS. In their latest meta report (#197) even the smallest (reported) archetype have a decent 2.62% play rate. Sure there are many more decks that have a lower playrate but still the distribution looks less skewed without a huge discrepancy from the top.\r\nThe variables’ limitation is reflected of course in the LMI. See Fig. 6 to compare the LMI distribution with and without normalization and Table ?? to consult the data without normalization.\r\n\r\n\r\n\r\nFigure 6: Comparing LMI distribution with and without normalizazion (vS methodology)\r\n\r\n\r\n\r\nIt can be seen the normalization here allows for a wider range of values being able to discern better the differences between each deck. As written at the start, it’s not that without normalization the index is not working as intended, that the index is wrong, but it’s not doing a good job, it’s a bad index. So, now that the role of normalization is clearer, how is it done? The choice is actually tied with the following step but here are the most common methods:\r\n\r\n\r\n\r\n\r\nMin-max: \\(I_i= \\frac{x_i - max(x)}{max(x) - min(x)}\\) the min and max value are 0 and 1, everything else is scaled between them\r\nStandardization \\(I_i = \\frac{x_i - \\mu_x}{\\sigma_x}\\) centered around the mean and with standard deviation equal to 1\r\nDistance to a reference \\(I_i = \\frac{x_i}{x_c}\\) each value is the ratio against a reference value\r\nRank \\(I_i = rank(x_i)\\) self-explanatory\r\nQuantile empircal distribution \\(I_i = \\frac{rank(x_i)}{N+1}\\)\r\nand so many more.\r\nThe normalization used for the vS-Meta score are modified example of of the min-max normalization. For the “Freq Score” there’s almost no difference from minmax as long as there’s a value with playrate almost equal to 0. For the “Power Score” (WR Index) the “min” and 1-max(WR) instead of the min(WR) in the data. I think the reason for using such method for the Power Score, is as follows: while by itself the distribution of WR is overall quite good. it wouldn’t be surprising if top decks had a win rate too much similar so limiting the effect of the power-score.\r\nMinMax Normalization\r\nThe resulting values of the Freq Index are the ones I’m more interested too see how how they are affected by the normalization.\r\nIn addition to testing the rescaling to the raw values I’ll also test with the log-transformation and root-squared-transformation (sqrt) of playrate in order to deal with the high unbalance of its values. I’m aware that both transformations are not scale-invariant and for some people it may give too much value to deck with a small playrate.\r\nYet, not being stuck with scale-invariant processes is really limiting and I think this is a point worth considering in the context of Legends of Runeterra (and MtG most likely). In LoR decks are created around champions and regions, so the possible combinations are quite a lot and many of these can be good without being “meme decks”. This is the sistematic problem mentioned before this section and it means that the game is bound to be filled of decks with small playrates deck and only a selected few with a very high value resulting in a distribution that’s very right tailed.\r\n\r\n\r\n\r\nI’ll start by showing the different distribution on Freq Index (Fig. 7) and then showing the resulting LMI (Fig. 8)\r\n\r\n\r\n\r\nFigure 7: Boxplot of Freq Index when applying minmax normalization to: raw values / log-transformation / sqrt\r\n\r\n\r\n\r\nThe log-transformation seems to reduce well the skewness, the question is if it reduce it too much and the sqrt is more appropriate for this case study. I computed LMI for each case (Appendix 3) and looked at the LMI distribution (Fig. 8)\r\n\r\n\r\n\r\nFigure 8: Boxplot of LMI when applying: vS / minmax / log trasnformation + minmax / sqrt + minmax\r\n\r\n\r\n\r\nCompared to the vS-methodology, just using the minmax normalization gives the most similar results. When using the log or sqrt transformation of playrate all the values of LMI are bigger, which is as expected as we don’t penalize as much small playrates. Again, There is no correct answer, it depends on what’s the objective of the index. For example if we wanted to limit the results to just the top n highest decks, not adding a transformation may actually be more interesting as we would see bigger differences. Since I want to convey all the values then reducing the skewness may be more appropriate and would opt for the log-transformation.\r\n\r\n\r\n\r\nFigure 9: LMI / filter at 200 / log-tranformation of playrate / Minmax normalization\r\n\r\n\r\n\r\nIn the scatter plot it seems that the main “aestetic” difference is that the points are more aggregated to the right side of the chart because of all the high values of WR index. It’s not like this is wrong and it’s sort of obvious that the highest values of LMI correspond at high values of WR. Compared to the vS-methology it’s also possible to notice an higher variance of LMI among the top values. This approach seems to work “better” overall.\r\nQuantile normalization\r\n\r\n\r\n\r\nNote: instead of the proper formula, I’ll use \\(I_i = \\frac{rank(x_i)}{N}\\). The reason being so that the highest value is always 1.\r\nWhen using the quantile normalization, boxplots and other summaries of the transformed distributions are useless since such normalization will result into a uniform distribution. (Fig. 13 )\r\n\r\n\r\n\r\nFigure 10: LMI / filter at 200 / Quantile normalization\r\n\r\n\r\n\r\nI actually like this result compared to the minmax one. While the obvious critique is that decks like Azir/Irelia and Nasus/Thresh are not “a class of their own” like the raw data suggest (high WR but also extremely high playrate) this methodology not only cover well the spectrum of values for LMI but also for WR and Freq. Since it can further be improved I’ll continue now with the next steps using the Quantile normalization.\r\nAnother type of normalization is working with ranks. But since that directly translate in the following steps I’ll cover it later.\r\nAggregation (and weighting)\r\nThis step comprehend two equally important procedures: Decide how the importance/relevance of each variable when computing the index and how to aggregate those values.\r\nRegarding the weighting we can’t really do that much. Either we opt for the same weight (0.50/0.50) without changing anything from the current metholody or the opt for any other justified convex combination.\r\nSince in my opinion the Win rate is more important than play rate to measure the strength of a deck I’ll try assigning the (0.75,0.25) and (\\(\\frac{2}{3}\\),\\(\\frac{1}{3}\\)) more as a test. If people are interested in this topic I may try to poll the general opinion about the proper weight (Weight by public opinion / Delphi).\r\nRegarding the aggregation methods, while there are infinite possibilities the main question is: should the variable have compensatory properties?\r\nWhat it means in this case is: can a drop in Win rate be compensated by an higher value in play rate for the overall results (and viceversa)? By using an arithmetic mean we have full compensability, a drop of 0.2 in WR score can be compensated with an increase of 0.2 of Freq score. This property is problably the main reason I wanted to tackle the vS methodolgy as not only I don’t think this should be a case of full compensability but the results are affected by their normalization of choice. Again, it’s not that their method is wrong. But I think it can be improved, at least for LoR.\r\nSo, what are the alternatives to the aritmetic means? All the power mean of order r actually, and all of the other have different level of compensability. Usually the most common choices are:\r\nGeometric mean: \\(\\mu = \\prod_{i=1}^{n}x_{i}^{w_i}\\)\r\npartial compensability, equal to zero if any variable is zero\r\nHarmonic mean: \\(\\mu = \\left(\\sum_{i=1}^{n}\\frac{w_i}{x_{i}}\\right)^{-1}\\)\r\npartial compensability, less than the geometric mean, not defined is a variable is equal to zero\r\n\\(x_i\\) are the variable values of index i and \\(w_i\\) their corresponding weight\r\nThis two formulas are also a reason why I can appreciate the quantile normalization more than the minmax, because of the values I would obtain. With the minmax I would also have at most two decks with a zero in them and I wanted to avoid this case.\r\nSo, with 3 different weighting vectors and 3 aggregation methods to compare we have 9 different results to compare (Tab.5. And this is as extremely simple case…\r\n\r\n\r\n\r\n… still, my decision about how to compute the LMI in this process is relatively simple. Unless I want to give to “Freq Ind” compared to “WR Ind”, I don’t think there’s the necessity to use a weighted mean, it would only accentuate the skewness I wanted to deal with. The remaining choice is between the 3 proposed means, I don’t want full compensability so I exclude the aritmetic mean, then since I used a quantile normalization that gives a uniform distribution but I still want to penalize “the origina small values”, the harmonic mean is the harsher of the two.\r\n\r\n\r\n\r\nFigure 11: LMI / filter at 200 / Quantile normalization / Harmonic mean\r\n\r\n\r\n\r\nRanking methods\r\nThe remaining steps are related to the validation of an Index, the visualization process and other quality checks, the aggregation was the last steps of the “computation phase”. This “quality checks” are a vast topic but it’s not really necessary for such simple CI. So, now, as mentioned right before the aggregation step, I’ want to I’ll try to use a different approach to Normalization and Aggregation: working with ranks. It means that the variable are reduced to their ranking order. Of course this is only possibles with variables that can be ordered, so for example not with most categorical data. The order of course doesn’t have to be from the max to the min, it depends of the correlation between the variables and the objective of the Index. For example if we won’t an “Environmental Index”, CO2 levels can be ranked from the min to the max. Transforming the direction of a variable can be used also in the previous context but here it’s as, if not more important. I’ll only introduce one ranking method: Borda ranking method.\r\n\r\n\r\n\r\nAggregating Ranks: Borda\r\nThe method is quite simple: first of all, for each item in a variable we assign a value corresponding at how high the item is ranked.\r\nExample If we have 5 values for the variable X: (0.6,0.4,1,0,0.2) their ranking is -> (2,3,1,5,4) -> if we give 0 point to the min value, 1 to the second to last and so on until N-1 (with N the number of values of X) we have the result points -> (3,2,4,0,1). In order to improve a little the results and readability I’ll change a little the rules by giving from 1 to N points.\r\nWe repeat this for each variable and then we sums the point by rows.\r\nIt’s also possible to aggregate ranks simply by computing their mean / median. There are also more complex method like Copeland, CKYL but they are “wasted” with only two variables. In case this Index is expanded in the future I may try to use them.\r\nAs usual the results can be consulted in the Appendix ??\r\n\r\n\r\n\r\nFigure 12: LMI / filter at 200 / Borda method\r\n\r\n\r\n\r\nFig.12 is the only case it this case study where we can’t maintain the same axis range as we are dealing with the ranks. Also, here it’s possible to understand why I decided to assign N and not N-1 point to the first ranked, so that the theoretical best deck would be at coordinate (N,N) instead of (N-1,N-1) which would have been a bit less intuitive. it also mean that the worst theoretical deck instead of being at (0,0) now it would be at (1,1).\r\nIf the plot seems similar to the Quantile one (11) it’s because it is, the quantile normalization is pretty much a conversion to the ranks. Does it means that they are equal? No. There are advantage and disadvantage for each choice. Personally I would give an edge to the Quantile and the other (not-ranbking methods) as there are more options when using a linear scale.\r\nLMI (final)\r\nAs explained in the previous steps, to compute the LMI I currently decide to use the following methodology:\r\nFiltering data with less than 200 games\r\nUsing the variables: Win Rates / Play Rate\r\nQuantile normalization\r\nHarmonic Mean as aggregation\r\nThe result is the following plot. In this case it’s possible to hover on each point to see their values. I also modified the range of the points’ radius to accentuate the differences.\r\n\r\n\r\n\r\nAnd of course the data in a tabular format, ordered by decreasing LMI.\r\n\r\n\r\n\r\nTo conclude, I hope this work can be a foundation for more elaborate discussions and think how the index can be improved / expanded. The Riot API may not provide a lot of data, but there is still already so much can be done.\r\n\r\nAppendix\r\n\r\n\r\n\r\n\r\n\r\nTable 1: Data no Filter games\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 2: Data filtered of decks without at least 200 games\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 2: Data no Normalization\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 3: Minmax table\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 4: Quantile table\r\n\r\n\r\n\r\n\r\n\r\n\r\nTable 5: Aggregation table\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 13: Boxplot of LMI when applying: vS / quantile / minmax+log trasnformation to playrate / minmax+sqrt transformation to playrate\r\n\r\n\r\n\r\nThe following is the table of the data I used for this analysis. I already filtered the cases with less than 100 games.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nIf anyone reading this document have a good idea to suggest feel free to suggest it by contacting me.↩︎\r\nData from Master rank from Patch 2.7 to 2.8 included.↩︎\r\nWith the max WR = 100% and its complementary to 100 which is 100-100=0, the scale still remain 0 to 100%↩︎\r\n",
    "preview": "analysis/lmi/images/LMI.png",
    "last_modified": "2021-07-21T10:51:13+02:00",
    "input_file": {},
    "preview_width": 624,
    "preview_height": 384
  }
]
