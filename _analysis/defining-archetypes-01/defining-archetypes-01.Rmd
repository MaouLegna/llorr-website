---
title: "Defining Archetypes #1: Looking at the similarity of Akshan/Sivir/Zed with similar archetypes"
description: |
  First entry on a series of article that will gather my explorations over different way to define archetypes in Legends of Runeterra
base_url: https://www.llorr-stats.com
preview:
author:
  - name: Valentino (Legna) Vazzoler
date: 09-06-2021
output:
 distill::distill_article:
    toc: true
    toc_float: true    
    toc_depth: 3
    self_contained: false
citation: false
draft: FALSE
twitter:
  site: "@Maou_Legna"
  creator: "@Maou_Legna"
params:
  # prev:  "2021-07-07 21:00:00" #UTC tz / 'previous' week start
  start: "2021-07-14 21:00:00" #UTC tz / 'current' week start
  end:   "2021-08-25 21:00:00" #UTC tz / 'current' week end
  skip:  1850000  # Patch 2.11 - after removing a few games  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  comment = NA,
  R.options = list(width = 140,
                   digits.secs=6),
  dev.args = list(bg = 'transparent'), # make graphics with transparent background
  fig.align = 'center',
  fig.width=9,
  fig.height=6,
  engine.path = list(
    python = 'C:/anaconda/'   # -> use_python("C:/anaconda/")
  ),
  #'distill options
  layout="l-body-outset",
  preview=FALSE
)

#' R Option
source(file.path("C:","LlorR","scripts","lor_main.R" ))

# require(Hmisc)    # provides knitrSet and other functions
xaringanExtra::use_panelset()
#' Python
# py_run_string("print('Hello World')")
# lor_deckcodes <- import("lor_deckcodes")
# py_module_available("lor_deckcodes")
```

```{r}
theme_Publication <- function(base_size=14, base_family="helvetica") {
      library(grid)
      library(ggthemes)
      (theme_foundation(base_size=base_size, base_family=base_family)
       + theme(plot.title = element_text(face = "bold",
                                         size = rel(1.2), hjust = 0.5),
               text = element_text(),
               panel.background = element_rect(colour = NA),
               plot.background = element_rect(colour = NA),
               panel.border = element_rect(colour = NA),
               axis.title = element_text(face = "bold",size = rel(1)),
               axis.title.y = element_text(angle=90,vjust =2),
               axis.title.x = element_text(vjust = -0.2),
               axis.text = element_text(), 
               axis.line = element_line(colour="black"),
               axis.ticks = element_line(),
               panel.grid.major = element_line(colour="#f0f0f0"),
               panel.grid.minor = element_blank(),
               legend.key = element_rect(colour = NA),
               legend.position = "bottom",
               legend.direction = "horizontal",
               legend.key.size= unit(0.2, "cm"),
               legend.margin = unit(0, "cm"),
               legend.title = element_text(face="italic"),
               plot.margin=unit(c(10,5,5,5),"mm"),
               strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
               strip.text = element_text(face="bold")
          ))
      
}

scale_fill_Publication <- function(...){
      library(scales)
      discrete_scale("fill","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}

scale_colour_Publication <- function(...){
      library(scales)
      discrete_scale("colour","Publication",manual_pal(values = c("#386cb0","#fdb462","#7fc97f","#ef3b2c","#662506","#a6cee3","#fb9a99","#984ea3","#ffff33")), ...)

}
```

```{r twitter-meta, echo = FALSE}
library(metathis)
meta() %>%
  meta_description(
    "First entry on a series of article that will gather my explorations over different way to define archetypes in Legends of Runeterra"
  ) %>% 
  meta_viewport() %>% 
  meta_social(
    title = "Defining Archetypes #1: Looking at the similarity of Akshan/Sivir/Zed with similar archetypes",
    url = "https://llorr-stats.netlify.app/",
    image = "images/archetypes/A01-ASZSZ.png",
    image_alt = "ASZSZ",
    og_type = "website",
    og_author = "Legna",
    twitter_card_type = "summary",
    twitter_creator = "@Maou_Legna"
  )
```


```{r panelset-style}
xaringanExtra::style_panelset_tabs(font_family = "Roboto",
                                   active_foreground = "white",
                                   hover_foreground = "black",
                                   hover_border_color = "black",
                                   active_background = "#007fff"
                                   )
```

# Introduction

This series of article/analysis are meant to rappresent my journey in how to define archetypes.

Archetypes in Legends of Runeterra are *currently* defined by me by the combinations of champions and regions. While it's a lazy method, it's (was?) a first approximation that worked decently aside for some exception. A limitation I always knew is that the number of possible archetypes increase too rapidaly with the release of new cards and will probably get too high compared to the number of available games (at least at Master) sooner or later. On the other side of the spectrum the most restricting classification would with a categorical (maybe even just dichotomical) variable, something like using the **Super Archetypes** from viciousSyndicate (vS): *Initiative* and *Resource* decks [^1]. Every other archetype classification is in immediatiate and it's a vast ocean of possibilities with no 'correct' solution.

As everything needs to be done step by step, I'll start with what was pointed to me a few weeks ago:

```{r tweet1}
# require(tweetrmd)
# tweetrmd::tweet_screenshot(tweetrmd::tweet_url("drlor4", "1420488109603442688"),maxwidth = 400, file="./images/archetypes/tweet1-1.png")
# include_graphics("images/archetypes/tweet1-1.png")
tweetrmd::include_tweet("https://twitter.com/drlor4/status/1420488109603442688",plain = TRUE)
```

Around the times Dragons and Overwhelm (SH/FR) decks turned into legit meta options, decks with 3 champions have become more widely used and they are their *acceptance* as legit option has increased, no more being just a bad choice by default.

During the times of that tweet, in the patch 2.12/2.13 there was an higly performing deck with three champions: Akshan/Sivir/Zed (ASZ).

What I aim to answer is related so the suggestion in the tweet : is my current aggregation too strict? Is Sivir/Zed or Akshan/Sivir the same deck as ASZ, only lacking a champion? While by intuition they may looks similar, it's not a proper answer which I tried to respond with this article. [^2]

[^1]: their definition, example and so on will be a topic for the future.

[^2]: I'm aware that the aggregation problem is not limited to cases with three champions, some cases may even be related to a single card like "Feel the Rush" or "ARAM (Howling Abyss)" but as mentioned, one must proceed with baby steps and this is probably a good starting point.

# Data

```{r raw-data}
#' load gameDT
#'############
file.DT <- file.path("C:","LlorR","data","raw","LoR_MatchDT.csv")
header        <- fread(file.DT, header = FALSE, na.strings = c("",NA), nrows = 1, stringsAsFactors = FALSE)
LoR.Match.RMD <- fread(file.DT, header = FALSE, na.strings = c("",NA), skip = params$skip ) # ~2.11/2.12
colnames(LoR.Match.RMD) <- unlist(header,use.names = F)

#' load Account
#'#############
file.Account <- file.path("C:","LlorR","data","raw","LoR_ACCOUNT.csv")
LoR.Account.RMD <- fread(file.Account, header=T, na.strings = c("",NA), encoding = 'UTF-8') %>%
  mutate( RiotID = paste(gameName,tagLine),refID = puuid_4 ) %>%
  pivot_longer(
  cols = c("puuid","puuid_1","puuid_2","puuid_3","puuid_4"),
  names_to = "origin",
  values_to = "puuid"
)

#' load DeckDT
#'############
LoR.Deck        <- fread(file.path("C:","LlorR","data","raw","LoR_DECK.csv"),na.strings = c("",NA))
```

```{r account-info}
masterEU   <- LoR.Account.RMD %>% filter(activeShard=="europe"   & master=="master") %>% distinct(gameName,tagLine) %>% count() %>% pull()
masterNA   <- LoR.Account.RMD %>% filter(activeShard=="americas" & master=="master") %>% distinct(gameName,tagLine) %>% count() %>% pull()
masterASIA <- LoR.Account.RMD %>% filter(activeShard=="asia"     & master=="master") %>% distinct(gameName,tagLine) %>% count() %>% pull()

namesList.EU.RMD     <- length(lor_leaderboard("europe")$name)
namesList.NA.RMD     <- length(lor_leaderboard("americas")$name)
namesList.ASIA.RMD   <- length(lor_leaderboard("asia")$name)
```

```{r prepare-data}
LoR.Melt.Matches.RMD <- LoR.Match.RMD %>%
  #' Base filters
  ###############
  filter( game_type=="Ranked" ) %>%
  filter( game_start_time_utc >= as.POSIXct(params$start, tz = "UTC") & game_start_time_utc < as.POSIXct(params$end, tz = "UTC") ) %>%
  #' 'process' data
  #################
  left_join(.,LoR.Deck[,.(deck_code,archetype)] %>% setnames(old = "archetype", new = "player_1")   ,by=c("deck_code_1"="deck_code")) %>%
  left_join(.,LoR.Deck[,.(deck_code,archetype)] %>% setnames(old = "archetype", new = "opponent_1") ,by=c("deck_code_2"="deck_code")) %>%
  mutate( player_2 = opponent_1, opponent_2 = player_1, oppoppuid_1 = puuid_2, oppoppuid_2 = puuid_1 ) %>%
  select( match_key,server,game_start_time_utc,game_version,total_turn_count,
          ends_with("_1"),ends_with("_2"),-ends_with("_3"),-ends_with("_4"),-contains("deck_id"),-contains("participants") ) %>%
  #' melt data
  ############
  melt(id.vars=c("match_key","server","game_start_time_utc","game_version","total_turn_count"), measure.vars=patterns(
    str_sub(
      names(select(.,ends_with("_1")))
      ,end = -3)
  ),
  value.name = str_sub(
    names(select(.,ends_with("_1")))
    ,end = -3)
  ) %>%
  #' finish 'process' data
  ########################
  left_join(. , LoR.Account.RMD[,c("puuid","RiotID","refID")] %>% setnames(old = "RiotID", new = "userID")     ,by=c("puuid"="puuid")) %>%
  left_join(. , LoR.Account.RMD[,c("puuid","RiotID")] %>% setnames(old = "RiotID", new = "opponentID") ,by=c("oppoppuid"="puuid")) %>%
  left_join(.,LoR.Deck %>% select(!archetype),by=c("deck_code","factions")) %>%
  #' nChamp
  #########
  rowwise() %>%
  mutate(champions = extract_champions(c_across(contains("Champion")) ) ) %>%
  ungroup() %>%
  mutate( nChamp = str_count(champions,pattern = "/")+1) %>%
  mutate( nChamp = replace(nChamp, str_detect(player,"Championless"),0) ) %>%
  select(-ends_with("puuid"),-refID)
```

The sample is made of `r NROW(LoR.Melt.Matches.RMD)` Ranked games from `r params$start` to `r params$end`, so covering the patch 2.12/2.13 after the start of the Ruination Event so that there aren't any changes in the card pool in the timeframe analyzed by amount of cards or balance changes.

Because there was the raise of the Demacian deck with Akshan/Sivir, these decks are removed as they could create a few problem in the following steps. In addition I only consider decks with 6 copies of champions (the max value). This is done to remove the outliers in deck creation and making the sample more homogeneous for a step that will follow.[^3]

```{r ASZ}
#' Akshan / Sivir / Zed abs freq
################################
ASZ.DT <- LoR.Melt.Matches.RMD |>
  filter( !is.na(Champion.06) ) |>
  filter( champions == "Akshan / Sivir / Zed" )

LoR.Melt.Matches.RMD <- LoR.Melt.Matches.RMD |> 
  filter( !is.na(Champion.06) ) |>
  filter( player != "Akshan / Sivir (DE/SH)" ) 

nGames <- LoR.Melt.Matches.RMD |>
  NROW()
```

The sample is reduced to `r nGames` games

```{r compute-table-nChamp}
require(gtsummary)
require(gt)

tbl1 <- LoR.Melt.Matches.RMD %>%
  mutate( SZ = ifelse( (str_detect(champions,"Sivir") & str_detect(champions,"Zed"))  ,"Sivir/Zed","no Sivir/Zed") ) %>%
  select(nChamp,SZ) %>%
  gtsummary::tbl_summary(., by = SZ, label = nChamp ~ "#Champion") %>%
  gtsummary::add_overall()
  # gtsummary::as_gt() %>%
  # gt::tab_source_note(gt::md(glue::glue("Ranked games from {params$start} to {params$end}")))

tbl2 <- LoR.Melt.Matches.RMD %>%
  mutate( SZ = ifelse( (str_detect(champions,"Sivir") & str_detect(champions,"Akshan"))  ,"Sivir/Akshan","no Sivir/Akshan") ) %>%
  select(nChamp,SZ) %>%
  gtsummary::tbl_summary(., by = SZ, label = nChamp ~ "#Champion")
  # gtsummary::add_overall()
  # gtsummary::as_gt() %>%
  # gt::tab_source_note(gt::md(glue::glue("Ranked games from {params$start} to {params$end}")))
  
tbl <- tbl_merge( 
    tbls = list(tbl1, tbl2),
    tab_spanner = c("**Zed**", "**Akshan**")
  )
  # modify_spanning_header(stat_0_1 ~ NA)

tbl %>%
  as_gt() %>%
  tab_options(
    table.background.color = "transparent",
    table.font.color = "black",
    table.font.color.light = "black"
  )
```

```{r compute-champ-data}
#' nchamp freq
tblData <- LoR.Melt.Matches.RMD %>%
  tabyl(nChamp)

#' overall freq of 3 champ decks
################################
nChamp3.percent <- tblData %>%
  filter(nChamp == 3) %>%
  pull(percent) %>%
  percent(accuracy = 0.01)

nChamp3 <- tblData %>%
  filter(nChamp == 3) %>%
  pull(n)
  
#' freq of decks with 3 champs among decks with Sivir Zed
##########################################################
SZ3.percent <- LoR.Melt.Matches.RMD %>%
  mutate( SZ = ifelse( (str_detect(champions,"Sivir") & str_detect(champions,"Zed"))  ,"Sivir/Zed","no Sivir/Zed") )

#' Absolute number for SivirZed3
################################
SZ3 <- LoR.Melt.Matches.RMD %>%
  mutate( SZ = ifelse( (str_detect(champions,"Sivir") & str_detect(champions,"Zed"))  ,"Sivir/Zed","no Sivir/Zed") ) %>%
  filter( SZ == "Sivir/Zed" ) %>%
  tabyl(nChamp) %>%
  filter(nChamp == 3) %>%
  pull(n)

#' Absolute number for SivirAkshan3  
###################################
SA3 <- LoR.Melt.Matches.RMD %>%
  mutate( SZ = ifelse( (str_detect(champions,"Sivir") & str_detect(champions,"Akshan"))  ,"Sivir/Akshan","no Sivir/Akshan") ) %>%
  filter( SZ == "Sivir/Akshan" ) %>%
  tabyl(nChamp) %>%
  filter(nChamp == 3) %>%
  pull(n)

# sprintf(paste0("",round(tblData[4,"percent"]*100,2),"%%"))
```

```{r print-table-nChamp}
# tbl
```

`r kableExtra::text_spec("Note :", color = "red")` The percetages are column-wise

The overall prevalence of '3 champions deck' is around `r nChamp3.percent`. This value is mostly carried by the ASZ decks with `r NROW(ASZ.DT)` games which amoutn to almost half the cases of 3 champs decks `r round(NROW(ASZ.DT)/nChamp3,3)*100`%

More specificaly, those `r NROW(ASZ.DT)` ASZ decks are the main subset of both SZ decks when using 3-champions (`r round(NROW(ASZ.DT)/SZ3,3)*100`% of the cases) and for AZ decks too (`r round(NROW(ASZ.DT)/SA3,3)*100`% of the cases). In other words, when a third champion is added to SZ or AZ decks the result is almost always an ASZ, meaning ASZ seems a common ground to both these two archetypes. But are ASZ just a common ground or the general cases are already almost equal (AZ and SZ).

[^3]: all deck with no Champion or mono Champion are excluded by default because of this.

# Methods

## Hierarchy of steps

This section illustrate the mathematical/statistical theory and application I'll use to tackle the question the article's question.

But before that, what are the steps I want to follows?

```{r venn-AS, fig.cap="ASZ as special case of AS", out.width = '50%'}
tbl_1<-tibble(
    AkshanSivir=rep(1, 8),
    AkshanSivirZed=c(1,1,1,0,0,0,0,0)
)

plot(eulerr::euler(tbl_1))
```

```{r venn-SZ, fig.cap="ASZ as special case of SZ", out.width = '50%'}
tbl_2<-tibble(
    SivirZed=rep(1, 8),
    AkshanSivirZed=c(1,1,1,0,0,0,0,0)
)

plot(eulerr::euler(tbl_2))
```

As mentioned I first need to see if the hyphothesis rappresented in the venn diagrams (Fig:\@ref(fig:venn-AS) and Fig:\@ref(fig:venn-SZ)) is correct: ASZ is just a special case of one/or both of AS or SZ.

```{r venn-cross, fig.cap="ASZ as special case of both AS and SZ", out.width = '50%'}
# Input in the form of a named numeric vector
tbl_cross <- eulerr::euler(c("A" = 10, "B" = 5, "A&B" = 5))

# Add a custom legend and retain quantities
# plot(tbl_cross, labels = list(labels = c("SivirZed", "AkshanZed"))) +
plot(tbl_cross, labels = list(labels = c("SivirZed", "AkshanZed")))
```

If it's true for both, then I will check AS and SZ can be considered similar, so, by looking at Fig:\@ref(fig:venn-cross) how the intersection is, if Sivir/Zed and Akshan/Zed do seems to overlap and how.

## Distance among decks

When looking at a deck it's possible to visualize them a network-graph where each node is a card and the edges the connection between cards.

```{r example-graph}
require(Rcpp)
require(tidytext)
require(igraph)

require(tidygraph)
require(ggraph)

data <- tibble( matchid = c(1),
                value = c("04SH020 04SH020 04SH020 04SH130 04SH130 04SH130 04SH103 04SH103 04SH093 04SH055")
)

#' All cards, not correct
# nodes <- LoR.Card %>%
#   as_tibble() %>%
#   select(cardCode) %>% 
#   rowid_to_column("id") %>%
#   rename(label = cardCode)

#' Only the cards in the data, correct approach
nodes <- data %>%
  select(value) %>%
  separate_rows(., value, convert = TRUE) %>%
  distinct() %>% 
  rowid_to_column("id") %>%
  rename(label = value)
  
edges <- data %>%
  tidytext::unnest_tokens(input = value, output = bigram, to_lower = FALSE, token = 'skip_ngrams', n = 4) %>%
  mutate(num_words = map_int(.x = .$bigram, .f = ~ ngram::wordcount(.x))) %>%
  filter(num_words == 2) %>%
  select(-num_words) %>%
  separate(col = "bigram", into = c("card_1", "card_2"), sep = " ") %>%
  count(card_1, card_2, sort = TRUE, name = "weight") %>%
  # left_join(LoR.Set %>% select(cardCode, Name_1 = name), by = c("card_1" = "cardCode")) %>%
  # left_join(LoR.Set %>% select(cardCode, Name_2 = name), by = c("card_2" = "cardCode")) %>%
  left_join(nodes, by = c("card_1" = "label")) %>%
  rename(from = id) %>%
  left_join(nodes, by = c("card_2" = "label")) %>%
  rename(to = id) %>%
  select(from, to, weight)

nodes_name <- nodes |>
  left_join(LoR.Set[,c("cardCode","name")], by =c("label"="cardCode") ) |>
  select(-label) |>
  rename("label"="name")
```

```{r print-example-graph, fig.cap="Deck as a Network graph", out.width = '75%'}
# visNetwork::visNetwork(nodes_name, edges)

graph_from_data_frame(edges , directed = TRUE, vertices = nodes_name ) %>%
ggraph() + 
  geom_edge_link(length = unit(1, 'mm')) + 
  geom_node_label(aes(label = label), repel = TRUE) +
  # geom_node_text(aes(label = label), colour = 'black', vjust = 0.4) + 
  ggtitle('Network graph',
          subtitle = 'Example with Cards') + 
  geom_node_point(size = 5, colour = 'steelblue') +
  theme_graph()
```

It's possible than to expand the concept to archetypes where they would be a collection of decks, expanding the graph to more cards and for example adding the information related to the playrates of cards and which are commonly played toghether by using weighted edges.

The advantage of this approach for the question of this article would be having to compare a single item for each archetype, the archetype-network, but with the disadvantage of working with a more complex structure which is the reason it's not applied in this paper.

To compare archetypes we start by comparing decks, but what does it means to "compare" decks? To compare somethings we must to able to measure the similarity or dissimilarity which requires the use of a metric. What follows in an example to illustrate an example of metric and how to evalute the similarity of decks.

Suppose we have the following decks of 10 cards:

```{r create-code}
# getCardCode("Merciless Hunter")
# getCardCode("Shaped Stone")
code1 <- lordecks::get_code_from_decklist(c("2:01IO009","2:04SH020","2:04SH130","2:04SH103","2:04SH093"))
code2 <- lordecks::get_code_from_decklist(c(            "3:04SH020","3:04SH130","2:04SH103","2:04SH093"))
# Problematic
code3 <- lordecks::get_code_from_decklist(c(            "3:04SH020","3:04SH130","2:04SH103","2:04SH055"))
code4 <- lordecks::get_code_from_decklist(c(            "3:04SH020","3:04SH130","2:04SH103","1:04SH093","1:04SH055"))
```

```{r print-codes}
lordecks::get_decklist_from_code(code1) |>
  left_join(LoR.Set[,c("name","cardCode")], by = c("cardcode"="cardCode") )

lordecks::get_decklist_from_code(code2) |>
  left_join(LoR.Set[,c("name","cardCode")], by = c("cardcode"="cardCode") )
```

The only differences are the champions and their amount.

Overall there's a similarity of 8 (out of 10) or a distance of 2 (out of 10).

It can proven that this is indeed what it's called a *distance* or *metric* as it has all the necessary properties:

-   Not-negative codomain, so $[0,Inf)$[^4]. This is true as it's definite in $[0,40]_\mathbb{N}$

<!-- -->

-   $d(x,y) = d(y,x)$ (Simmetry)

-   $d(x,x)=0$

-   $d(x,y)\leq d(x,z)+d(z,y)$ (The Triangle inequality)

<a href="https://twitter.com/drisoth/">Drisoth</a> already showed that it can be used with success in hierarchical clustering (DBSCAN in his case)[^5] to good success.

While a proper metric, there is a problem with this measure that makes us prefer another one. The following example explain the problem with the "counting of cards difference", it could be said that the metric lack subtlety as it doesn't reward decks having a similar distribution of cards' copies as can be seen in the following example:

```{r print-codes-problem}
lordecks::get_decklist_from_code(code2) |>
  left_join(LoR.Set[,c("name","cardCode")], by = c("cardcode"="cardCode") )

lordecks::get_decklist_from_code(code3) |>
  left_join(LoR.Set[,c("name","cardCode")], by = c("cardcode"="cardCode") )

lordecks::get_decklist_from_code(code4) |>
  left_join(LoR.Set[,c("name","cardCode")], by = c("cardcode"="cardCode") )
```

The difference among these deck is the same at 2 cards, what changes are either 2 copies or Merciless Hunter, 2 copies of Ruin Runner or a single copy for both of the cards Marciless Hunter and Ruin Runner.

Again, we want to remark, this is not "wrong", just we would prefer an alternative with more discriminatory power. A possible solution, is the commonly used metric that add this nuance, the *cosine distance*.

The *cosine similarity* is defined as:

<!-- @ref(eq:cosine) -->

```{=tex}
\begin{equation}

\cos(A,B) = \frac{A \cdot B}{||A||_2||B||_2} (\#eq:cosine)

\end{equation}
```
which can be written as

<!-- @ref(eq:cosinesum) -->

```{=tex}
\begin{equation}

\cos(A,B) = \frac{\sum{A_iB_i}}{ \sqrt{\sum{A^2_i}} \sqrt{\sum{B^2_i}}} (\#eq:cosinesum)

\end{equation}
```
The measure runs from 0 (orthogonal vectors or maximum dissimilarity) to 1 (parallel vectors or maximum similarity) so with max and min at the opposite cases of what we want as it is indeed a measure of similarity and not dissimilarity. The *cosine distance* is simply defined as 1 - cosine similarity.

The previous example that would always have same distance 0.2

$$
\begin{bmatrix}
0 & 0.2 & 0.2 \\
0.2 & 0 & 0.2 \\
0.2 & 0.2 & 0
\end{bmatrix}
$$

have now distance matrix:

```{r latex-matrix}
deck.matrix <- matrix(c(3,3,2,2,0,
                        3,3,2,0,2,
                        3,3,2,1,1),byrow = T,nrow=3 )
DSim <- eisen_cos.sim(deck.matrix) %>% as.matrix()

write_matex <- function(x) {
  begin <- "$$\\begin{bmatrix}"
  end <- "\\end{bmatrix}$$"
  X <-
    apply(x, 1, function(x) {
      paste(
        paste(x, collapse = "&"),
        "\\\\"
      )
    })
  writeLines(c(begin, X, end))
}

write_matex2 <- function(x) {
  begin <- "\\begin{bmatrix}"
  end <- "\\end{bmatrix}"
  X <-
    apply(x, 1, function(x) {
      paste(
        paste(x, collapse = "&"),
        "\\\\"
      )
    })
  paste(c(begin, X, end), collapse = "")
}

# write_matex(round(DSim,2))
# write_matex2(round(DSim,2))
```

$$`r write_matex2(round(DSim,2))`$$

```{r}
# A <- matrix(c(1, 3, 0, 1), 2, 2)
# B <- matrix(c(5, 3, 1, 4), 2, 2)
# 
# # Utility function to print matrices in proper LaTeX format
# print_mat <- function(mat) {
#   n <- nrow(mat)
#   c('\\begin{bmatrix}',
#     paste0(sapply(seq_len(n - 1),
#                   function(i) paste0(mat[i, ], collapse = ' & ')),
#            ' \\\\'),
#     paste0(mat[n, ], collapse = ' & '),
#     '\\end{bmatrix}')
# } 
# 
# # ```{r, results = 'asis'}
# writeLines(c('$$',
#              print_mat(round(DSim,2)),
#              '$$'))
```

It's now possible to better explain the reason why the data was restricted to cases with 6 copies of Champions cards.

We have to measure the similarity in three different archetypes (AS,SZ,ASZ) and no matter our choices, from the raw data we would always find at least a difference related to one card among these archetypes.

For example between an AS and SZ deck the min card-difference would be a single copy of Akshan with a single copy of Zed because of the definition of archetypes applied.

In order not to have to account the difference in champions and the number of their copies we will evalutate the difference among all non-champion cards. If the distance is zero or near it, it would mean that aside for the champions of choice the decks are similar giving support to the hypthesis of being part of the same "archetype". Or, to put it differently, we modify out data so that when comparing different deck from different archetypes the possible values for the cosine distance remain in $[0,1]$ helping the comparison in the following steps, without for example having to rescale the values. Because of the choice of removing the champions there's the suggestion of also filtering all cases with less than 6 champions cards. While it's possible to compute the cosine distance with deck of a different number of cards computable for this problem we consider more appropriate working with decks with the same number of cards.

[^4]: Not actually a properties but a requirement in its definition

[^5]: <a href="https://twitter.com/Drisoth/status/1397716499104681984?s=20">Archetypes - Cluster</a>

## Decklist Distance Matrix

We described how to compare single decks but we want to answer a question related to archetypes. To do as such, let's say we want to start with the comparison with AS and ASZ, from the decklist/deckcode of these decks we create the distance matrix among decks.

$A={\begin{pmatrix}A_{{11}}&A_{{12}}\\A_{{21}}&A_{{22}}\end{pmatrix}}$

Where A is a $(n+m)×(n+m)$ simmetric block matrix where

* n is the number of deckcodes/decklist from $Archetype_1$

* m is the number of deckcodes/decklist from $Archetype_2$

* $A_{{11}}$ is the $n×n$ distance matrix relative to deck of $Archetype_1$

* $A_{{22}}$ is the $n×n$ distance matrix relative to deck of $Archetype_2$

* $A_{{12}}=A_{{21}}^T$ is the $n×m$ matrix containing the distances between $Archetype_1$ vs $Archetype_2$

What we propose is to compare the values between $A_{{11}}$, $A_{{22}}$ [^6] and $A_{{12}}$ with the hyphotesis that if the archetypes are indeed similar/equal the distances should have the same mean (and variance) which is equivalent to apply and ANOVA test.

[^6]: As $A_{{11}}$ and $A_{{22}}$ are simmetric matrix relative to the same Archetype's decks we'll only use the values from the upper triangular matrix without diagonal.

# Analysis

```{r n-unique-decks}
nAS <- LoR.Melt.Matches.RMD |>
  filter( player == "Akshan / Sivir (IO/SH)" ) |>
  distinct(deck_code) |>
  NROW()

nSZ <- LoR.Melt.Matches.RMD |>
  filter( player == "Sivir / Zed" ) |>
  distinct(deck_code) |>
  NROW()

nASZ <- LoR.Melt.Matches.RMD |>
  filter( player == "Akshan / Sivir / Zed" ) |>
  distinct(deck_code) |>
  NROW()
```

```{r define-functions}
# Don't need I just need to set the values of the card column to 0
#
# rm_asz <- function(deck_code) {
#   deck_code %>%
#   # "CMCACAICBQAQEAQFAEBQEGIGAQDRIJRWG5OWOAYBAMBAUAIEA6BACAYBAILCKMICAECAPCQBAIAQECI2" %>%
#     lordecks::get_decklist_from_code() |>
#     dplyr::filter( cardcode %!in% c("01IO009","04SH120","04SH130") ) |>
#     lordecks::get_code_from_decklist_df()
# }
```

```{r modify-deckcode}
AS.half <- LoR.Melt.Matches.RMD |>
  filter( player == "Akshan / Sivir (IO/SH)" ) |>
  tabyl(deck_code) |>
  arrange(desc(n)) |>
  mutate( cumFreq = cumsum(percent) ) |>
  filter( cumFreq <= 0.50 ) |>
  # count() # 60
  pull(deck_code)

SZ.half <- LoR.Melt.Matches.RMD |>
  filter( player == "Sivir / Zed" ) |>
  tabyl(deck_code) |>
  arrange(desc(n)) |>
  mutate( cumFreq = cumsum(percent) ) |>
  filter( cumFreq <= 0.50 ) |>
  # count() # 49
  pull(deck_code)

ASZ.half <- LoR.Melt.Matches.RMD |>
  filter( player == "Akshan / Sivir / Zed" ) |>
  tabyl(deck_code) |>
  arrange(desc(n)) |>
  mutate( cumFreq = cumsum(percent) ) |>
  filter( cumFreq <= 0.50 ) |>
  # count() # 10
  pull(deck_code)
```

Not all deckcodes have been used to create the submatrices of the block matrix. The number of *unique deckcodes* for each archetypes was considered too big, relative to the number of games [^7], and as each deck have the same weight there could be risk of not properly rapresenting the distances distribution by using all deckcodes. Only the most frequent deck codes that account for at least 50% of the games have been used `r length(AS.half)` decks for AS, `r length(SZ.half)` decks for SZ, `r length(ASZ.half)` decks for ASZ.

[^7]: `r nAS` decks for AS, `r nSZ` decks for SZ, `r nASZ` decks for ASZ

Two distance matrix have been created for AZ decks vs ASZ decks and SZ decks vs ASZ decks.

Results are provided in Tab:\@ref(tab:ASZvsAS) and Fig:\@ref(fig:plot-ASZ-AS) for the ASZ vs AS decks while for ASZ vs SZ decks in Tab:\@ref(tab:ASZvsSZ) and Fig:\@ref(fig:plot-ASZ-SZ)

```{r ASZ-AS}
deck.matrix <- LoR.Card$cardCode %>% purrr::map_dfc(setNames, object = list(numeric()))
codes <- c(ASZ.half,AS.half)

for (i in 1:length(codes)) {
  # decklist <- codes[1] %>% get_decklist_from_code()
  decklist <- codes[i] %>% get_decklist_from_code()
  deck.matrix[NROW(deck.matrix)+1, decklist$cardcode] <- as.list(decklist$count)
}

deck.matrix <- deck.matrix |>
  mutate( across(everything(), ~replace_na(.x, 0))  ) |>
  mutate( across(c("01IO009","04SH120","04SH130"), ~0)  )

DSim.AS.ASZ <- eisen_cos.sim(deck.matrix)

sub.DSim.1 <- as.matrix(DSim.AS.ASZ)[1:length(ASZ.half),1:length(ASZ.half)]
sub.DSim.2 <- as.matrix(DSim.AS.ASZ)[(length(ASZ.half)+1):NROW(DSim),(length(ASZ.half)+1):NROW(DSim)]
sub.DSim.X <- as.matrix(DSim.AS.ASZ)[1:length(ASZ.half),(length(ASZ.half)+1):NROW(DSim)]

DSim.tbl_1 <- rbind(
  tibble( value = sub.DSim.1[upper.tri(sub.DSim.1)],
          group = "ASZ" ),
  tibble( value = sub.DSim.2[upper.tri(sub.DSim.2)],
          group = "AS" ),
  tibble( value = sub.DSim.X %>% as.vector(),
          group = "ASZvsAS" )
)
```

```{r summary-ASZ-AS}
# require(flextable)
# library(officer)
DSim.tbl_1 |>
  group_by(group) |>
  summarise(across(.fns = list(mean = mean, sd = sd, skew = psych::skew), .names = "{fn}")) |>
  rename_all(~str_to_title(.)) |>
  mutate( across(where(is.numeric), ~round(.,3) ) ) |>
  # summarise(across(.fns = list(mean = mean, sd = sd, skew = psych::skew), .names = "{col}_{fn}")) |>
  flextable::flextable() %>%
  flextable::set_caption(., "Summary statistic ASZvsAS decks", autonum = officer::run_autonum(seq_id = "tab", bkm = "ASZvsAS"))
```

```{r plot-ASZ-AS, fig.cap="distribution of cosine distances for ASZ vs AS decks"}
DSim.tbl_1 |>
  ggplot(aes(x = value, fill=group)) +
  geom_density() +
  theme(legend.position = "bottom") +
  xlim(c(0,0.5)) +
  # envalysis::theme_publish()
  ggsci::scale_fill_npg() +
  # ggsci::scale_fill_jama() +
  # scale_fill_Publication() +
  theme_Publication() +
  labs(x = "Distance") +

DSim.tbl_1 |>
  # mutate( group = factor(group) ) |>
  ggplot(aes(x = group, y = value, fill=group)) +
  geom_boxplot() +
  ylim(c(0,0.5)) +
  theme(legend.position = "none") +
  coord_flip() +
  ggsci::scale_fill_npg() +
  theme_Publication() +
  labs(y = "Distance", x = "") +
  plot_annotation(title = 'Distances distribution',
                  subtitle = 'ASZ vs AS decks',caption = 'cosine distances between the deckcodes that accounts for at least 50% of the games played') +
  plot_layout(guides = 'auto', ncol = 2,widths = c(6, 4))

ggsave("./images/archetypes/A01-ASZAS.png")
```
```{r ASZ-SZ}
deck.matrix <- LoR.Card$cardCode %>% purrr::map_dfc(setNames, object = list(numeric()))
codes <- c(ASZ.half,SZ.half)

for (i in 1:length(codes)) {
  # decklist <- codes[1] %>% get_decklist_from_code()
  decklist <- codes[i] %>% get_decklist_from_code()
  deck.matrix[NROW(deck.matrix)+1, decklist$cardcode] <- as.list(decklist$count)
}

deck.matrix <- deck.matrix |>
  mutate( across(everything(), ~replace_na(.x, 0))  ) |>
  mutate( across(c("01IO009","04SH120","04SH130"), ~0)  )

DSim.SZ.ASZ <- eisen_cos.sim(deck.matrix)

sub.DSim.1 <- as.matrix(DSim.SZ.ASZ)[1:length(ASZ.half),1:length(ASZ.half)]
sub.DSim.2 <- as.matrix(DSim.SZ.ASZ)[(length(ASZ.half)+1):NROW(DSim),(length(ASZ.half)+1):NROW(DSim)]
sub.DSim.X <- as.matrix(DSim.SZ.ASZ)[1:length(ASZ.half),(length(ASZ.half)+1):NROW(DSim)]

DSim.tbl_2 <- rbind(
  tibble( value = sub.DSim.1[upper.tri(sub.DSim.1)],
          group = "ASZ" ),
  tibble( value = sub.DSim.2[upper.tri(sub.DSim.2)],
          group = "SZ" ),
  tibble( value = sub.DSim.X %>% as.vector(),
          group = "ASZvsSZ" )
)
```

```{r summary-ASZ-SZ}
DSim.tbl_2 |>
  group_by(group) |>
  summarise(across(.fns = list(mean = mean, sd = sd, skew = psych::skew), .names = "{fn}")) |>
  rename_all(~str_to_title(.)) |>
  mutate( across(where(is.numeric), ~round(.,3) ) ) |>
  # summarise(across(.fns = list(mean = mean, sd = sd, skew = psych::skew), .names = "{col}_{fn}")) |>
  flextable::flextable() %>%
  flextable::set_caption(., "Summary statistic ASZvsSZ decks", autonum = officer::run_autonum(seq_id = "tab", bkm = "ASZvsSZ"))
```

```{r plot-ASZ-SZ, fig.cap="distribution of cosine distances for ASZ vs SZ decks", preview=TRUE}
DSim.tbl_2 |>
  ggplot(aes(x = value, fill=group)) +
  geom_density() +
  theme(legend.position = "bottom") +
  xlim(c(0,0.5)) +
  # envalysis::theme_publish()
  ggsci::scale_fill_npg() +
  # ggsci::scale_fill_jama() +
  # scale_fill_Publication() +
  theme_Publication() +
  labs(x = "Distance") +
  
DSim.tbl_2 |>
  # mutate( group = factor(group) ) |>
  ggplot(aes(x = group, y = value, fill=group)) +
  geom_boxplot() +
  ylim(c(0,0.5)) +
  theme(legend.position = "none") +
  coord_flip() +
  ggsci::scale_fill_npg() +
  theme_Publication() +
  labs(y = "Distance", x = "") +   
  # guide_area() + 
  plot_annotation(title = 'Distances distribution',
                  subtitle = 'ASZ vs SZ decks',caption = 'cosine distances between the deckcodes that accounts for at least 50% of the games played') +
  plot_layout(guides = 'auto', ncol = 2,widths = c(6, 4))

ggsave("./images/archetypes/A01-ASZSZ.png")
```
And lastly we show the result of the ANOVA applied first for AZ decks

```{r ANOVA}
# AS_aov <- aov(value ~ group, data = DSim.tbl_1)
# look at effects and interactions
print(summary(aov(value ~ group, data = DSim.tbl_1)))
# this extracts ANOVA output into a nice tidy dataframe
# tidy_AS_aov <- tidy(AS_aov)
```
Here we don't reject $H_0$ as the p-values (the values the $Pr(>F)$ columns ) is above 0.05 giving support to the hyphotesis that ASZ is just a special case of AS and they can be aggregated.

In th case with SZ decks the ANOVA test gives:

```{r print ANOVA}
print(summary(aov(value ~ group, data = DSim.tbl_2)))
```
Meaning we reject the null hyphotesis $H_0$ that the distances are from the same population and their distribution is the same. But while this is true, we can also see that the value is near 0.5 meaning it would be wiser to check Tukey post-hoc tests.

```{r tukey}
tukey.test <- TukeyHSD(
  aov(value ~ group, data = DSim.tbl_2)
) 

tukey.test
```
```{r print-tukey, fig.cap="Tukey Post-Hoc test"}
# Plot pairwise TukeyHSD comparisons and color by significance level
ggplot(tidy(tukey.test), aes(colour=cut(adj.p.value, c(0, 0.01, 0.05, 1), 
                           label=c("p<0.01","p<0.05","Non-Sig")))) +
  geom_hline(yintercept=0, lty="11", colour="grey30") +
  geom_errorbar(aes(contrast, ymin=conf.low, ymax=conf.high), width=0.2) +
  geom_point(aes(contrast, estimate)) +
  ggsci::scale_color_npg() +
  theme_Publication() +
  labs(title = "95% family-wise confidence level",
       x="Contrast",
       y="Differences in mean levels of group",
       colour="")
```

We can see that the rejection for the ANOVA test can be explained by the resulting differences for SZ and ASZ decks. But simply looking at the threshold of 0.05 would ignore how this is a very borderline result. So, while rules *are not* meant to be broken (when doing analysis) this is a rare case where we don't blindy follows the raw numbers, meaning we accept the hyphotesis that SZ and ASZ too are from the same population / or the same Archetype.

# Conclusion

The analysis gives support to the hyphotesis of aggregating the archetypes defined as ASZ, SZ and AS as Dr.LoR suggested. [^8]

[^8]: any change will probably occour on the first report after the release of this article.

Further testing should check is the sample and condition we choose are too strict or too lenient.

The next article in this series will introduce the application of hierarchical clustering methods to the archetypes problem both replicating Drisoth methodology and possible alternatives.
