---
params:
  title: "CI?! What is a Confidence Interval?"
  description: "A little guide to understanding and use/read them and why TLC is in the mix?!"

title: | 
  `r params$title`
description: |
  `r params$description`
base_url: https://www.llorr-stats.com
author: Valentino (Legna) Vazzoler
date: 2022-06-11
output:
 distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    self_contained: false
citation: false
# bibliography: references.bib
draft: TRUE
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo       = FALSE,
  eval       = TRUE,
  warning    = FALSE,
  error      = FALSE,
  message    = FALSE,
  comment    = NA,
  R.options  = list(width = 140, digits.secs=6),
  dev.args   = list(bg = 'whitesmoke'),
  fig.align  = 'center',
  fig.width  = 12,
  fig.height = 8,
  # fig.path   = "figures/prefix-"
  fig.path   = glue::glue("images/{params$ind}-"),
  layout     = "l-page",
  preview    = TRUE
)

# R Option
# options(scipen = 999)
source(file.path("C:","LlorR","scripts","lor_main.R" ))
# source(file.path("C:","LlorR","scripts","functions","lor_constants.R"))
source(file.path("C:","LlorR","scripts","functions","lor_functions.R"))
xaringanExtra::use_panelset()
```

```{r panelset-style}
xaringanExtra::style_panelset_tabs(
  font_family        = "Helvetica",
  active_foreground  = "white",
  hover_foreground   = "black",
  hover_border_color = "black",
  active_background  = "#007fff"
  )
```

```{r twitter-meta, echo = FALSE}
metathis::meta() |>
  metathis::meta_description(params$description) |>
  metathis::meta_viewport() |>
  metathis::meta_social(
    title = params$title,
    url = "https://www.llorr-stats.com/",
    image = "",
    image_alt = "",
    og_type = "website",
    og_author = "Legna",
    twitter_card_type = "summary",
    twitter_creator = "@Maou_Legna"
  )
```

# Introduction

**Player A**: "This deck is way better than yours. You see, it even reached a 55% WR at Master this week!"

**Player B**: "You fool! You clearly didn't see the latest values as mine is obviously the superior version with a 55.5% WR at Master this week!"

**Voice in the background**: "Little did they know both decks win-rates were actually the same"

For those who use my content one may notice that I use something called Confidence Interval (CI) or similarly those who use [Storm](https://twitter.com/storm_lor) [deck tracker](https://app.lormaster.com/meta) can see he adds a $\pm X$ value to a deck win-rate. That is a confidence interval.

While the intuition may easily tell how to read them, it's also really, really easy to misunderstand them.

Here, we'll explain what they are, how they are computed, why you should almost always require their use and also why/how you shouldn't look too much into them.

If the last two points seems a contradiction they are not but we will try to convey the underling reasoning.

> Hi, Legna here, while normally I try to write those *analysis* articles in a publication-style format this post is meant to be an easier read for most players.
>
> I would like to say that this is the first of a series of articles meant to explain some statistical concepts in order to better understand the data and their nuances but I can hardly guarantee it, I will try, but most likely the cadence will be slow. Even this article took weeks not because the content is hard, but mostly because of a combination of little time plus needing to understand what and how to write the content.

Let us start with this example:

* Between a deck with a 55% WR from 20 games and a deck with 53% WR from 100.000 games which deck is probably safer/better to choose?

If ones goes by the typical twitter-level analysis 55% > 53% and so the first deck is the better choice.

Most people (I hope) would disagree as 53% is the more stable value. Why is that?

Because the more data we have, *the more we reduce the effect of chance* and  the data will converge to its *true value / true win-rate* ^[which would require an infinite amount of games.]

The example in this case was too easy, so it was *easy* to answer. Later we will provide some example not as obvious.

# Easy Level - A sort of TLDR

As counter-intuitive as it may be we need to start with what is **not** a confidence interval:

> A Confidence Interval (CI) is not the probability that the true value of our estimate in inside a certain interval. For such case the true value is either contained or not and so the probability is either 1 (it's inside) or 0 (it's outside)

*Add an easy explanation*

> Let's say we have a deck with 58.5% WR and CI of [57%, 60%]. A CI doesn't mean that there is 95% probability that the true win-rate in between 57% and 60%. If the **true win-rate** is 58% the value is inside the interval and so the proability of being inside it is 100%. If the true value was 56.5% then the probability of the true value being inside the CI was 0%. If, for example if the true value is 58% then it's contained and the probability is one, if it's 55% then it's outside the range and the probability is zero

A CI is a natural extension of a single point estimate (a single value) and it provides information about the variability, stability of our estimate, the WR.

```{r}
n  <- 1000
x  <- 600
p  <- x/n
LL <- p - qnorm(0.975)*sqrt( (p*(1-p))/n )
UL <- p + qnorm(0.975)*sqrt( (p*(1-p))/n )

CI <- glue::glue("[{scales::percent(LL,accuracy = 0.1)},{scales::percent(UL,accuracy = 0.1)}]")

# binom::binom.confint(x = 600,n = 1000, conf.level = 0.95)
```

Let us take a deck with `r n` games and `r x` wins, the 60% WR estimate obtained as $\frac{\#wins}{\#games}$ is a point estimate while the CI is `r CI`.

Their use is intrinsically connection with hypothesis testing so CI also provides a rigorous frame about how to interpret them.

Suppose we we would test if the deck WR is 60%%.

As we can see that the CI does includes that value 57% < 60% < 63%, then we don't reject hypothesis that the WR is indeed 60%.

On the other hand, if the CI was, let's say [54.0%,57.0%] then we would reject the hypothesis that the WR is 60%, having support that the true win-rates lies elsewhere.

> It's very important to be careful how to interpret a statistical hyphotesis. One **NEVER PROVES** something, but it can reject an hypothesis, giving at most *support* to the opposite but never proving it. Think of SCP-55, all that is known is that it is not round, what shapes does it have are still an infinite amount of alternative options

Now, let us use the example from the introduction.

We have two decks, one with WR at 55.5% and one with WR at 55%. How can we say with confidence that they do indeed differ?

```{r example-wIntersection, fig.width=6, fig.height=4}
n_intro <- 10^4

intro_example <- rbind(
binom::binom.confint(x = 5500, n = n_intro, conf.level = 0.95, methods = "asymptotic"),
binom::binom.confint(x = 5550, n = n_intro, conf.level = 0.95, methods = "asymptotic")
)

intro_example |>
  add_column(deck = c("deckA","deckB")) |>
  mutate(deck = factor(deck, levels = c("deckB","deckA"),ordered = T) ) |>
  as_tibble() |>
  ggplot(aes(x = lower, y = deck, xend = upper, yend = deck, colour = deck)) +
  geom_segment() +
  geom_vline(aes(xintercept  = lower[2]), linetype = 2, alpha = 0.5 ) +
  geom_vline(aes(xintercept  = upper[1]), linetype = 2, alpha = 0.5 ) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1) ) +
  labs(
    x = element_blank(),
    y = element_blank()
  ) +
  theme_539() +
  scale_colour_hue("clarity") +
  theme(legend.position = "none")
```
We simply look at their CI and check if their intervals do overlap or not. It they overlap their difference is not statistically significant.

In Fig:\@ref(fig:example-wIntersection) the line overlap -> we don't reject the equality of win-rates -> there is support on the **equality of win-rates**.

```{r example-woIntersection, fig.width=6, fig.height=4}
tibble(
  deck = c("deckA","deckB"), 
  lower = c(0.52, 0.545),
  upper = c(0.54, 0.58)
  ) |>
  mutate(deck = factor(deck, levels = c("deckB","deckA"),ordered = T) ) |>
  ggplot(aes(x = lower, y = deck, xend = upper, yend = deck, colour = deck)) +
  geom_segment() +
  geom_vline(aes(xintercept  = lower[2]), linetype = 2, alpha = 0.5 ) +
  geom_vline(aes(xintercept  = upper[1]), linetype = 2, alpha = 0.5 ) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1) ) +
  labs(
    x = element_blank(),
    y = element_blank()
  ) +
  theme_539() +
  scale_colour_hue("clarity") +
  theme(legend.position = "none")
```
We proceed in the same way for the example illustrated in Fig:\@ref(fig:example-woIntersection)

The line don't overlap -> we reject the equality of win-rates -> there is support on the **inequality of win-rates**.

So everything seems pretty easy: lines overlap = no difference, no overlap = different enough...

... well, no, unless you are working on a very important model you don't want to be as strict and try to consider each case

```{r example-fringe, fig.width=6, fig.height=4}
wr_1 = 0.54
n_1 = 250
wr_2 = 0.63
n_2 = 1000

CI_1 <- binom::binom.confint(x = round(wr_1*n_1),n =  n_1, 0.95, methods = "exact")[4:6]
CI_2 <- binom::binom.confint(x = round(wr_2*n_2),n =  n_2, 0.95, methods = "exact")[4:6]

tibble(
  deck = c("deckA","deckB"), 
  lower = c(CI_1$lower, CI_2$lower),
  upper = c(CI_1$upper, CI_2$upper)
  ) |>
  mutate(deck = factor(deck, levels = c("deckB","deckA"),ordered = T) ) |>
  ggplot(aes(x = lower, y = deck, xend = upper, yend = deck, colour = deck)) +
  geom_segment() +
  geom_vline(aes(xintercept  = lower[2]), linetype = 2, alpha = 0.5 ) +
  geom_vline(aes(xintercept  = upper[1]), linetype = 2, alpha = 0.5 ) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1) ) +
  labs(
    x = element_blank(),
    y = element_blank()
  ) +
  theme_539() +
  scale_colour_hue("clarity") +
  theme(legend.position = "none")
```
Here the two lines overlap but personally we would reject the equality of win-rates. It happens for a very small section and maybe the sample size is not even that big for deckA. ^[deckA has 250 games, while deckB has 1000 games]

We don't want to say that sometimes there are no rules, it's more that things are not so black and white and one must learn to navigate in the infinite sea of grey.

So, after this what I must conclude is that one must decide subjectively each time? Once we set some rules we should try to follow them as much as we can.

**How we can use the CI for positive or negative WR**



**If we look too many data we will most likely find in false positive**




# Mid Level - Reject Points, embrace Intervals

When one has access to some (continuous) data, one of the easiest statistics we can compute is the sample mean $\bar X $, yet while effective the mean greatly reduce the overall information and we have no idea about the uncertainty of our results as we mentioned in the first example.

If we have a bunch of games results classified as either 0 or 1 a win-rate estimate will be the simple mean $\bar x = \sum_i^n x_i$

In order to expand from a point estimation we can switch to an interval estimation

**Add how the number of games required for a better interval gros exponentially**

# Hard Level - TLC, when Lissandra is doing statistics

```{r}
binom::binom.confint(x = c(2, 4), n = 100, tol = 1e-8)

x = 2
n = 4
alpha = 0.05

p <- x/n
p <- 0.6
# alpha <- 1 - conf.level
alpha2 <- 0.5 * alpha
z <- qnorm(1 - alpha2)
z2 <- z * z

se <- sqrt(p * (1 - p)/n)
lcl <- p - z * se
ucl <- p + z * se
```



```{r create-example}
set.seed(123)

n = 30
# stats::runif(n) > (1 - p)
sample1 <- purrr::rbernoulli(n = 30, p = 0.55) |> as.numeric()
# skimr::skim(sample1)
```








A confidence interval for a population mean is of the following form
x¯±z⋆sn−−√

You should by now be comfortable with calculating the mean and standard deviation of a sample in R. And we know that the sample size is 60. So the only remaining building block is finding the appropriate critical value for a given confidence level. We can use the qnorm function for this task, which will give the critical value associated with a given percentile under the normal distribution. Remember that confidence levels and percentiles are not equivalent. For example, a 95% confidence level refers to the middle 95% of the distribution, and the critical value associated with this area will correspond to the 97.5th percentile.

We can find the critical value for a 95% confidence interal using

```{r}
z_star_95 <- qnorm(0.975)
z_star_95

# ## [1] 1.959964
# which is roughly equal to the value critical value 1.96 that you’re likely familiar with by now.
# 
# Let’s finally calculate the confidence interval:

samp %>%
  summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
            upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))
```

```{r}
params <- ames %>%
  summarise(mu = mean(area))

# Exercise: Does your confidence interval capture the true average size of houses in Ames?
# 
# params$mu
# ## [1] 1499.69

samp %>%
  summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
            upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))

ci <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - z_star_95 * (sd(area) / sqrt(n)),
                  upper = mean(area) + z_star_95 * (sd(area) / sqrt(n)))

ci <- ci %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))

# ci %>%
#   slice(1:5)

ci_data <- data.frame(ci_id = c(1:50, 1:50),
                      ci_bounds = c(ci$lower, ci$upper),
                      capture_mu = c(ci$capture_mu, ci$capture_mu))

ggplot(data = ci_data, aes(x = ci_bounds, y = ci_id, 
                           group = ci_id, color = capture_mu)) +
  geom_point(size = 2) +  # add points at the ends, size = 2
  geom_line() +           # connect with lines
  geom_vline(xintercept = params$mu, color = "darkgray") # draw vertical line


ci_99 <- ames %>%
        rep_sample_n(size = n, reps = 50, replace = TRUE) %>%
        summarise(lower = mean(area) - z_star_99 * (sd(area) / sqrt(n)),
                  upper = mean(area) + z_star_99 * (sd(area) / sqrt(n)))

ci_99 <- ci_99 %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))

ci_data_99 <- data.frame(ci_id = c(1:50, 1:50),
                      ci_bounds = c(ci_99$lower, ci_99$upper),
                      capture_mu = c(ci_99$capture_mu, ci_99$capture_mu))

ggplot(data = ci_data_99, aes(x = ci_bounds, y = ci_id, 
                           group = ci_id, color = capture_mu)) +
  geom_point(size = 2) +  
  geom_line() +           
  geom_vline(xintercept = params$mu, color = "darkgray") 
```

## Article 2

Review of Confidence Intervals
When we compute a confidence interval, we first compute an estimate of a parameter with a statistic.

For example, we draw a random sample then compute the sample mean to estimate the parameter.

With a single sample (or anything short of the whole population) we don’t know where the population mean lies, so we want to localize the population mean within an interval, computed from the data in the sample.

An interval is a range of values (e.g. all real numbers between 4801 and 6801: written [4801, 6801]). A confidence interval is a range of plausible intervals for the parameter. A 95% confidence interval for a parameter is an interval computed by a method guaranteed to successfully cover the parameter 95% of the time (i.e. for 95% of the samples).

We call 95% the “confidence level” for the parameter. Other confidence levels, anything between 0% and 100%, are possible.

As the confidence level increases, what happens to the width of the confidence interval? The width of the confidence interval increases.

As a follow up to the last question, will you be more confident that the population mean lies in a bigger interval, or less confident. You will be more confident that the population mean lies in a bigger interval.

As the sample size increases, what happens to the width of the confidence interval? The confidence level width increases as sample size increases.

In other words, will you be able to localize the population mean better (in a smaller interval) with a larger sample size? Yes.

If the variablility in the population increases, what happens to the width of the confidence interval? The width of the confidence interval increases as variability in the population increases.

In other words, will you be able to localize the population mean better (in a smaller interval) with more variability in the population? No, it will be more difficult to localize population mean with more variability in the population.

> Drawing Confidence Intervals Assuming You Know Shape of Sampling Distribution
According to the Central Limit Theorem, the sampling distribution for the sample mean has a Normal (bell shaped) distribution. Using this approximation, and the **68-95-99.7 Rule** to assign a margin of error (half the width of the confidence interval, centered on sample mean) to be 2 times the standard error (a statistic that estimates the standard deviation of the sampling distribution). We did this in class the Friday before Thanksgiving.



We are 95% confident that the true average size of houses in Ames lies between the values 8390.28 and 11747.99.

For the confidence interval to be valid, the sample mean must be normally distributed and have standard error s/√n. What conditions must be met for this to be true?
For this to be true, sampled observations need to be independent. Independence is more likely if random samplng is used and, if sampling without replacement, the sample size should be less than 10% of the population. The popluation distribution should either be normal or n>30 and the population distribution is not extremely skewed.

Exercise 4:
What does 95% confidence mean?
This refers to the long term success rate of this method, so it means that 95% of the confidence intervals produced will successfully capture the population parameter of interest, in this case, the mean Lot Area of homes in Ames.

## Andy


We can't access the population so we take samples
There will be variation across samples
There will be sampling errors
We go crazy for sampling and we takes lots of sampling and we takes the means for each samples and plot the distribution of the means
the particular sample we have may not have have the population values
but the sampling distribution will give us the population value
the sampling deviation will give us that
the sampling deviation should be narrows and the standard deviation of the sampling distribution is the standard error

An interval such as that across a large number of samples we contains the population values
How wide should the interval be to contains the population value a lot of times
we take a sample and decide to use it

1.96*SE

The estimate and its interval may or may not contain the true population value
across a lot of sample if were to set the limits around the estimate around 1.96*SE
we are going to hit the population value 95% of SAMPLES

Each bar is a sample that

Intervals that contains the true population value of the paramter in 95% ifsamples

NO - It's an interval i'm 95% confident that the population estimate falls within the interval 
it's an interval where there is a 95% probability that contains the population value!
Hyper no! it's either 1 or 0 but you don't know which
They do not reflect confidence in the value of the population parameter


Assuming that this sample is one of the 95% that yields a confidence interval containing the true value of the parameter 

For every standard deviation change of the paramter we have an increase of the effect


```{r}
# broom::tidy(model)
# # modelbased::estimate_means(lm,fixed=var_name)
# 
# car::Anova(model, type=3)
# 
# ggplot2::autoplot(model,which=c(1,2,3,4), colour="#5c97bf", alpha = 0.5, size = 1) + theme_minimal()
# 
# robust::lmRob()
# 
# parameters::model_parameters(model, robust=TRUE, vcov.type="HC4")
```



In statistics, a sampling distribution or finite-sample distribution is the probability distribution of a given random-sample-based statistic
Wikipedia

# Definition


# Example
