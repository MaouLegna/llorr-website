---
title: "EXPANDING THE LOR-META-INDEX - Bo3 DATA"
description: |
  Adding a Ban Index to the LMI by using data from Bo3 Matches and showcasing some of the complexity of costructing a Composite Indicator
base_url: https://www.llorr-stats.com
preview:
author:
  - name: Valentino (Legna) Vazzoler
date: 09-12-2021
output:
 distill::distill_article:
    toc: true
    toc_float: true    
    toc_depth: 3
    self_contained: false
citation: false
draft: TRUE
twitter:
  site: "@Maou_Legna"
  creator: "@Maou_Legna"
params:
  # prev:  "2021-07-07 21:00:00" #UTC tz / 'previous' week start
  start: "2021-07-14 21:00:00" #UTC tz / 'current' week start
  end:   "2021-08-25 21:00:00" #UTC tz / 'current' week end
  skip:  1850000  # Patch 2.11 - after removing a few games  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  comment = NA,
  R.options = list(width = 140,
                   digits.secs=6),
  dev.args = list(bg = 'transparent'), # make graphics with transparent background
  fig.align = 'center',
  fig.width=9,
  fig.height=6,
  engine.path = list(
    python = 'C:/anaconda/'   # -> use_python("C:/anaconda/")
  ),
  #'distill options
  layout="l-body-outset",
  preview=FALSE
)

#' R Option
source(file.path("C:","LlorR","scripts","lor_main.R" ))

# require(Hmisc)    # provides knitrSet and other functions
xaringanExtra::use_panelset()
#' Python
# py_run_string("print('Hello World')")
# lor_deckcodes <- import("lor_deckcodes")
# py_module_available("lor_deckcodes")
```

```{r twitter-meta, echo = FALSE}
# library(metathis)
metathis::meta() |>
  metathis::meta_description(
    "Adding a Ban Index to the LMI by using data from Bo3 Matches and showcasing some of the complexity of costructing a Composite Indicator"
  ) |> 
  metathis::meta_viewport() |> 
  metathis::meta_social(
    title = "EXPANDING THE LOR-META-INDEX - Bo3 DATA",
    url = "https://www.llorr-stats.com",
    image = "images/LMIv2",
    image_alt = "LMIv2",
    og_type = "website",
    og_author = "Legna",
    twitter_card_type = "summary",
    twitter_creator = "@Maou_Legna"
  )
```

```{r panelset-style}
xaringanExtra::style_panelset_tabs(font_family = "Roboto",
                                   active_foreground = "white",
                                   hover_foreground = "black",
                                   hover_border_color = "black",
                                   active_background = "#007fff"
                                   )
```

# Introduction

# Data

```{r raw-data}
#' load gameDT
#'############
file.DT <- file.path("C:","LlorR","data","raw","LoR_MatchDT.csv")
header        <- fread(file.DT, header = FALSE, na.strings = c("",NA), nrows = 1, stringsAsFactors = FALSE)
LoR.Match.RMD <- fread(file.DT, header = FALSE, na.strings = c("",NA), skip = params$skip ) # ~2.11/2.12
colnames(LoR.Match.RMD) <- unlist(header,use.names = F)

#' load Account
#'#############
file.Account <- file.path("C:","LlorR","data","raw","LoR_ACCOUNT.csv")
LoR.Account.RMD <- fread(file.Account, header=T, na.strings = c("",NA), encoding = 'UTF-8') %>%
  mutate( RiotID = paste(gameName,tagLine),refID = puuid_4 ) %>%
  pivot_longer(
  cols = c("puuid","puuid_1","puuid_2","puuid_3","puuid_4"),
  names_to = "origin",
  values_to = "puuid"
)

#' load DeckDT
#'############
LoR.Deck        <- fread(file.path("C:","LlorR","data","raw","LoR_DECK.csv"),na.strings = c("",NA))
```

```{r prepare-data}
LoR.Melt.Matches.RMD <- LoR.Match.RMD %>%
  #' Base filters
  ###############
  filter( game_mode == 'SeasonalTournamentLobby' ) |>
  filter( game_start_time_utc < as.POSIXct("2021-08-17 21:00:00", tz = "UTC") ) |>
  #' 'process' data
  #################
  left_join(.,LoR.Deck[,.(deck_code,archetype)] %>% setnames(old = "archetype", new = "player_1")   ,by=c("deck_code_1"="deck_code")) %>%
  left_join(.,LoR.Deck[,.(deck_code,archetype)] %>% setnames(old = "archetype", new = "opponent_1") ,by=c("deck_code_2"="deck_code")) %>%
  mutate( player_2 = opponent_1, opponent_2 = player_1, oppoppuid_1 = puuid_2, oppoppuid_2 = puuid_1 ) %>%
  select( match_key,server,game_start_time_utc,game_version,total_turn_count,
          ends_with("_1"),ends_with("_2"),-ends_with("_3"),-ends_with("_4"),-contains("deck_id"),-contains("participants") ) %>%
  #' melt data
  ############
  melt(id.vars=c("match_key","server","game_start_time_utc","game_version","total_turn_count"), measure.vars=patterns(
    str_sub(
      names(select(.,ends_with("_1")))
      ,end = -3)
  ),
  value.name = str_sub(
    names(select(.,ends_with("_1")))
    ,end = -3)
  ) %>%
  #' finish 'process' data
  ########################
  left_join(. , LoR.Account.RMD[,c("puuid","RiotID","refID")] %>% setnames(old = "RiotID", new = "userID")     ,by=c("puuid"="puuid")) %>%
  left_join(. , LoR.Account.RMD[,c("puuid","RiotID")] %>% setnames(old = "RiotID", new = "opponentID") ,by=c("oppoppuid"="puuid")) %>%
  left_join(.,LoR.Deck %>% select(!archetype),by=c("deck_code","factions")) %>%
  #' nChamp
  #########
  rowwise() %>%
  mutate(champions = extract_champions(c_across(contains("Champion")) ) ) %>%
  ungroup() %>%
  mutate( nChamp = str_count(champions,pattern = "/")+1) %>%
  mutate( nChamp = replace(nChamp, str_detect(player,"Championless"),0) ) %>%
  select(-ends_with("puuid"),-refID)
```

When I wrote the basic theory about the index I mentioned how it's a concept that can be expanded whenever I can find more (appropriate) variable to add. At the previous Seasonal I already had an idea but had no time to apply it. In this case I added the information regarding the ban rate of a deck.

Short explanation: Since now we have 3 variables there two options to consider, either they are used independently as before, or a new step is added a mid-tier aggregation. Since ban rate are always associated with pick rates (p&b) I dediced to create a "p&b dimension" that is composed by the play rate and ban rate. I applied the quantile normalization to use the same scale and the play rate, but there was an option to leave the value raw, the important part is probably leave decks with 0% ban rate to remain 0 and this happens with most transformations. the play rate and ban rate are aggregated with a weighed mean (but in this case with equals weights) the resulting p&b-dimension-index is normalized and then finally aggregated to create the LMI. This is just a quick application of the theory but a more rigorous approach will require testing all the steps with the new framework