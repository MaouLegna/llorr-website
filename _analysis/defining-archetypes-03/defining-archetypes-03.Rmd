---
params:
  ind: "03"
  title: "Defining Archetypes #3: "
  description: ""
title: | 
  `r params$title`
description: |
  `r params$description`
# preview: 
base_url: https://www.llorr-stats.com
author:
  - name: Valentino (Legna) Vazzoler
date: 11-11-2021
output:
 distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    self_contained: false
citation: false
slug: legna2021archetype03
bibliography: references.bib
draft: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  comment = NA,
  R.options = list(width = 140,
                   digits.secs=6),
  dev.args = list(bg = 'transparent'), # make graphics with transparent background
  fig.align = 'center',
  fig.width=12,
  fig.height=8,
  engine.path = list(
    python = 'C:/anaconda/'   # -> use_python("C:/anaconda/")
  ),
  #'distill options
  layout="l-body-outset",
  preview=FALSE
)

#' R Option
options(scipen = 999)
source(file.path("C:","LlorR","scripts","lor_main.R" ))
xaringanExtra::use_panelset()

pacman::p_load(apcluster,dbscan,fpc,factoextra)
```

```{r panelset-style}
xaringanExtra::style_panelset_tabs(
  font_family = "Helvetica",
  active_foreground = "white",
  hover_foreground = "black",
  hover_border_color = "black",
  active_background = "#007fff"
  )
```

# Introduction

In the [previous article/analysis](https://llorr-stats.netlify.app/analysis/defining-archetypes-02/) on defining archetypes we introduced the basic theory of Cluster Analysis (CA) and applied to a simple toy-example of Legends of Runeterra (LoR) decks.

Along side the general theory we introduced and also applied a few commonly used algorithms and some of the "newer/trending" ones like Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Affinity Propagation Clustering (APcluster).

The example was tailored to give a general idea about the methods, some of their strong point and also weaknesses.

As the previous analysis was mostly based around the mathematical properties 

Here, we want to continue to use the Cluster Analysis but this times applied to a set of data on the magnitude equal or at least similar to a real 

```{r}

```


Decklist from "Last Season Master" games in patch 2.18 ~90k decks

Decklist from "Master" games in patch 2.18 ~10k decks

---

Distance Matrix and so, all algorithm derived by them have a quadratic growth ($o^2$) so scalability is a problem.

This makes the choice and/or application of certain method/algorithms/ecc not feasable at high dimension.

BUT if the "whole" problem related to the distance matrix is too big an approach comes to help: to "Divide et Impera" the problem

We are going to refer to the similarity matrix instead of the normalized distance matrix.

First of all, we knows that the similarity matrix has a structure so that it is defined $0_{n \times n}$ null-matrix for most of sub-matrix defined in it.

To be more precise, everywhere all regions from both deck are different the similarity between these deck is 0

There are sadly exception to this property: when we deal with dual region cards we can have non overlapping "factions" but still common cards

> Example: a BandleCity/Noxus (BC/NX) deck and a Demacia/Ionia (DE/IO) deck both sharing "Poppy" as a card

> BandleCity Ruined more than the Ruination

For now everything we will do will ignore this factor. While we can take into account the second-region of a card and simply expand the cards pool with them there other factor that would increase the complexity of the problem so that it's left for future works.

## The Shuriman Desert is Sparse

Let's assume we don't have the problem of the DualRegion cards, what do we know about the structure of the similarity matrix ?

We know that there are 55 unique combination of region

When comparing two decks we so have 55^2 possible sub-matrix of confrontation between combination of regions. Of course we as the Matrix is symmetrical it's reduced to just 1540 cases.

But even among those 1540, the cases different from zero are not that many.

As we mentioned only cases with deck that share at least a common region can be different from zero.

This makes it so the number of sub-matrix to consider follows the following formula:

$\sum_i^n((i-1)^2+\frac{i(i+1)}{2})$

```{r}
#' region to find the percentage all cases of "interceptions" between elements like factions. For example BC/NX does correlate with all BC and all NX cases
regionComboInterception <- function(n) {
  # n = 10
  dim <- n*(n+1)/2
  total = 0
  for ( i in 1:n ) {
    p1 <- i*(i+1)/2
    p2 <- (i-1)^2
    total <- total + p1 + p2
  }
  total/(dim*(dim+1)/2)
}
  
tibble::tibble( region = 1:10,
        coverage = map_dbl(1:10, ~regionComboInterception(.x)) ) |>
  gt::gt() |>
  fmt_percent(
    columns = coverage,
    decimals = 2
  ) |>
  tab_header(
    title = "Sparsity of Similarity Matrix",
    subtitle = md("Percent of sub-matrix that share a common region <br> by number of existing regions.")
  ) |>
  gtExtras::gt_theme_538()
```

From **Table1 (add ref) **  we can see that in the current setting with n=10 existing regions of the 1540 cases only the 32% actually meaningful.

But this is not over as only a small subset of this 32% is actually relevant. 

What follows is a simplification which works for most cases.

When we compare decks with a common shared region not all comparison are meaningful.

If decks with only one shared regions have to be similar either the key cards are unique enough to identify the decks and so the regions are not important, or the shared region presence must be overwhelming compared to the second one. If it wasn't by definition of the similarity we used up until know (a measure defined by number of copies of a card in a deck) than the similarity will be small giving indication of different archetypes/clusters.

In other words the decks that matters are bridge among the regions with a main region that mostly identify the deck.

As easy example is the Mistwraith decks that we also used in the previous article.

Normally Mistwraith decks are made mostly of ShadowIsles cards while the remaining cards are often from a region of choice that synergies with the rest of the deck but are not essential / key-cards. This cards act are the bridge between regions.

Is the deck using as the only not-SI cards 3 copies of Pale Cascade? Then it's a SI/MT deck

Is the deck using as the only not-SI cards any copies of Raz Bloodmane? Then it's a SI/SH deck and SI/MT and SI/SH are connected

Is the deck using as the only not-SI cards 3 copies of Iterative Improvement? Then it's a SI/PZ deck and we connected SH,MT and PZ by SI.

And so on

Of course as mentioned this is more an approximation as one could that a Mistwraith deck with just 20 SI cards and a lot of duplication cards can be defined as Mistwratith decks but here we assume that that by itself is an over-simplification and it's more likely to be defined as a sub-archetype of Mistwraith Allegiance that may have sense to the connected/related the 20-SI cards Mistwraith deck would most likely while having a similar goal and strategy would have a play-pattern that differs enough from the Mistwraith Allegiance so that in this initial clustering it is more correct to separate them.

In a second step, when trying to find more generalized archetypes (be it something like aggro/control/initiative/resource) then there is reason to try aggregated these different "aggregated version" of Mistwraith decks but as of now, with 

---

We so choose to propose to set a rule so that only these bridge decks are clustered. This open for a consequential step, as we restricted the between regions cases to decks with an overwhelming presence of a region to the other they can be all aggregated into the ~Mono region

What benchmark and rules should we use ? This is tricky but the idea was of using either an hard defined benchmark and to support the presence of Allegiance

```{r region-freq-dist}

```


An idea was to use the inclusion of Allegiance cards as their effect is not a gamble only in deck that either can heavily control their draw or are made mostly of a single region. As LoR offer some card draw control options they are far from common so usually use of Allegiance cards do predict the use of an ~Mono deck.

Sadly this is true, but not entirely. Not only these cards have being played in decks where their activation is very risky but there are even cases there more the Allegiance card for both region has being played in the same deck.

```{r allegiance-mess}

```

There is also an additional potential failing point of this strategy: the "Theseus's Archetype".

This is related to the problem with Mistwraith deck mentioned before. We said that there can be a ~Mono SI version and others SI/XX when the second region has way too many cards to assume it's still the same deck.

Overall this problem is being left for another moment to refine the result of a cluster analysis but conceptually we believe there is merit both in saying there can be more version of the same base-archetype and then we can work on an aggregated one

```{r create-example}
# load DeckDT
#'###########
# LoR.Deck.RMD        <- fread(file.path("C:","LlorR","data","raw","LoR_DECK.csv"),na.strings = c("",NA))

# data.table::fwrite(example_archetye_03,"C:/Users/Valentino Vazzoler/Documents/R/llorr-website/data/example_archetye_03.csv")
example_archetye_03 <- data.table::fread("C:/Users/Valentino Vazzoler/Documents/R/llorr-website/data/example_archetye_03.csv",na.strings = c("",NA))
# data.table::fwrite(LoR.Deck.RMD[deck_code %in% example_archetye_03$deck_code,],"C:/Users/Valentino Vazzoler/Documents/R/llorr-website/data/example_archetye_03_old.csv")

# set.seed(123)
# Archetype3 <- LoR.Deck.RMD |>
#   group_by(factions) |>
#   slice_sample( n = 300 )
# fwrite(Archetype3,"./data/example_archetye_03.csv")

# set.seed(123)
# Archetype3.20 <- Archetype3 |>
#   group_by(factions) |>
#   slice_sample( n = 20 )
# cos.dsim.arch3.20  <- cos.dsimMatrix(Archetype3.20$deck_code)
# fwrite(Archetype3.20, "./data/example_archetye_03_20.csv")
# fwrite(as.matrix(cos.dsim.arch3.20),"./data/example_cosDist_03_20.csv")
# 
# set.seed(123)
# Archetype3.100 <- Archetype3 |>
#   group_by(factions) |>
#   slice_sample( n = 100 )
# cos.dsim.arch3.100 <- cos.dsimMatrix(Archetype3.100$deck_code)
# fwrite(Archetype3.100,"./data/example_archetye_03_100.csv")
# fwrite(as.matrix(cos.dsim.arch3.100),"./data/example_cosDist_03_100.csv")
```




```{r}
alleDeck <- example_archetye_03 |>
  select(deck_code,allegiance,factions,cards.region.freq) |>
  # separate_rows(factions) |>
  separate_rows(factions,cards.region.freq) |>
  mutate(cards.region.freq = as.numeric(cards.region.freq) ) |>
  filter(cards.region.freq >=  33 | !is.na(allegiance) ) |>
  group_by(deck_code) |>
  slice_max(cards.region.freq) |>
  ungroup() |>
  as.data.table()




```


```{r raw-data}
# Archetype3 <- fread("./data/example_archetye_03.csv")
# Archetype3.20  <- fread("./data/example_archetye_03_20.csv")
# Archetype3.100 <- fread("./data/example_archetye_03_100.csv")
# fwrite(example_archetye_03[deck_code %in% Archetype3.20$deck_code],"./data/example_archetye_03_20.csv")
# fwrite(example_archetye_03[deck_code %in% Archetype3.100$deck_code],"./data/example_archetye_03_100.csv")

cos.dsim.arch3.20 <- fread("./data/example_cosDist_03_20.csv",header=T) |>
  as.matrix() |> as.dist()

# cos.dsim.arch3.100 <- fread("./data/example_cosDist_03_100.csv",header=T) |>
#   as.matrix() |> as.dist()
```

Trivia: the dimension of the distance matrix when I used 20 example for possible faction combination so a 1100x1100[^1] matrix is

[^1]: 20*55=1100

```{r}
object.size(cos.dsim.arch3.20)
```

While the size for a case with 100 decks, a 5500x5500 decks is:

```{r}
object.size(cos.dsim.arch3.100)
```

This doesn't seems too bad, but there are factors to consider:
- The increase is size scale badly with the increase in rows/columns. 5500 are hardly a lot, a patch can easily have ~20k different deck-list played.
- The computation fatigue scales even worse -> explain prodotto matriciale

To this we have to add 

The first thing to do in any cluster analysis that we actually forgot to even do the most basic step and it is to display the distance matrix

```{r fig.width=12, fig.height=8}
# library("factoextra")
factoextra::fviz_dist(cos.dsim.arch3.20,show_labels = F,
                      gradient = list(low = "yellow", high = "firebrick3")) +
  theme(legend.position = "none")
```

```{r fig.width=12, fig.height=8}
lattice::levelplot(as.matrix(cos.dsim.arch3.20), main="1100 X 1100 Heatmap", xlab="", ylab="", col.regions=colorRampPalette(c("yellow","firebrick3"), space = "rgb")(10), cuts=9, at=seq(0,1,0.1), scales=list(x=list(at=NULL),y=list(at=NULL)))
```

```{r fig.width=12, fig.height=8}
lattice::levelplot(as.matrix(cos.dsim.arch3.100), main="5500 X 5500 Heatmap", xlab="", ylab="", col.regions=colorRampPalette(c("yellow","firebrick3"), space = "rgb")(10), cuts=9, at=seq(0,1,0.1), scales=list(x=list(at=NULL),y=list(at=NULL)))
```

```{r fig.width=12, fig.height=8}
heatmap3::heatmap3(as.matrix(cos.dsim.arch3.20),useRaster=T,Rowv=NA,Colv=NA, col = colorRampPalette(c("yellow","firebrick3"))(1024))
                   # legendfun=function() NA )
```

```{r fig.width=12, fig.height=8}
heatmap3::heatmap3(as.matrix(cos.dsim.arch3.100),useRaster=TRUE,Rowv=NA,Colv=NA, col=colorRampPalette(c("yellow","firebrick3"))(1024))
```

# Divide and Conquer the archetypes

```{r}
example_archetye_03 |>
  group_by(factions) |>
  summarise(n = n())
```


## Heatmap3 code example

```{r fig.width=12, fig.height=8}
nrowcol <- 1000
dat <- matrix(ifelse(runif(nrowcol*nrowcol) > 0.5, 1, 0), nrow=nrowcol)

heatmap3::heatmap3(dat,useRaster=TRUE,Rowv=NA,Colv=NA)
heatmap3::heatmap3(matrix(rnorm(10),ncol=2),legendfun=function() plot(0,0,bty="n",xaxt="n",yaxt="n",type="n"))
```

## Lattice code example

```{r fig.width=12, fig.height=8}
# install.packages("lattice")
library(lattice)

#Build the data
nrowcol <- 1000
dat <- matrix(ifelse(runif(nrowcol*nrowcol) > 0.5, 1, 0), nrow=nrowcol)

#Build the palette and plot it

x <- seq(pi/4, 5 * pi, length.out = 100)
y <- seq(pi/4, 5 * pi, length.out = 100)
r <- as.vector(sqrt(outer(x^2, y^2, "+")))
grid <- expand.grid(x=x, y=y)
grid$z <- cos(r^2) * exp(-r/(pi^3))
levelplot(z ~ x * y, grid, cuts = 50, scales=list(log="e"), xlab="",
          ylab="", main="Weird Function", sub="with log scales",
          colorkey = FALSE, region = TRUE)

levelplot(z ~ x * y, grid, cuts = 50, scales=list(x=list(at=NULL),y=list(at=NULL)), xlab="",
          ylab="", main="Weird Function", sub="with log scales",
          colorkey = FALSE, region = TRUE)


## triangular end-points in color key, with a title
levelplot(z ~ x * y, grid, col.regions = topo.colors(10),
          at = c(-Inf, seq(-0.8, 0.8, by = 0.2), Inf))
```

```{r fig.width=12, fig.height=8}
SI <- cos.dsimMatrix(alleDeck[factions == "SI",deck_code])

dend.SI <- hclust(SI,method = "average")

set.seed(123)
ap.SI <- apcluster(linKernel(SI,normalize = T),details = T)

apcluster::heatmap(
  ap.SI,linKernel(SI,normalize = T),
  # Rowv=NA, Colv=NA,
  # cexRow= 0.75, cexCol = 0.75,
  cexRow= 0, cexCol = 0,
  # sideColors=c("darkgreen", "yellowgreen"),
  # col=terrain.colors(12),
  legend = "col"
  )

factoextra::fviz_dend(dend.SI)

table(archetype.v2,
      ap.res@idx)

table(example_archetye_03[deck_code %in% alleDeck[factions == "SI",deck_code], archetype],ap.SI@idx)
```

```{r}
NXPZ <- cos.dsimMatrix(example_archetye_03[factions == "NX,PZ",deck_code])

example_archetye_03[factions == "NX,PZ",tabyl(archetype)]

dend.NXPZ <- hclust(NXPZ,method = "average")

factoextra::fviz_dend(dend.NXPZ)

set.seed(123)
ap.NXPZ <- apcluster(linKernel(NXPZ,normalize = T),details = T, q= 0)

apcluster::heatmap(
  ap.NXPZ,linKernel(NXPZ,normalize = T),
  # Rowv=NA, Colv=NA,
  # cexRow= 0.75, cexCol = 0.75,
  cexRow= 0, cexCol = 0,
  # sideColors=c("darkgreen", "yellowgreen"),
  # col=terrain.colors(12),
  legend = "col"
  )

print( table(example_archetye_03[deck_code %in% example_archetye_03[factions == "NX,PZ",deck_code], archetype],ap.NXPZ@idx), zero.print = ".")


getOption("max.print")

options(max.print=2000)

173
280
293

example_archetye_03[factions == "NX,PZ",deck_code][which(ap.NXPZ@idx==173)]
example_archetye_03[factions == "NX,PZ",deck_code][which(ap.NXPZ@idx==280)]
example_archetye_03[factions == "NX,PZ",deck_code][which(ap.NXPZ@idx==293)]
```

