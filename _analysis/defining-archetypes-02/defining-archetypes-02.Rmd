---
params:
  ind: "02"
  patch: "Patch 2.17 - Week 1"
  title: "Defining Archetypes #2: xxx xxx xxx"
  description: "xxx xxx xxx xxx"
  cardlurl: "https://dd.b.pvp.net/latest/set5/en_us/img/cards/05BC116.png"
  # prev:  "2021-09-29 21:00:00" #UTC tz / 'current' previous week start
  start: "2021-09-01 21:00:00" #UTC tz / 'current' week start
  end:   "2021-09-15 21:00:00" #UTC tz / 'current' week end
  skip:  2800000  # ~ Patch 2.16

title: | 
  `r params$title`
description: |
  `r params$patch` - `r params$description`
base_url: https://www.llorr-stats.com
preview: |
  `r params$cardlurl`
author:
  - name: Valentino (Legna) Vazzoler
date: 10-06-2021
output:
 distill::distill_article:
    toc: true
    toc_float: true
    toc_depth: 3
    self_contained: false
citation: false
bibliography: biblio.yaml
draft: TRUE

references:
- type: article-journal
  id: WatsonCrick1953
  author:
  - family: Watson
    given: J. D.
  - family: Crick
    given: F. H. C.
  issued:
    date-parts:
    - - 1953
      - 4
      - 25
  title: 'Molecular structure of nucleic acids: a structure for
    deoxyribose nucleic acid'
  title-short: Molecular structure of nucleic acids
  container-title: Nature
  volume: 171
  issue: 4356
  page: 737-738
  DOI: 10.1038/171737a0
  URL: https://www.nature.com/articles/171737a0
  language: en-GB
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  eval = TRUE,
  warning = FALSE,
  error = FALSE,
  message = FALSE,
  comment = NA,
  R.options = list(width = 140,
                   digits.secs=6),
  dev.args = list(bg = 'transparent'), # make graphics with transparent background
  fig.align = 'center',
  fig.width=12,
  fig.height=8,
  engine.path = list(
    python = 'C:/anaconda/'   # -> use_python("C:/anaconda/")
  ),
  #'distill options
  layout="l-body-outset",
  preview=FALSE
)

#' R Option
options(scipen = 999)
source(file.path("C:","LlorR","scripts","lor_main.R" ))
xaringanExtra::use_panelset()
```

```{r panelset-style}
xaringanExtra::style_panelset_tabs(
  font_family = "Helvetica",
  active_foreground = "white",
  hover_foreground = "black",
  hover_border_color = "black",
  active_background = "#007fff"
  )
```

```{r functions}
#' extract the top n most played list for 'archetypes provided'
top_n_codes <- \(DT = LoR.Melt.Matches.RMD,archetypes,n,dopull=T) DT |>
  dplyr::filter(archetype%in%{{archetypes}}) |>
  dplyr::group_by(archetype) |>
  dplyr::count(deck_code) |>
  dplyr::slice_max(deck_code,n=n,with_ties=F) |>
  ungroup()|>{\(x) if( dopull==T ) dplyr::pull(x,deck_code) else x}()


#' distance Matrix given deck_codes
dsimMatrix <- function( codes ) {
  deck.matrix <- LoR.Card$cardCode |> purrr::map_dfc(setNames, object = list(numeric()))
  for (i in 1:length(codes)) {
    if (i%%100==0) glue::glue("Fill parse matrix #{i} - {Sys.time()}") |> message()
    decklist <- codes[i] |> lordecks::get_decklist_from_code()
    deck.matrix[NROW(deck.matrix)+1, decklist$cardcode] <- as.list(decklist$count)
  }
  deck.matrix |> mutate( across(everything(), ~replace_na(.x, 0)) ) 
}

#' distance Matrix given deck_codes
cos.dsimMatrix <- function( codes ) {
  deck.matrix <- LoR.Card$cardCode |> purrr::map_dfc(setNames, object = list(numeric()))
  for (i in 1:length(codes)) {
    if (i%%500==0) glue::glue("Fill parse matrix #{i} - {Sys.time()}") |> message()
    decklist <- codes[i] |> lordecks::get_decklist_from_code()
    deck.matrix[NROW(deck.matrix)+1, decklist$cardcode] <- as.list(decklist$count)
  }
  deck.matrix <- deck.matrix |> mutate( across(everything(), ~replace_na(.x, 0)) ) 
  eisen_cos.sim(deck.matrix)
}
```


```{r raw-data-all}
# skip.dt <-fread(file.path("C:","LlorR","data","raw","skip_row.csv")  )
# skip.dt

#' load gameDT
#'############
# file.DT <- file.path("C:","LlorR","data","raw","LoR_MatchDT.csv")
# header        <- fread(file.DT, header = FALSE, na.strings = c("",NA), nrows = 1, stringsAsFactors = FALSE)
# LoR.Match.RMD <- fread(file.DT, header = FALSE, na.strings = c("",NA), skip = params$skip )
# colnames(LoR.Match.RMD) <- unlist(header,use.names = F)
# 
# #' load Account
# #'#############
# LoR.Account.RMD <- fread(file.path("C:","LlorR","data","raw","LoR_ACCOUNT.csv"),
#                          header=T, na.strings = c("",NA), encoding = 'UTF-8') |>
#   mutate( RiotID = sprintf("%s#%s",gameName,tagLine) )
# 
# #' load DeckDT
# #'############
LoR.Deck.RMD        <- fread(file.path("C:","LlorR","data","raw","LoR_DECK.csv"),na.strings = c("",NA))[ !is.na(archetype_pretty), archetype:=archetype_pretty ]
 
# #' patch 2.14 to 2.15
# #'###################
# patch214215code <- LoR.Match.RMD |>
#   filter( game_type=="Ranked" ) |>
#   filter( game_start_time_utc >= as.POSIXct(params$start, tz = "UTC") & game_start_time_utc < as.POSIXct(params$end, tz = "UTC") ) |>
#   select( -ends_with("_3"),-ends_with("_4")  ) |>
#   select( starts_with("deck_code") ) |>
#   pivot_longer(cols = c(ends_with("_1"),ends_with("_2")),
#                names_to = c(".value"),
#                names_pattern = "(.*)_[0-9]"
#                ) |>
#   left_join(LoR.Deck.RMD[,.(deck_code,archetype)],  by=c("deck_code") )

# NROW(patch214215code) # 155214
# patch214215code |> fwrite(file.path("C:","LlorR","data","clean","deckcode_patch214215.csv")  )

# length(unique(patch214215code$deck_code)) # 17772
# NROW(DSim_patch214215) # 17772

#' load parse Matrix
#'##################
# DSim_patch214215 <- fread(file.path("C:","LlorR","data","clean","DSimMatrix_0214to0215.csv"))
# cos.DSim_patch214215 <- fread(file.path("C:","LlorR","data","clean","cos.DSimMatrix_0215to0216.csv"), header=T) |> as.matrix()
# fwrite(DSim_patch215216,file.path("C:","LlorR","data","clean","DSimMatrix_0215to0216.csv"))

# cos.DSim_patch214215[1:10,1:10]
# DSim_patch214215[1:10] |> eisen_cos.sim()

#' Archetype-Fix
#'##############
source(file.path("C:","LlorR","scripts","functions","lor_archetype_rmd.R"))
```
```{r}
# how I selecter the decks, it is reproducible as more decks will be inserted in the DB

set.seed(123)
Rep1 <- LoR.Deck.RMD |>
  filter( archetype == "Ashe/LeBlanc" & is.na(archetype_pretty) ) |>
  slice_sample(n = 75) |>
  pull(deck_code)

set.seed(123)
Rep2 <- LoR.Deck.RMD |>
  filter( archetype_pretty == "Marauder" ) |>
  slice_sample(n = 25) |>
  pull(deck_code)

set.seed(123)
AI <- LoR.Deck.RMD |>
  filter( archetype == "Azir/Irelia", ) |>
  slice_sample(n = 100) |>
  pull(deck_code)

set.seed(123)
Dragon1 <- LoR.Deck.RMD |>
  filter( archetype == "Aurelion Sol/Jarvan IV/Shyvana" ) |>
  slice_sample(n = 30) |>
  pull(deck_code)

set.seed(123)
Dragon2 <- LoR.Deck.RMD |>
  filter( archetype == "Aurelion Sol/Shyvana" ) |>
  slice_sample(n = 70) |>
  pull(deck_code)

set.seed(123)
Sion1 <- LoR.Deck.RMD |>
  filter( archetype == "Draven/Sion (NX/PZ)" & is.na(archetype_pretty) ) |>
  slice_sample(n = 80) |>
  pull(deck_code)

set.seed(123)
Sion2 <- LoR.Deck.RMD |>
  filter( archetype_pretty == "RubinBait - Draven/Sion", ) |>
  slice_sample(n = 20) |>
  pull(deck_code)

set.seed(123)
Mist1 <- LoR.Deck.RMD |>
  filter( archetype_pretty == "Mistwraith Allegiance" & str_detect(factions,"Targon") ) |>
  slice_sample(n = 50) |>
  pull(deck_code)

set.seed(123)
Mist2 <- LoR.Deck.RMD |>
  filter( archetype_pretty == "Mistwraith Allegiance" & str_detect(factions,"Piltover") ) |>
  slice_sample(n = 50) |>
  pull(deck_code)

#' Archetype names fix
######################
LoR.Deck.RMD[ !is.na(archetype_pretty), archetype:=archetype_pretty ]
```

```{r prepare-examples}
#' archetypes names
archetypes <- c( 
  "Ashe/LeBlanc",           # 75/25 noMarauder/Marauder
  "Azir/Irelia",            # 100
  "Dragons (DE/MT)",        # 30/70 J4/PureDrake "Aurelion Sol/Jarvan IV/Shyvana",  "Aurelion Sol/Shyvana",
  "Draven/Sion (NX/PZ)",    # 80/20 DravenSion/RubinBait
  "Mistwraith Allegiance"   # 50/50 Targon/Piltover
)

LoR.Archetype.Ex <- rbind(
  LoR.Deck.RMD[ deck_code %in% Rep1, ],
  LoR.Deck.RMD[ deck_code %in% Rep2, ],
  LoR.Deck.RMD[ deck_code %in% AI, ],
  LoR.Deck.RMD[ deck_code %in% Dragon1, ],
  LoR.Deck.RMD[ deck_code %in% Dragon2, ],
  LoR.Deck.RMD[ deck_code %in% Sion1, ],
  LoR.Deck.RMD[ deck_code %in% Sion2, ],
  LoR.Deck.RMD[ deck_code %in% Mist1, ],
  LoR.Deck.RMD[ deck_code %in% Mist2, ]
)
  


# LoR.Archetype.Exe[ !is.na(archetype_pretty), archetype:=archetype_pretty ]
# LoR.Archetype.Exe[ archetype == "RubinBait - Draven/Sion" , archetype:="Draven/Sion (NX/PZ)" ]
# LoR.Archetype.Exe[ archetype == "Marauder" , archetype:="Ashe/LeBlanc" ]

mini.ex <- c(Rep1[1:7], # Ashe/LB
             Rep2[1:3], # Marauder
             AI[1:10],  # AI
             Dragon1[1:3], # with J4
             Dragon2[1:7], # no J4
             Sion1[1:8],   # OG
             Sion2[1:2],   # fake-burn
             Mist1[1:5],   # MT
             Mist2[1:5])   # PnZ

LoR.Archetype.Mini <- LoR.Archetype.Ex |>
  filter(deck_code %in% mini.ex )

# fwrite(LoR.Archetype.Ex, "./data/example_archetye.csv")
# fwrite(LoR.Archetype.Mini, "./data/example_archetye_mini.csv")

# LoR.Archetype.Ex   <- fread("./data/example_archetye.csv")
# LoR.Archetype.Mini <- fread("./data/example_archetye_mini.csv")

# #' distance matrix
sparseMatrix.Ex   <- dsimMatrix(codes =  LoR.Archetype.Ex$deck_code )
sparseMatrix.mini <- dsimMatrix(codes =  LoR.Archetype.Mini$deck_code )

rownames.archetype <- lapply(archetypes, function(x) sprintf("%s.%s",x,c(1:10))) |> unlist()

sparseMatrix.mini <- as.data.frame(sparseMatrix.mini)
rownames(sparseMatrix.mini) <- rownames.archetype

DSim_ex   <- eisen_cos.sim(sparseMatrix.Ex)
DSim_mini <- eisen_cos.sim(sparseMatrix.mini)
```

```{r}
# DSim_patch215216 <- unique(patch215216code$deck_code) |> dsimMatrix()
# fwrite(DSim_patch215216,file.path("C:","LlorR","data","clean","DSimMatrix_0215to0216.csv"))

# DSim <- DSim_patch215216 |> eisen_cos.sim()

# fwrite(as.matrix(DSim),file.path("C:","LlorR","data","clean","cos.DSimMatrix_0215to0216.csv"))
```

# Introduction

Defining archetypes on Legends of Runeterra is both a complex and simple problem. It's simple if we consider that it's possible to define decks by the combination of champions and regions of choice but it's also complex by the fact that such definition is quite limited.

On our [previous article/analysis](https://llorr-stats.netlify.app/analysis/defining-archetypes-01/) we gave a possible method about how to compare archetypes and see if they can be considered from a shared common archetype or not. The proposed method makes use of inferential statistical analysis to reach a conclusion. Sadly, it's also a methodology that's more fitting a posterior analysis, when hypothetical archetypes are already defined, a tool more fitted to refine the results and not to define archetypes.

A more fitting methodology to find archetype is a form of exploratory data analysis (EDA) known as *Clustering Analysis* (CA). Its aim is to find subgroups (or clusters) in our data without relying on a *response variable*, also the reason why it's called *unsupervised learning*.

As useful as it is a CA suffer from a fundamental problem of not being able to check out the quality of the results. With a vast array of different algorithms and hyper-parameters this also means that finding the the "correct" way to use a CA to define archetypes (which was supposed to be the aim of this article) is not only impossible, it's also seeing the CA in the wrong way. Surely some choices are better than others but there is no perfect answer and to be fair, this was making us, was making me, procrastinating the writing of this article. The result, or maybe compromise was to reduce the scale on this article which will be small dive into the cluster analysis. While I want to provide some food for thought for others in the end the main recipient of the article is myself, to provide me a more solid foundation on the topic and how to approach it knowing the basic limitations of what I'm planning to use.

# Data

The example used in this article is made out of 50 decks. More details will be described 

* Five archetypes with Different regions & different play style
  1. Azir/Irelia
  2. Ashe/LeBlanc
  3. Dragons (DE/MT)
  4. Draven/Sion (NX/PZ)
  5. Mistwraith Alligiance
  
More details about how they were chosen will be written later as results are shown

# Clustering 

Clustering is a basic data mining task with a wide variety of applications. not surprisingly, there exist many clustering algorithms. However, clustering is an ill defined problem - given a data set, it is not clear what a "correct" clustering for that set is. Indeed, different algorithms may yield dramatically different outputs for the same input sets.
In spite of the wide use of clustering in many practical applications, currently, there exist no principled method to guide the selection of a clustering algorithm.
Currently, such decisions are often made in a very ad hoc, if not completely random, manner. Users are aware of the cost involved in employing different clustering algorithms, such as running times, memory requirement, and software.

Clustering is applied in a wide range of disciplines, from astronomy to zoology, yet its theoretical underpinnings are still poorly understood. Even the fairy basic problem of which algorithm to select for a given application (known as "the user dilemma") is left to ad hoc solutions, as theory is only starting to address fundamental differences between clustering methods.

Clustering refers to a very broad set of techniques for findings subgroups or *clusters*, in a data set. When we cluster the observations of a data set, we seek partition then into distinct groups so that the observations within each group are quite similar to each other, while observation in a different groups are quite different from each other. Of course, to make this concrete, we must define what it means for two or more observations to be *similar or different*

Since clustering is popular in many fields, there exist a great number of clustering methods 

## K-Mean

```{r}
km.out <- kmeans(sparseMatrix.mini, 3, nstart = 10)
km.out <- kmeans(sparseMatrix.mini, 5, nstart = 10)

k5 <- kmeans(sparseMatrix.mini, centers = 5, nstart = 25)

fviz_cluster(k5, data = sparseMatrix.mini)

df <- USArrests
df <- na.omit(df)

k2 <- kmeans(df, centers = 2, nstart = 25)
fviz_cluster(k2, data = df)

setDT(sparseMatrix.mini)

rownames(sparseMatrix.mini) <- LoR.Archetype.Mini$archetype



```


## Hierarchical Clustering

```{r Example1}
ex.hc.complete <- hclust(DSim_mini, method = "complete")
set.seed(123)
ex.hc.complete.n <- hclust(DSim_mini, method = "complete", members = sample(1:5000,NROW(DSim_mini) ))

ex.hc.single   <- hclust(DSim_mini, method = "single")

ex.hc.average  <- hclust(DSim_mini, method = "average")
set.seed(123)
ex.hc.average.n  <- hclust(DSim_mini, method = "average", members = sample(1:5000,NROW(DSim_mini)))

ex.hc.centroid <- hclust(DSim_mini, method = "centroid")
set.seed(123)
ex.hc.centroid.n <- hclust(DSim_mini, method = "centroid", members = sample(1:5000,NROW(DSim_mini)))

paste 

ex.hc.complete$labels <- LoR.Archetype.Mini$archetype
fviz_dend(ex.hc.complete, cex = 0.5 ) +
fviz_dend(ex.hc.complete.n, cex = 0.5 )

fviz_dend(ex.hc.average, cex = 0.5 ) +
fviz_dend(ex.hc.average.n, cex = 0.5 )

fviz_dend(ex.hc.centroid, cex = 0.5 ) +
fviz_dend(ex.hc.centroid.n, cex = 0.5 )
```

```{r}
# library("apcluster")
# s1 <- negDistMat(iris, r=2)
# 
# apres1a <- apcluster(negDistMat(DSim_mini,r=1))
# 
# table(apres1a@idx,LoR.Archetype.Mini$archetype)
# 
# apcluster::heatmap(apres1a,negDistMat(DSim_mini,r=1))
# 
# heatmap(apres1a,as.data.frame(DSim_mini))
# 
# apcluster::linSimMat
# 
# apcluster::corSimMat(DSim_mini,signed = F,r=1)
# linKernel(DSim_mini,normalize = T)
# 
# eisen_cos.sim(DSim_mini)
```




```{r}
# library(dbscan)
# 
# data(iris)
# iris <- as.matrix(iris[,1:4])
```

```{r}
# library(dplyr)
# library(tidyr)
# library(purrr)
# library(ggplot2)
# iris0 <- iris %>%  
#   group_by(Species) %>%  
#   nest() %>%  
#   mutate(
#     gg1 = purrr::map(data, ~ ggplot(., aes(Sepal.Length, Sepal.Width)) + geom_point()),
#     gg2 = purrr::map(data, ~ ggplot(., aes(Sepal.Length, Petal.Width)) + geom_point()),
#     gg3 = purrr::map(data, ~ ggplot(., aes(Sepal.Length, Petal.Length)) + geom_point()),
#     g = purrr::pmap(list(gg1, gg2, gg3), ~ gridExtra::grid.arrange(..1, ..2, ..3))
#   )
```


```{r}
# kNNdistplot(iris, k = 5)
# abline(h=.5, col = "red", lty=2)
# 
# res <- dbscan(iris, eps = .5, minPts = 5)
# res
# 
# pairs(iris, col = res$cluster + 1L)
# 
# hullplot(x = iris, cl = res) # grafico delle aree convesse

# if(!require(devtools)) install.packages("devtools")
# devtools::install_github("kassambara/factoextra")

# library(factoextra)
# data("multishapes")
# df <- multishapes[, 1:2]
# set.seed(123)
# km.res <- kmeans(df, 5, nstart = 25)
# fviz_cluster(km.res, df, frame = FALSE, geom = "point")

# install.packages("fpc")
# install.packages("dbscan")

# Load the data 
# Make sure that the package factoextra is installed
# data("multishapes", package = "factoextra")
# df <- multishapes[, 1:2]
# 
# library("fpc")
# # Compute DBSCAN using fpc package
# set.seed(123)
# db <- fpc::dbscan(df, eps = 0.15, MinPts = 5)
# # Plot DBSCAN results
# plot(db, df, main = "DBSCAN", frame = FALSE)
# 
# library("factoextra")
# fviz_cluster(db, df, stand = FALSE, frame = FALSE, geom = "point")

# Print DBSCAN
# print(db)

# Cluster membership. Noise/outlier observations are coded as 0
# A random subset is shown
# db$cluster[sample(1:1089, 50)]

# dbscan::kNNdistplot(df, k =  5)
# abline(h = 0.15, lty = 2)
```

```{r}
# #The iris dataset is used:
# 
# # Load the data
# data("iris")
# iris <- as.matrix(iris[, 1:4])
# #The optimal value of “eps” parameter can be determined as follow:
# 
# dbscan::kNNdistplot(iris, k =  4)
# abline(h = 0.4, lty = 2)
# # Compute DBSCAN using fpc::dbscan() and dbscan::dbscan(). Make sure that the 2 packages are installed:
# 
# set.seed(123)
# # fpc package
# res.fpc <- fpc::dbscan(iris, eps = 0.4, MinPts = 4)
# # dbscan package
# res.db <- dbscan::dbscan(iris, 0.4, 4)
# # The result of the function fpc::dbscan() provides an object of class ‘dbscan’ containing the following components:
# # cluster: integer vector coding cluster membership with noise observations (singletons) coded as 0
# # isseed: logical vector indicating whether a point is a seed (not border, not noise)
# # eps: parameter eps
# # MinPts: parameter MinPts
# # The result of the function dbscan::dbscan() is an integer vector with cluster assignments. Zero indicates noise points.
# # Note that the function dbscan:dbscan() is a fast re-implementation of DBSCAN algorithm. The implementation is significantly faster and can work with larger data sets than the function fpc:dbscan().
# 
# # Make sure that both version produce the same results:
# 
# all(res.fpc$cluster == res.db)
# ## [1] TRUE
# #The result can be visualized as follow:
# 
# fviz_cluster(res.fpc, iris, geom = "point")
```

```{r twitter-meta, echo = FALSE}
# library(metathis)
# meta() %>%
#   meta_description(
#     "First entry on a series of article that will gather my explorations over different way to define archetypes in Legends of Runeterra"
#   ) %>% 
#   meta_viewport() %>% 
#   meta_social(
#     title = "Defining Archetypes #1: Looking at the similarity of Akshan/Sivir/Zed with similar archetypes",
#     url = "https://llorr-stats.netlify.app/",
#     image = "images/archetypes/A01-ASZSZ.png",
#     image_alt = "ASZSZ",
#     og_type = "website",
#     og_author = "Legna",
#     twitter_card_type = "summary",
#     twitter_creator = "@Maou_Legna"
#   )
```

# Legal bla bla {.unnumbered}

This content was created under Riot Games' "Legal Jibber Jabber" policy using assets owned by Riot Games. Riot Games does not endorse or sponsor this project.
